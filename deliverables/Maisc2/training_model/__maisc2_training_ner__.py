# -*- coding: utf-8 -*-
"""__maisc2_training_ner__

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10SlA2xw03xs4hT4LSr0Uy9AOOJKqFszJ
"""

!pip install -U spacy
!pip install spacy_transformers
!python -m spacy download pt_core_news_sm

import os
os.kill(os.getpid(), 9)

import spacy
import spacy_transformers
from spacy.tokens import DocBin
from tqdm import tqdm
import json

spacy.__version__

!nvidia-smi

maisc2_data = json.load(open('/content/drive/MyDrive/__projects__/maisc2-training/data/input/maisc2_spacy_output_14.json', 'r', encoding='utf-8'))

maisc2_data

!python -m spacy init fill-config /content/drive/MyDrive/__projects__/maisc2-training/data/base_config.cfg /content/drive/MyDrive/__projects__/maisc2-training/data/config.cfg

def get_spacy_doc(file, data):
  nlp = spacy.blank('pt')
  db = DocBin()

  for text, annot in tqdm(data):
    doc = nlp.make_doc(text)
    annot = annot['entities']

    ents = []
    entity_indices = []

    for start, end, label in annot:
      skip_entity = False
      for idx in range(start, end):
        if idx in entity_indices:
          skip_entity = True
          break
      if skip_entity == True:
        continue

      entity_indices = entity_indices + list(range(start, end))

      try:
        span = doc.char_span(start, end, label=label, alignment_mode='strict')
      except:
        continue

      if span is None:
        err_data = str([start, end]) + ' ' + str(text) + '\n'
        file.write(err_data)

      else:
        ents.append(span)

    try:
      doc.ents = ents
      db.add(doc)
    except:
      pass

  return db

from sklearn.model_selection import train_test_split
train, test = train_test_split(maisc2_data, test_size=0.2)

len(train), len(test)

file = open('error.txt', 'w')

db = get_spacy_doc(file, train)
db.to_disk('/content/drive/MyDrive/__projects__/maisc2-training/train_data.spacy')

db = get_spacy_doc(file, test)
db.to_disk('/content/drive/MyDrive/__projects__/maisc2-training/test_data.spacy')

file.close()

db.tokens

len(db.tokens)

!python -m spacy train /content/drive/MyDrive/__projects__/maisc2-training/data/config.cfg --output /content/drive/MyDrive/__projects__/maisc2-training/output --paths.train /content/drive/MyDrive/__projects__/maisc2-training/train_data.spacy --paths.dev /content/drive/MyDrive/__projects__/maisc2-training/test_data.spacy --gpu-id 0

import spacy
nlp = spacy.load('/content/drive/MyDrive/__projects__/maisc2-training/output/model-best')

# entity recognition
doc = nlp('Chegou o exército com caminhões anfíbios direcionem para os pontos mais críticos de inundação')
# doc = nlp('o fogo iniciou no lado norte da vegetação')
#doc = nlp('o inimigo esta próximo abra fogo')
#doc = nlp('A operação tem comando de frente das viaturas vindo ao suldeste')
#doc = nlp('Os policiais vão rever as estratégias para atacar o quartel com os blindados, drones e granadas')
#doc = nlp('Atacar pelo franco esquerdo')
for ent in doc.ents:
  print(f'{ent} >> [{ent.label_}]')

# priority classification
# doc = nlp ('Equipe de apoio removam o que puderem do caminho#')
# doc = nlp ('Alguma confirmação de explosões secundárias?#')

msg = 'ataquem todos os soldados que cruzarem a linha vermelha#'
doc = nlp(msg)

for _ in doc.ents: print(f'{_} >> {_.label_}')
#print ([_ for _ in doc.ents])