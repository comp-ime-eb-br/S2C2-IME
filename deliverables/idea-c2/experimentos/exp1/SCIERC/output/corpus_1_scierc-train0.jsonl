{"id": "C86-1105", "text": " How to obtain  hierarchical relations (e.g.  superordinate -hyponym relation ,  synonym relation ) is one of the most important problems for  thesaurus construction . A pilot system for extracting these  relations  automatically from an ordinary  Japanese language dictionary  (Shinmeikai Kokugojiten, published by Sansei-do, in machine readable form) is given. The features of the  definition sentences  in the  dictionary , the mechanical extraction of the  hierarchical relations  and the estimation of the results are discussed. ", "Comments": [], "entities": [{"id": 1089272, "label": "ENT", "start_offset": 16, "end_offset": 38}, {"id": 1089273, "label": "ENT", "start_offset": 46, "end_offset": 77}, {"id": 1089274, "label": "ENT", "start_offset": 81, "end_offset": 97}, {"id": 1089275, "label": "ENT", "start_offset": 143, "end_offset": 165}, {"id": 1089276, "label": "ENT", "start_offset": 205, "end_offset": 214}, {"id": 1089277, "label": "ENT", "start_offset": 248, "end_offset": 276}, {"id": 1089278, "label": "ENT", "start_offset": 367, "end_offset": 375}, {"id": 1089279, "label": "ENT", "start_offset": 384, "end_offset": 404}, {"id": 1089280, "label": "ENT", "start_offset": 414, "end_offset": 424}, {"id": 1089281, "label": "ENT", "start_offset": 461, "end_offset": 483}], "relations": [{"id": 173238, "from_id": 1089272, "to_id": 1089275, "type": "PART-OF"}, {"id": 173239, "from_id": 1089277, "to_id": 1089276, "type": "USED-FOR"}, {"id": 173240, "from_id": 1089279, "to_id": 1089280, "type": "PART-OF"}, {"id": 173241, "from_id": 1089273, "to_id": 1089272, "type": "HYPONYM-OF"}, {"id": 173242, "from_id": 1089274, "to_id": 1089272, "type": "HYPONYM-OF"}, {"id": 173243, "from_id": 1089276, "to_id": 1089272, "type": "COREF"}, {"id": 173244, "from_id": 1089280, "to_id": 1089277, "type": "COREF"}, {"id": 173245, "from_id": 1089281, "to_id": 1089276, "type": "COREF"}, {"id": 173246, "from_id": 1089273, "to_id": 1089274, "type": "CONJUNCTION"}, {"id": 173247, "from_id": 1089279, "to_id": 1089278, "type": "USED-FOR"}]}
{"id": "X98-1022", "text": "  Automatic summarization  and  information extraction  are two important Internet services.  MUC  and  SUMMAC  play their appropriate roles in the next generation Internet. This paper focuses on the  automatic summarization  and proposes two different models to extract  sentences  for  summary generation  under two tasks initiated by  SUMMAC-1 . For  categorization task ,  positive feature vectors  and  negative feature vectors  are used cooperatively to construct generic, indicative  summaries . For adhoc task, a  text model  based on relationship between  nouns  and  verbs  is used to filter out irrelevant  discourse segment , to rank relevant  sentences , and to generate the  user-directed summaries . The result shows that the  NormF  of the best summary and that of the fixed summary for adhoc tasks are 0.456 and 0. 447. The  NormF  of the best summary and that of the fixed summary for  categorization task  are 0.4090 and 0.4023. Our system outperforms the average system in  categorization task  but does a common job in adhoc task. ", "Comments": [], "entities": [{"id": 1089282, "label": "ENT", "start_offset": 2, "end_offset": 25}, {"id": 1089283, "label": "ENT", "start_offset": 32, "end_offset": 54}, {"id": 1089284, "label": "ENT", "start_offset": 94, "end_offset": 97}, {"id": 1089285, "label": "ENT", "start_offset": 104, "end_offset": 110}, {"id": 1089286, "label": "ENT", "start_offset": 201, "end_offset": 224}, {"id": 1089287, "label": "ENT", "start_offset": 253, "end_offset": 259}, {"id": 1089288, "label": "ENT", "start_offset": 288, "end_offset": 306}, {"id": 1089289, "label": "ENT", "start_offset": 318, "end_offset": 323}, {"id": 1089290, "label": "ENT", "start_offset": 338, "end_offset": 346}, {"id": 1089291, "label": "ENT", "start_offset": 354, "end_offset": 373}, {"id": 1089292, "label": "ENT", "start_offset": 377, "end_offset": 401}, {"id": 1089293, "label": "ENT", "start_offset": 408, "end_offset": 432}, {"id": 1089294, "label": "ENT", "start_offset": 470, "end_offset": 500}, {"id": 1089295, "label": "ENT", "start_offset": 507, "end_offset": 517}, {"id": 1089296, "label": "ENT", "start_offset": 522, "end_offset": 532}, {"id": 1089297, "label": "ENT", "start_offset": 618, "end_offset": 635}, {"id": 1089298, "label": "ENT", "start_offset": 689, "end_offset": 712}, {"id": 1089299, "label": "ENT", "start_offset": 742, "end_offset": 747}, {"id": 1089300, "label": "ENT", "start_offset": 803, "end_offset": 814}, {"id": 1089301, "label": "ENT", "start_offset": 842, "end_offset": 847}, {"id": 1089302, "label": "ENT", "start_offset": 904, "end_offset": 923}, {"id": 1089303, "label": "ENT", "start_offset": 952, "end_offset": 958}, {"id": 1089304, "label": "ENT", "start_offset": 983, "end_offset": 989}, {"id": 1089305, "label": "ENT", "start_offset": 994, "end_offset": 1013}, {"id": 1089306, "label": "ENT", "start_offset": 1040, "end_offset": 1050}], "relations": [{"id": 173248, "from_id": 1089282, "to_id": 1089283, "type": "CONJUNCTION"}, {"id": 173249, "from_id": 1089282, "to_id": 1089286, "type": "COREF"}, {"id": 173250, "from_id": 1089292, "to_id": 1089293, "type": "CONJUNCTION"}, {"id": 173251, "from_id": 1089292, "to_id": 1089291, "type": "USED-FOR"}, {"id": 173252, "from_id": 1089293, "to_id": 1089291, "type": "USED-FOR"}, {"id": 173253, "from_id": 1089296, "to_id": 1089297, "type": "USED-FOR"}, {"id": 173254, "from_id": 1089296, "to_id": 1089298, "type": "USED-FOR"}, {"id": 173255, "from_id": 1089296, "to_id": 1089295, "type": "USED-FOR"}, {"id": 173256, "from_id": 1089301, "to_id": 1089299, "type": "COREF"}, {"id": 173257, "from_id": 1089301, "to_id": 1089302, "type": "EVALUATE-FOR"}, {"id": 173258, "from_id": 1089302, "to_id": 1089291, "type": "COREF"}, {"id": 173259, "from_id": 1089295, "to_id": 1089300, "type": "COREF"}, {"id": 173260, "from_id": 1089305, "to_id": 1089302, "type": "COREF"}, {"id": 173261, "from_id": 1089305, "to_id": 1089304, "type": "EVALUATE-FOR"}, {"id": 173262, "from_id": 1089305, "to_id": 1089303, "type": "EVALUATE-FOR"}, {"id": 173263, "from_id": 1089303, "to_id": 1089304, "type": "COMPARE"}, {"id": 173264, "from_id": 1089293, "to_id": 1089294, "type": "USED-FOR"}, {"id": 173265, "from_id": 1089292, "to_id": 1089294, "type": "USED-FOR"}, {"id": 173266, "from_id": 1089287, "to_id": 1089288, "type": "USED-FOR"}, {"id": 173267, "from_id": 1089299, "to_id": 1089300, "type": "EVALUATE-FOR"}, {"id": 173268, "from_id": 1089306, "to_id": 1089305, "type": "EVALUATE-FOR"}, {"id": 173269, "from_id": 1089306, "to_id": 1089303, "type": "EVALUATE-FOR"}, {"id": 173270, "from_id": 1089300, "to_id": 1089306, "type": "COREF"}, {"id": 173271, "from_id": 1089284, "to_id": 1089285, "type": "CONJUNCTION"}, {"id": 173272, "from_id": 1089289, "to_id": 1089290, "type": "PART-OF"}, {"id": 173273, "from_id": 1089291, "to_id": 1089289, "type": "HYPONYM-OF"}, {"id": 173274, "from_id": 1089295, "to_id": 1089289, "type": "HYPONYM-OF"}, {"id": 173275, "from_id": 1089287, "to_id": 1089289, "type": "USED-FOR"}, {"id": 173276, "from_id": 1089287, "to_id": 1089303, "type": "COREF"}]}
{"id": "C88-2160", "text": "   A new approach for  Interactive Machine Translation  where the  author  interacts during the creation or the modification of the  document  is proposed. The explanation of an  ambiguity  or an error for the purposes of correction does not use any concepts of the underlying  linguistic theory  : it is a reformulation of the erroneous or ambiguous  sentence  . The interaction is limited to the analysis step of the  translation process  . This paper presents a new  interactive disambiguation scheme  based on the  paraphrasing  of a  parser  's multiple output. Some examples of  paraphrasing  ambiguous  sentences  are presented. ", "Comments": [], "entities": [{"id": 1089408, "label": "ENT", "start_offset": 9, "end_offset": 17}, {"id": 1089409, "label": "ENT", "start_offset": 23, "end_offset": 54}, {"id": 1089410, "label": "ENT", "start_offset": 278, "end_offset": 295}, {"id": 1089411, "label": "ENT", "start_offset": 420, "end_offset": 439}, {"id": 1089412, "label": "ENT", "start_offset": 470, "end_offset": 503}, {"id": 1089413, "label": "ENT", "start_offset": 519, "end_offset": 531}], "relations": [{"id": 173346, "from_id": 1089408, "to_id": 1089409, "type": "USED-FOR"}, {"id": 173347, "from_id": 1089412, "to_id": 1089408, "type": "COREF"}, {"id": 173348, "from_id": 1089413, "to_id": 1089412, "type": "USED-FOR"}]}
{"id": "AAAI_2008_255_abs", "text": "It is well-known that diversity among base classifiers is crucial for constructing a strong ensemble. Most existing ensemble methods obtain diverse individual learners through resampling the instances or features. In this paper, we propose an alternative way for ensemble construction by resampling pairwise constraints that specify whether a pair of instances belongs to the same class or not. Using pairwise constraints for ensemble construction is challenging because it remains unknown how to influence the base classifiers with the sampled pairwise constraints. We solve this problem with a two-step process. First, we transform the original instances into a new data representation using projections learnt from pairwise constraints. Then, we build the base clas-sifiers with the new data representation. We propose two methods for resampling pairwise constraints following the standard Bagging and Boosting algorithms, respectively. Extensive experiments validate the effectiveness of our method.", "Comments": [], "entities": [{"id": 1089532, "label": "ENT", "start_offset": 38, "end_offset": 54}, {"id": 1089533, "label": "ENT", "start_offset": 92, "end_offset": 100}, {"id": 1089534, "label": "ENT", "start_offset": 116, "end_offset": 132}, {"id": 1089535, "label": "ENT", "start_offset": 263, "end_offset": 284}, {"id": 1089536, "label": "ENT", "start_offset": 288, "end_offset": 319}, {"id": 1089537, "label": "ENT", "start_offset": 401, "end_offset": 421}, {"id": 1089538, "label": "ENT", "start_offset": 426, "end_offset": 447}, {"id": 1089539, "label": "ENT", "start_offset": 511, "end_offset": 527}, {"id": 1089540, "label": "ENT", "start_offset": 537, "end_offset": 565}, {"id": 1089541, "label": "ENT", "start_offset": 668, "end_offset": 687}, {"id": 1089542, "label": "ENT", "start_offset": 694, "end_offset": 705}, {"id": 1089543, "label": "ENT", "start_offset": 718, "end_offset": 738}, {"id": 1089544, "label": "ENT", "start_offset": 759, "end_offset": 776}, {"id": 1089545, "label": "ENT", "start_offset": 790, "end_offset": 809}, {"id": 1089546, "label": "ENT", "start_offset": 838, "end_offset": 869}, {"id": 1089547, "label": "ENT", "start_offset": 893, "end_offset": 924}], "relations": [{"id": 173442, "from_id": 1089532, "to_id": 1089533, "type": "USED-FOR"}, {"id": 173443, "from_id": 1089537, "to_id": 1089538, "type": "USED-FOR"}, {"id": 173444, "from_id": 1089535, "to_id": 1089538, "type": "COREF"}, {"id": 173445, "from_id": 1089533, "to_id": 1089535, "type": "COREF"}, {"id": 173446, "from_id": 1089532, "to_id": 1089539, "type": "COREF"}, {"id": 173447, "from_id": 1089543, "to_id": 1089542, "type": "USED-FOR"}, {"id": 173448, "from_id": 1089539, "to_id": 1089544, "type": "COREF"}, {"id": 173449, "from_id": 1089536, "to_id": 1089535, "type": "USED-FOR"}, {"id": 173450, "from_id": 1089536, "to_id": 1089546, "type": "COREF"}, {"id": 173451, "from_id": 1089547, "to_id": 1089546, "type": "USED-FOR"}, {"id": 173452, "from_id": 1089542, "to_id": 1089541, "type": "USED-FOR"}, {"id": 173453, "from_id": 1089541, "to_id": 1089545, "type": "COREF"}, {"id": 173454, "from_id": 1089545, "to_id": 1089544, "type": "USED-FOR"}]}
{"id": "ICML_2006_119_abs", "text": "We investigate the problem of learning to predict moves in the board game of Go from game records of expert players. In particular, we obtain a probability distribution over legal moves for professional play in a given position. This distribution has numerous applications in computer Go, including serving as an efficient stand-alone Go player. It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players. Our method has two major components: a) a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b) a Bayesian learning algorithm (in two variants) that learns a distribution over the values of a move given a board position based on the local pattern context. The system is trained on 181,000 expert games and shows excellent prediction performance as indicated by its ability to perfectly predict the moves made by professional Go players in 34% of test positions.", "Comments": [], "entities": [{"id": 1089673, "label": "ENT", "start_offset": 63, "end_offset": 79}, {"id": 1089674, "label": "ENT", "start_offset": 85, "end_offset": 115}, {"id": 1089675, "label": "ENT", "start_offset": 144, "end_offset": 168}, {"id": 1089676, "label": "ENT", "start_offset": 234, "end_offset": 246}, {"id": 1089677, "label": "ENT", "start_offset": 276, "end_offset": 287}, {"id": 1089678, "label": "ENT", "start_offset": 323, "end_offset": 344}, {"id": 1089679, "label": "ENT", "start_offset": 346, "end_offset": 348}, {"id": 1089680, "label": "ENT", "start_offset": 378, "end_offset": 391}, {"id": 1089681, "label": "ENT", "start_offset": 396, "end_offset": 407}, {"id": 1089682, "label": "ENT", "start_offset": 412, "end_offset": 428}, {"id": 1089683, "label": "ENT", "start_offset": 438, "end_offset": 451}, {"id": 1089684, "label": "ENT", "start_offset": 456, "end_offset": 466}, {"id": 1089685, "label": "ENT", "start_offset": 472, "end_offset": 478}, {"id": 1089686, "label": "ENT", "start_offset": 510, "end_offset": 535}, {"id": 1089687, "label": "ENT", "start_offset": 630, "end_offset": 657}, {"id": 1089688, "label": "ENT", "start_offset": 765, "end_offset": 786}, {"id": 1089689, "label": "ENT", "start_offset": 792, "end_offset": 798}, {"id": 1089690, "label": "ENT", "start_offset": 821, "end_offset": 833}], "relations": [{"id": 173550, "from_id": 1089674, "to_id": 1089673, "type": "USED-FOR"}, {"id": 173551, "from_id": 1089676, "to_id": 1089675, "type": "COREF"}, {"id": 173552, "from_id": 1089676, "to_id": 1089677, "type": "USED-FOR"}, {"id": 173553, "from_id": 1089679, "to_id": 1089680, "type": "USED-FOR"}, {"id": 173554, "from_id": 1089680, "to_id": 1089682, "type": "USED-FOR"}, {"id": 173555, "from_id": 1089681, "to_id": 1089682, "type": "USED-FOR"}, {"id": 173556, "from_id": 1089680, "to_id": 1089681, "type": "CONJUNCTION"}, {"id": 173557, "from_id": 1089685, "to_id": 1089679, "type": "COREF"}, {"id": 173558, "from_id": 1089686, "to_id": 1089687, "type": "CONJUNCTION"}, {"id": 173559, "from_id": 1089686, "to_id": 1089685, "type": "PART-OF"}, {"id": 173560, "from_id": 1089687, "to_id": 1089685, "type": "PART-OF"}, {"id": 173561, "from_id": 1089689, "to_id": 1089685, "type": "COREF"}, {"id": 173562, "from_id": 1089690, "to_id": 1089689, "type": "USED-FOR"}, {"id": 173563, "from_id": 1089679, "to_id": 1089683, "type": "USED-FOR"}, {"id": 173564, "from_id": 1089683, "to_id": 1089684, "type": "USED-FOR"}, {"id": 173565, "from_id": 1089679, "to_id": 1089681, "type": "USED-FOR"}]}
{"id": "INTERSPEECH_2007_20_abs", "text": "We propose an efficient dialogue management for an information navigation system based on a document knowledge base. It is expected that incorporation of appropriate N-best candidates of ASR and contextual information will improve the system performance. The system also has several choices in generating responses or confirmations. In this paper, this selection is optimized as minimization of Bayes risk based on reward for correct information presentation and penalty for redundant turns. We have evaluated this strategy with our spoken dialogue system \" Dialogue Navigator for Kyoto City \" , which also has question-answering capability. Effectiveness of the proposed framework was confirmed in the success rate of retrieval and the average number of turns for information access.", "Comments": [], "entities": [{"id": 1089734, "label": "ENT", "start_offset": 24, "end_offset": 43}, {"id": 1089735, "label": "ENT", "start_offset": 51, "end_offset": 80}, {"id": 1089736, "label": "ENT", "start_offset": 92, "end_offset": 115}, {"id": 1089737, "label": "ENT", "start_offset": 166, "end_offset": 190}, {"id": 1089738, "label": "ENT", "start_offset": 195, "end_offset": 217}, {"id": 1089739, "label": "ENT", "start_offset": 235, "end_offset": 241}, {"id": 1089740, "label": "ENT", "start_offset": 259, "end_offset": 265}, {"id": 1089741, "label": "ENT", "start_offset": 294, "end_offset": 331}, {"id": 1089742, "label": "ENT", "start_offset": 379, "end_offset": 405}, {"id": 1089743, "label": "ENT", "start_offset": 415, "end_offset": 421}, {"id": 1089744, "label": "ENT", "start_offset": 426, "end_offset": 458}, {"id": 1089745, "label": "ENT", "start_offset": 463, "end_offset": 470}, {"id": 1089746, "label": "ENT", "start_offset": 475, "end_offset": 490}, {"id": 1089747, "label": "ENT", "start_offset": 515, "end_offset": 523}, {"id": 1089748, "label": "ENT", "start_offset": 533, "end_offset": 593}, {"id": 1089749, "label": "ENT", "start_offset": 611, "end_offset": 640}, {"id": 1089750, "label": "ENT", "start_offset": 672, "end_offset": 681}, {"id": 1089751, "label": "ENT", "start_offset": 703, "end_offset": 728}, {"id": 1089752, "label": "ENT", "start_offset": 737, "end_offset": 760}, {"id": 1089753, "label": "ENT", "start_offset": 765, "end_offset": 783}], "relations": [{"id": 173592, "from_id": 1089734, "to_id": 1089735, "type": "USED-FOR"}, {"id": 173593, "from_id": 1089736, "to_id": 1089735, "type": "USED-FOR"}, {"id": 173594, "from_id": 1089740, "to_id": 1089741, "type": "USED-FOR"}, {"id": 173595, "from_id": 1089743, "to_id": 1089742, "type": "USED-FOR"}, {"id": 173596, "from_id": 1089743, "to_id": 1089744, "type": "USED-FOR"}, {"id": 173597, "from_id": 1089745, "to_id": 1089746, "type": "USED-FOR"}, {"id": 173598, "from_id": 1089745, "to_id": 1089742, "type": "USED-FOR"}, {"id": 173599, "from_id": 1089747, "to_id": 1089742, "type": "COREF"}, {"id": 173600, "from_id": 1089740, "to_id": 1089739, "type": "COREF"}, {"id": 173601, "from_id": 1089739, "to_id": 1089735, "type": "COREF"}, {"id": 173602, "from_id": 1089750, "to_id": 1089747, "type": "COREF"}, {"id": 173603, "from_id": 1089751, "to_id": 1089750, "type": "EVALUATE-FOR"}, {"id": 173604, "from_id": 1089752, "to_id": 1089753, "type": "USED-FOR"}, {"id": 173605, "from_id": 1089752, "to_id": 1089750, "type": "EVALUATE-FOR"}, {"id": 173606, "from_id": 1089751, "to_id": 1089752, "type": "CONJUNCTION"}, {"id": 173607, "from_id": 1089737, "to_id": 1089739, "type": "USED-FOR"}, {"id": 173608, "from_id": 1089738, "to_id": 1089739, "type": "USED-FOR"}, {"id": 173609, "from_id": 1089737, "to_id": 1089738, "type": "CONJUNCTION"}, {"id": 173610, "from_id": 1089748, "to_id": 1089747, "type": "EVALUATE-FOR"}, {"id": 173611, "from_id": 1089749, "to_id": 1089748, "type": "FEATURE-OF"}, {"id": 173612, "from_id": 1089740, "to_id": 1089748, "type": "COREF"}, {"id": 173613, "from_id": 1089743, "to_id": 1089745, "type": "CONJUNCTION"}]}
{"id": "W02-1404", "text": " In this study, we propose a  knowledge-independent method  for aligning  terms  and thus extracting  translations  from a  small, domain-specific corpus  consisting of  parallel English and Chinese court judgments  from Hong Kong. With a  sentence-aligned corpus ,  translation equivalences  are suggested by analysing the  frequency profiles  of  parallel concordances . The method overcomes the limitations of  conventional statistical methods  which require  large corpora  to be effective, and  lexical approaches  which depend on existing  bilingual dictionaries . Pilot testing on a  parallel corpus  of about 113K  Chinese words  and 120K  English words  gives an encouraging 85%  precision  and 45%  recall . Future work includes fine-tuning the  algorithm  upon the analysis of the errors, and acquiring a  translation lexicon  for  legal terminology  by filtering out  general terms . ", "Comments": [], "entities": [{"id": 1089992, "label": "ENT", "start_offset": 30, "end_offset": 58}, {"id": 1089993, "label": "ENT", "start_offset": 124, "end_offset": 153}, {"id": 1089994, "label": "ENT", "start_offset": 170, "end_offset": 214}, {"id": 1089995, "label": "ENT", "start_offset": 240, "end_offset": 263}, {"id": 1089996, "label": "ENT", "start_offset": 267, "end_offset": 291}, {"id": 1089997, "label": "ENT", "start_offset": 325, "end_offset": 343}, {"id": 1089998, "label": "ENT", "start_offset": 349, "end_offset": 370}, {"id": 1089999, "label": "ENT", "start_offset": 377, "end_offset": 383}, {"id": 1090000, "label": "ENT", "start_offset": 427, "end_offset": 446}, {"id": 1090001, "label": "ENT", "start_offset": 463, "end_offset": 476}, {"id": 1090002, "label": "ENT", "start_offset": 500, "end_offset": 518}, {"id": 1090003, "label": "ENT", "start_offset": 546, "end_offset": 568}, {"id": 1090004, "label": "ENT", "start_offset": 591, "end_offset": 606}, {"id": 1090005, "label": "ENT", "start_offset": 689, "end_offset": 698}, {"id": 1090006, "label": "ENT", "start_offset": 709, "end_offset": 715}, {"id": 1090007, "label": "ENT", "start_offset": 756, "end_offset": 765}, {"id": 1090008, "label": "ENT", "start_offset": 817, "end_offset": 836}, {"id": 1090009, "label": "ENT", "start_offset": 843, "end_offset": 860}], "relations": [{"id": 173799, "from_id": 1089997, "to_id": 1089998, "type": "PART-OF"}, {"id": 173800, "from_id": 1090001, "to_id": 1090000, "type": "USED-FOR"}, {"id": 173801, "from_id": 1090003, "to_id": 1090002, "type": "USED-FOR"}, {"id": 173802, "from_id": 1090005, "to_id": 1090006, "type": "CONJUNCTION"}, {"id": 173803, "from_id": 1090008, "to_id": 1090009, "type": "USED-FOR"}, {"id": 173804, "from_id": 1089994, "to_id": 1089993, "type": "PART-OF"}, {"id": 173805, "from_id": 1089995, "to_id": 1089996, "type": "USED-FOR"}, {"id": 173806, "from_id": 1089999, "to_id": 1089992, "type": "COREF"}, {"id": 173807, "from_id": 1089999, "to_id": 1090000, "type": "COMPARE"}, {"id": 173808, "from_id": 1089999, "to_id": 1090002, "type": "COMPARE"}, {"id": 173809, "from_id": 1090007, "to_id": 1089999, "type": "COREF"}]}
{"id": "INTERSPEECH_2014_40_abs", "text": "This paper deals with the problem of generating the fundamental frequency (F0) contour of speech from a text input for text-to-speech synthesis. We have previously introduced a statistical model describing the generating process of speech F0 contours, based on the discrete-time version of the Fujisaki model. One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours. To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning, this paper proposes extending this model to a context-dependent one. We further propose a parameter training algorithm for the present model based on a decision tree-based context clustering.", "Comments": [], "entities": [{"id": 1090061, "label": "ENT", "start_offset": 52, "end_offset": 96}, {"id": 1090062, "label": "ENT", "start_offset": 104, "end_offset": 114}, {"id": 1090063, "label": "ENT", "start_offset": 119, "end_offset": 143}, {"id": 1090064, "label": "ENT", "start_offset": 177, "end_offset": 194}, {"id": 1090065, "label": "ENT", "start_offset": 232, "end_offset": 250}, {"id": 1090066, "label": "ENT", "start_offset": 294, "end_offset": 308}, {"id": 1090067, "label": "ENT", "start_offset": 314, "end_offset": 332}, {"id": 1090068, "label": "ENT", "start_offset": 341, "end_offset": 346}, {"id": 1090069, "label": "ENT", "start_offset": 355, "end_offset": 357}, {"id": 1090070, "label": "ENT", "start_offset": 396, "end_offset": 405}, {"id": 1090071, "label": "ENT", "start_offset": 424, "end_offset": 443}, {"id": 1090072, "label": "ENT", "start_offset": 463, "end_offset": 488}, {"id": 1090073, "label": "ENT", "start_offset": 494, "end_offset": 509}, {"id": 1090074, "label": "ENT", "start_offset": 542, "end_offset": 567}, {"id": 1090075, "label": "ENT", "start_offset": 575, "end_offset": 585}, {"id": 1090076, "label": "ENT", "start_offset": 595, "end_offset": 615}, {"id": 1090077, "label": "ENT", "start_offset": 652, "end_offset": 657}, {"id": 1090078, "label": "ENT", "start_offset": 707, "end_offset": 735}, {"id": 1090079, "label": "ENT", "start_offset": 752, "end_offset": 757}, {"id": 1090080, "label": "ENT", "start_offset": 769, "end_offset": 807}], "relations": [{"id": 173842, "from_id": 1090062, "to_id": 1090061, "type": "USED-FOR"}, {"id": 173843, "from_id": 1090061, "to_id": 1090063, "type": "USED-FOR"}, {"id": 173844, "from_id": 1090061, "to_id": 1090065, "type": "COREF"}, {"id": 173845, "from_id": 1090064, "to_id": 1090065, "type": "USED-FOR"}, {"id": 173846, "from_id": 1090064, "to_id": 1090068, "type": "COREF"}, {"id": 173847, "from_id": 1090066, "to_id": 1090064, "type": "USED-FOR"}, {"id": 173848, "from_id": 1090067, "to_id": 1090068, "type": "FEATURE-OF"}, {"id": 173849, "from_id": 1090068, "to_id": 1090069, "type": "COREF"}, {"id": 173850, "from_id": 1090071, "to_id": 1090070, "type": "USED-FOR"}, {"id": 173851, "from_id": 1090069, "to_id": 1090070, "type": "COREF"}, {"id": 173852, "from_id": 1090070, "to_id": 1090072, "type": "USED-FOR"}, {"id": 173853, "from_id": 1090073, "to_id": 1090072, "type": "USED-FOR"}, {"id": 173854, "from_id": 1090075, "to_id": 1090074, "type": "USED-FOR"}, {"id": 173855, "from_id": 1090078, "to_id": 1090079, "type": "USED-FOR"}, {"id": 173856, "from_id": 1090080, "to_id": 1090078, "type": "USED-FOR"}, {"id": 173857, "from_id": 1090069, "to_id": 1090077, "type": "COREF"}, {"id": 173858, "from_id": 1090076, "to_id": 1090074, "type": "USED-FOR"}, {"id": 173859, "from_id": 1090079, "to_id": 1090077, "type": "COREF"}]}
{"id": "H01-1017", "text": " To support engaging human users in robust,  mixed-initiative speech dialogue interactions  which reach beyond current capabilities in  dialogue systems  , the  DARPA Communicator program  [1] is funding the development of a  distributed message-passing infrastructure  for  dialogue systems  which all  Communicator  participants are using. In this presentation, we describe the features of and  requirements  for a genuinely useful  software infrastructure  for this purpose. ", "Comments": [], "entities": [{"id": 1090081, "label": "ENT", "start_offset": 45, "end_offset": 90}, {"id": 1090082, "label": "ENT", "start_offset": 136, "end_offset": 152}, {"id": 1090083, "label": "ENT", "start_offset": 226, "end_offset": 268}, {"id": 1090084, "label": "ENT", "start_offset": 275, "end_offset": 291}], "relations": [{"id": 173860, "from_id": 1090083, "to_id": 1090084, "type": "USED-FOR"}, {"id": 173861, "from_id": 1090084, "to_id": 1090082, "type": "COREF"}]}
{"id": "C82-1054", "text": "   This paper proposes a series of modifications to the  left corner parsing algorithm  for  context-free grammars  . It is argued that the resulting algorithm is both efficient and flexible and is, therefore, a good choice for the  parser  used in a  natural language interface  . ", "Comments": [], "entities": [{"id": 1090167, "label": "ENT", "start_offset": 57, "end_offset": 86}, {"id": 1090168, "label": "ENT", "start_offset": 93, "end_offset": 114}, {"id": 1090169, "label": "ENT", "start_offset": 150, "end_offset": 159}, {"id": 1090170, "label": "ENT", "start_offset": 233, "end_offset": 239}, {"id": 1090171, "label": "ENT", "start_offset": 252, "end_offset": 278}], "relations": [{"id": 173916, "from_id": 1090167, "to_id": 1090168, "type": "USED-FOR"}, {"id": 173917, "from_id": 1090170, "to_id": 1090171, "type": "USED-FOR"}, {"id": 173918, "from_id": 1090169, "to_id": 1090167, "type": "COREF"}, {"id": 173919, "from_id": 1090169, "to_id": 1090170, "type": "USED-FOR"}]}
{"id": "CVPR_2015_303_abs", "text": "In this paper we target at generating generic action proposals in unconstrained videos. Each action proposal corresponds to a temporal series of spatial bounding boxes, i.e., a spatio-temporal video tube, which has a good potential to locate one human action. Assuming each action is performed by a human with meaningful motion, both appearance and motion cues are utilized to measure the ac-tionness of the video tubes. After picking those spatiotem-poral paths of high actionness scores, our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score. Compared with existing action proposal approaches, our action proposals do not rely on video segmentation and can be generated in nearly real-time. Experimental results on two challenging datasets, MSRII and UCF 101, validate the superior performance of our action proposals as well as competitive results on action detection and search.", "Comments": [], "entities": [{"id": 1090252, "label": "ENT", "start_offset": 38, "end_offset": 62}, {"id": 1090253, "label": "ENT", "start_offset": 66, "end_offset": 86}, {"id": 1090254, "label": "ENT", "start_offset": 93, "end_offset": 108}, {"id": 1090255, "label": "ENT", "start_offset": 126, "end_offset": 167}, {"id": 1090256, "label": "ENT", "start_offset": 177, "end_offset": 203}, {"id": 1090257, "label": "ENT", "start_offset": 246, "end_offset": 258}, {"id": 1090258, "label": "ENT", "start_offset": 334, "end_offset": 360}, {"id": 1090259, "label": "ENT", "start_offset": 389, "end_offset": 400}, {"id": 1090260, "label": "ENT", "start_offset": 408, "end_offset": 419}, {"id": 1090261, "label": "ENT", "start_offset": 471, "end_offset": 488}, {"id": 1090262, "label": "ENT", "start_offset": 494, "end_offset": 520}, {"id": 1090263, "label": "ENT", "start_offset": 540, "end_offset": 568}, {"id": 1090264, "label": "ENT", "start_offset": 577, "end_offset": 590}, {"id": 1090265, "label": "ENT", "start_offset": 623, "end_offset": 639}, {"id": 1090266, "label": "ENT", "start_offset": 670, "end_offset": 686}, {"id": 1090267, "label": "ENT", "start_offset": 711, "end_offset": 737}, {"id": 1090268, "label": "ENT", "start_offset": 743, "end_offset": 759}, {"id": 1090269, "label": "ENT", "start_offset": 775, "end_offset": 793}, {"id": 1090270, "label": "ENT", "start_offset": 876, "end_offset": 884}, {"id": 1090271, "label": "ENT", "start_offset": 886, "end_offset": 891}, {"id": 1090272, "label": "ENT", "start_offset": 896, "end_offset": 903}, {"id": 1090273, "label": "ENT", "start_offset": 946, "end_offset": 962}, {"id": 1090274, "label": "ENT", "start_offset": 997, "end_offset": 1024}], "relations": [{"id": 173965, "from_id": 1090256, "to_id": 1090255, "type": "HYPONYM-OF"}, {"id": 173966, "from_id": 1090256, "to_id": 1090257, "type": "USED-FOR"}, {"id": 173967, "from_id": 1090259, "to_id": 1090260, "type": "EVALUATE-FOR"}, {"id": 173968, "from_id": 1090258, "to_id": 1090259, "type": "USED-FOR"}, {"id": 173969, "from_id": 1090263, "to_id": 1090262, "type": "USED-FOR"}, {"id": 173970, "from_id": 1090264, "to_id": 1090265, "type": "USED-FOR"}, {"id": 173971, "from_id": 1090266, "to_id": 1090265, "type": "EVALUATE-FOR"}, {"id": 173972, "from_id": 1090267, "to_id": 1090268, "type": "COMPARE"}, {"id": 173973, "from_id": 1090271, "to_id": 1090270, "type": "HYPONYM-OF"}, {"id": 173974, "from_id": 1090272, "to_id": 1090270, "type": "HYPONYM-OF"}, {"id": 173975, "from_id": 1090271, "to_id": 1090272, "type": "CONJUNCTION"}, {"id": 173976, "from_id": 1090270, "to_id": 1090273, "type": "EVALUATE-FOR"}, {"id": 173977, "from_id": 1090274, "to_id": 1090273, "type": "EVALUATE-FOR"}, {"id": 173978, "from_id": 1090273, "to_id": 1090268, "type": "COREF"}, {"id": 173979, "from_id": 1090253, "to_id": 1090252, "type": "USED-FOR"}]}
{"id": "C90-3063", "text": "  Manual acquisition  of  semantic constraints  in broad domains is very expensive. This paper presents an automatic scheme for collecting statistics on  cooccurrence patterns  in a large  corpus . To a large extent, these statistics reflect  semantic constraints  and thus are used to disambiguate  anaphora references  and  syntactic ambiguities . The scheme was implemented by gathering statistics on the output of other linguistic tools. An experiment was performed to resolve  references  of the  pronoun \"it\"  in  sentences  that were randomly selected from the  corpus . The results of the experiment show that in most of the cases the  cooccurrence statistics  indeed reflect the  semantic constraints  and thus provide a basis for a useful  disambiguation tool . ", "Comments": [], "entities": [{"id": 1090303, "label": "ENT", "start_offset": 2, "end_offset": 46}, {"id": 1090304, "label": "ENT", "start_offset": 154, "end_offset": 175}, {"id": 1090305, "label": "ENT", "start_offset": 243, "end_offset": 263}, {"id": 1090306, "label": "ENT", "start_offset": 300, "end_offset": 319}, {"id": 1090307, "label": "ENT", "start_offset": 326, "end_offset": 347}, {"id": 1090308, "label": "ENT", "start_offset": 424, "end_offset": 440}, {"id": 1090309, "label": "ENT", "start_offset": 644, "end_offset": 667}, {"id": 1090310, "label": "ENT", "start_offset": 689, "end_offset": 709}, {"id": 1090311, "label": "ENT", "start_offset": 750, "end_offset": 769}], "relations": [{"id": 174005, "from_id": 1090305, "to_id": 1090306, "type": "USED-FOR"}, {"id": 174006, "from_id": 1090309, "to_id": 1090311, "type": "USED-FOR"}, {"id": 174007, "from_id": 1090305, "to_id": 1090307, "type": "USED-FOR"}, {"id": 174008, "from_id": 1090306, "to_id": 1090307, "type": "CONJUNCTION"}]}
{"id": "P03-1070", "text": " We investigate the  verbal and nonverbal means  for  grounding  , and propose a design for  embodied conversational agents  that relies on both kinds of  signals  to establish  common ground  in  human-computer interaction  . We analyzed  eye gaze  ,  head nods  and  attentional focus  in the context of a  direction-giving task  . The distribution of  nonverbal behaviors  differed depending on the type of  dialogue move  being grounded, and the overall pattern reflected a monitoring of lack of  negative feedback  . Based on these results, we present an  ECA  that uses  verbal and nonverbal grounding acts  to update  dialogue state  . ", "Comments": [], "entities": [{"id": 1090312, "label": "ENT", "start_offset": 21, "end_offset": 47}, {"id": 1090313, "label": "ENT", "start_offset": 54, "end_offset": 63}, {"id": 1090314, "label": "ENT", "start_offset": 81, "end_offset": 87}, {"id": 1090315, "label": "ENT", "start_offset": 93, "end_offset": 123}, {"id": 1090316, "label": "ENT", "start_offset": 178, "end_offset": 191}, {"id": 1090317, "label": "ENT", "start_offset": 197, "end_offset": 223}, {"id": 1090318, "label": "ENT", "start_offset": 240, "end_offset": 248}, {"id": 1090319, "label": "ENT", "start_offset": 253, "end_offset": 262}, {"id": 1090320, "label": "ENT", "start_offset": 269, "end_offset": 286}, {"id": 1090321, "label": "ENT", "start_offset": 309, "end_offset": 330}, {"id": 1090322, "label": "ENT", "start_offset": 355, "end_offset": 374}, {"id": 1090323, "label": "ENT", "start_offset": 411, "end_offset": 424}, {"id": 1090324, "label": "ENT", "start_offset": 501, "end_offset": 518}, {"id": 1090325, "label": "ENT", "start_offset": 561, "end_offset": 564}, {"id": 1090326, "label": "ENT", "start_offset": 577, "end_offset": 612}, {"id": 1090327, "label": "ENT", "start_offset": 625, "end_offset": 639}], "relations": [{"id": 174009, "from_id": 1090320, "to_id": 1090321, "type": "PART-OF"}, {"id": 174010, "from_id": 1090312, "to_id": 1090313, "type": "USED-FOR"}, {"id": 174011, "from_id": 1090314, "to_id": 1090315, "type": "USED-FOR"}, {"id": 174012, "from_id": 1090326, "to_id": 1090327, "type": "USED-FOR"}, {"id": 174013, "from_id": 1090326, "to_id": 1090325, "type": "USED-FOR"}, {"id": 174014, "from_id": 1090316, "to_id": 1090317, "type": "USED-FOR"}, {"id": 174015, "from_id": 1090318, "to_id": 1090319, "type": "CONJUNCTION"}, {"id": 174016, "from_id": 1090319, "to_id": 1090320, "type": "CONJUNCTION"}, {"id": 174017, "from_id": 1090319, "to_id": 1090321, "type": "PART-OF"}, {"id": 174018, "from_id": 1090318, "to_id": 1090321, "type": "PART-OF"}]}
{"id": "P06-1052", "text": " We present an efficient algorithm for the  redundancy elimination problem  : Given an  underspecified semantic representation (USR)  of a  scope ambiguity  , compute an  USR  with fewer mutually  equivalent readings  . The algorithm operates on  underspecified chart representations  which are derived from  dominance graphs  ; it can be applied to the  USRs  computed by  large-scale grammars  . We evaluate the algorithm on a  corpus  , and show that it reduces the degree of  ambiguity  significantly while taking negligible runtime. ", "Comments": [], "entities": [{"id": 1090339, "label": "ENT", "start_offset": 25, "end_offset": 34}, {"id": 1090340, "label": "ENT", "start_offset": 44, "end_offset": 74}, {"id": 1090341, "label": "ENT", "start_offset": 88, "end_offset": 132}, {"id": 1090342, "label": "ENT", "start_offset": 140, "end_offset": 155}, {"id": 1090343, "label": "ENT", "start_offset": 171, "end_offset": 174}, {"id": 1090344, "label": "ENT", "start_offset": 197, "end_offset": 216}, {"id": 1090345, "label": "ENT", "start_offset": 224, "end_offset": 233}, {"id": 1090346, "label": "ENT", "start_offset": 247, "end_offset": 283}, {"id": 1090347, "label": "ENT", "start_offset": 309, "end_offset": 325}, {"id": 1090348, "label": "ENT", "start_offset": 329, "end_offset": 331}, {"id": 1090349, "label": "ENT", "start_offset": 355, "end_offset": 359}, {"id": 1090350, "label": "ENT", "start_offset": 374, "end_offset": 394}, {"id": 1090351, "label": "ENT", "start_offset": 414, "end_offset": 423}, {"id": 1090352, "label": "ENT", "start_offset": 454, "end_offset": 456}, {"id": 1090353, "label": "ENT", "start_offset": 469, "end_offset": 489}], "relations": [{"id": 174022, "from_id": 1090341, "to_id": 1090342, "type": "USED-FOR"}, {"id": 174023, "from_id": 1090339, "to_id": 1090340, "type": "USED-FOR"}, {"id": 174024, "from_id": 1090341, "to_id": 1090343, "type": "COREF"}, {"id": 174025, "from_id": 1090351, "to_id": 1090352, "type": "COREF"}, {"id": 174026, "from_id": 1090344, "to_id": 1090343, "type": "USED-FOR"}, {"id": 174027, "from_id": 1090345, "to_id": 1090346, "type": "USED-FOR"}, {"id": 174028, "from_id": 1090339, "to_id": 1090345, "type": "COREF"}, {"id": 174029, "from_id": 1090347, "to_id": 1090346, "type": "USED-FOR"}, {"id": 174030, "from_id": 1090345, "to_id": 1090348, "type": "COREF"}, {"id": 174031, "from_id": 1090348, "to_id": 1090349, "type": "USED-FOR"}, {"id": 174032, "from_id": 1090341, "to_id": 1090349, "type": "COREF"}, {"id": 174033, "from_id": 1090350, "to_id": 1090349, "type": "USED-FOR"}, {"id": 174034, "from_id": 1090352, "to_id": 1090353, "type": "USED-FOR"}]}
{"id": "H94-1064", "text": " A major axis of research at LIMSI is directed at  multilingual, speaker-independent, large vocabulary speech dictation . In this paper the  LIMSI recognizer  which was evaluated in the  ARPA NOV93 CSR test  is described, and experimental results on the  WSJ and BREF corpora  under closely matched conditions are reported. For both  corpora   word recognition experiments  were carried out with  vocabularies  containing up to 20k  words . The recognizer makes use of  continuous density HMM  with  Gaussian mixture  for  acoustic modeling  and  n-gram statistics  estimated on the  newspaper texts  for  language modeling . The recognizer uses a  time-synchronous graph-search strategy  which is shown to still be viable with a 20k-word vocabulary when used with  bigram back-off language models . A second  forward pass , which makes use of a  word graph  generated with the  bigram , incorporates a  trigram language model .  Acoustic modeling  uses  cepstrum-based features ,  context-dependent phone models (intra and interword) ,  phone duration models , and  sex-dependent models . ", "Comments": [], "entities": [{"id": 1090360, "label": "ENT", "start_offset": 51, "end_offset": 119}, {"id": 1090361, "label": "ENT", "start_offset": 141, "end_offset": 157}, {"id": 1090362, "label": "ENT", "start_offset": 187, "end_offset": 206}, {"id": 1090363, "label": "ENT", "start_offset": 255, "end_offset": 275}, {"id": 1090364, "label": "ENT", "start_offset": 334, "end_offset": 341}, {"id": 1090365, "label": "ENT", "start_offset": 344, "end_offset": 360}, {"id": 1090366, "label": "ENT", "start_offset": 445, "end_offset": 455}, {"id": 1090367, "label": "ENT", "start_offset": 470, "end_offset": 492}, {"id": 1090368, "label": "ENT", "start_offset": 500, "end_offset": 516}, {"id": 1090369, "label": "ENT", "start_offset": 523, "end_offset": 540}, {"id": 1090370, "label": "ENT", "start_offset": 547, "end_offset": 564}, {"id": 1090371, "label": "ENT", "start_offset": 584, "end_offset": 599}, {"id": 1090372, "label": "ENT", "start_offset": 606, "end_offset": 623}, {"id": 1090373, "label": "ENT", "start_offset": 630, "end_offset": 640}, {"id": 1090374, "label": "ENT", "start_offset": 649, "end_offset": 687}, {"id": 1090375, "label": "ENT", "start_offset": 766, "end_offset": 797}, {"id": 1090376, "label": "ENT", "start_offset": 847, "end_offset": 857}, {"id": 1090377, "label": "ENT", "start_offset": 879, "end_offset": 885}, {"id": 1090378, "label": "ENT", "start_offset": 904, "end_offset": 926}, {"id": 1090379, "label": "ENT", "start_offset": 930, "end_offset": 947}, {"id": 1090380, "label": "ENT", "start_offset": 955, "end_offset": 978}, {"id": 1090381, "label": "ENT", "start_offset": 982, "end_offset": 1034}, {"id": 1090382, "label": "ENT", "start_offset": 1038, "end_offset": 1059}, {"id": 1090383, "label": "ENT", "start_offset": 1067, "end_offset": 1087}], "relations": [{"id": 174039, "from_id": 1090367, "to_id": 1090368, "type": "CONJUNCTION"}, {"id": 174040, "from_id": 1090370, "to_id": 1090372, "type": "USED-FOR"}, {"id": 174041, "from_id": 1090380, "to_id": 1090379, "type": "USED-FOR"}, {"id": 174042, "from_id": 1090362, "to_id": 1090361, "type": "EVALUATE-FOR"}, {"id": 174043, "from_id": 1090363, "to_id": 1090361, "type": "EVALUATE-FOR"}, {"id": 174044, "from_id": 1090366, "to_id": 1090361, "type": "COREF"}, {"id": 174045, "from_id": 1090367, "to_id": 1090366, "type": "USED-FOR"}, {"id": 174046, "from_id": 1090367, "to_id": 1090369, "type": "USED-FOR"}, {"id": 174047, "from_id": 1090371, "to_id": 1090370, "type": "EVALUATE-FOR"}, {"id": 174048, "from_id": 1090370, "to_id": 1090366, "type": "USED-FOR"}, {"id": 174049, "from_id": 1090367, "to_id": 1090370, "type": "CONJUNCTION"}, {"id": 174050, "from_id": 1090373, "to_id": 1090366, "type": "COREF"}, {"id": 174051, "from_id": 1090374, "to_id": 1090373, "type": "USED-FOR"}, {"id": 174052, "from_id": 1090375, "to_id": 1090374, "type": "CONJUNCTION"}, {"id": 174053, "from_id": 1090375, "to_id": 1090373, "type": "USED-FOR"}, {"id": 174054, "from_id": 1090377, "to_id": 1090376, "type": "USED-FOR"}, {"id": 174055, "from_id": 1090379, "to_id": 1090369, "type": "COREF"}, {"id": 174056, "from_id": 1090378, "to_id": 1090376, "type": "CONJUNCTION"}, {"id": 174057, "from_id": 1090381, "to_id": 1090379, "type": "USED-FOR"}, {"id": 174058, "from_id": 1090382, "to_id": 1090379, "type": "USED-FOR"}, {"id": 174059, "from_id": 1090383, "to_id": 1090379, "type": "USED-FOR"}, {"id": 174060, "from_id": 1090380, "to_id": 1090381, "type": "CONJUNCTION"}, {"id": 174061, "from_id": 1090381, "to_id": 1090382, "type": "CONJUNCTION"}, {"id": 174062, "from_id": 1090382, "to_id": 1090383, "type": "CONJUNCTION"}, {"id": 174063, "from_id": 1090362, "to_id": 1090364, "type": "HYPONYM-OF"}, {"id": 174064, "from_id": 1090363, "to_id": 1090364, "type": "HYPONYM-OF"}, {"id": 174065, "from_id": 1090368, "to_id": 1090369, "type": "USED-FOR"}, {"id": 174066, "from_id": 1090364, "to_id": 1090365, "type": "EVALUATE-FOR"}]}
{"id": "H01-1001", "text": "  Oral communication  is ubiquitous and carries important information yet it is also time consuming to document. Given the development of  storage media and networks  one could just record and store a  conversation  for documentation. The question is, however, how an interesting information piece would be found in a  large database  . Traditional  information retrieval techniques  use a  histogram  of  keywords  as the  document representation  but  oral communication  may offer additional  indices  such as the time and place of the rejoinder and the attendance. An alternative  index  could be the activity such as discussing, planning, informing, story-telling, etc. This paper addresses the problem of the  automatic detection  of those activities in meeting situation and everyday rejoinders. Several extensions of this basic idea are being discussed and/or evaluated: Similar to activities one can define subsets of larger  database  and detect those automatically which is shown on a large  database  of  TV shows  .  Emotions  and other  indices  such as the  dominance distribution of speakers  might be available on the  surface  and could be used directly. Despite the small size of the  databases  used some results about the effectiveness of these  indices  can be obtained. ", "Comments": [], "entities": [{"id": 1090397, "label": "ENT", "start_offset": 2, "end_offset": 20}, {"id": 1090398, "label": "ENT", "start_offset": 139, "end_offset": 165}, {"id": 1090399, "label": "ENT", "start_offset": 202, "end_offset": 214}, {"id": 1090400, "label": "ENT", "start_offset": 350, "end_offset": 382}, {"id": 1090401, "label": "ENT", "start_offset": 391, "end_offset": 414}, {"id": 1090402, "label": "ENT", "start_offset": 424, "end_offset": 447}, {"id": 1090403, "label": "ENT", "start_offset": 454, "end_offset": 472}, {"id": 1090404, "label": "ENT", "start_offset": 605, "end_offset": 613}, {"id": 1090405, "label": "ENT", "start_offset": 622, "end_offset": 632}, {"id": 1090406, "label": "ENT", "start_offset": 634, "end_offset": 642}, {"id": 1090407, "label": "ENT", "start_offset": 644, "end_offset": 653}, {"id": 1090408, "label": "ENT", "start_offset": 655, "end_offset": 668}, {"id": 1090409, "label": "ENT", "start_offset": 716, "end_offset": 735}, {"id": 1090410, "label": "ENT", "start_offset": 746, "end_offset": 756}, {"id": 1090411, "label": "ENT", "start_offset": 890, "end_offset": 900}, {"id": 1090412, "label": "ENT", "start_offset": 1003, "end_offset": 1025}, {"id": 1090413, "label": "ENT", "start_offset": 1030, "end_offset": 1038}, {"id": 1090414, "label": "ENT", "start_offset": 1073, "end_offset": 1107}], "relations": [{"id": 174075, "from_id": 1090403, "to_id": 1090397, "type": "COREF"}, {"id": 174076, "from_id": 1090405, "to_id": 1090404, "type": "HYPONYM-OF"}, {"id": 174077, "from_id": 1090406, "to_id": 1090404, "type": "HYPONYM-OF"}, {"id": 174078, "from_id": 1090407, "to_id": 1090404, "type": "HYPONYM-OF"}, {"id": 174079, "from_id": 1090408, "to_id": 1090404, "type": "HYPONYM-OF"}, {"id": 174080, "from_id": 1090405, "to_id": 1090406, "type": "CONJUNCTION"}, {"id": 174081, "from_id": 1090406, "to_id": 1090407, "type": "CONJUNCTION"}, {"id": 174082, "from_id": 1090407, "to_id": 1090408, "type": "CONJUNCTION"}, {"id": 174083, "from_id": 1090410, "to_id": 1090404, "type": "COREF"}, {"id": 174084, "from_id": 1090410, "to_id": 1090409, "type": "USED-FOR"}, {"id": 174085, "from_id": 1090411, "to_id": 1090410, "type": "COREF"}, {"id": 174086, "from_id": 1090401, "to_id": 1090400, "type": "USED-FOR"}, {"id": 174087, "from_id": 1090401, "to_id": 1090402, "type": "USED-FOR"}]}
{"id": "E99-1015", "text": " In order to build robust  automatic abstracting systems , there is a need for better  training resources  than are currently available. In this paper, we introduce an  annotation scheme  for scientific articles which can be used to build such a  resource  in a consistent way. The seven categories of the  scheme  are based on  rhetorical moves  of  argumentation . Our experimental results show that the  scheme  is stable, reproducible and intuitive to use. ", "Comments": [], "entities": [{"id": 1090465, "label": "ENT", "start_offset": 27, "end_offset": 56}, {"id": 1090466, "label": "ENT", "start_offset": 87, "end_offset": 105}, {"id": 1090467, "label": "ENT", "start_offset": 169, "end_offset": 186}, {"id": 1090468, "label": "ENT", "start_offset": 192, "end_offset": 211}, {"id": 1090469, "label": "ENT", "start_offset": 247, "end_offset": 255}, {"id": 1090470, "label": "ENT", "start_offset": 307, "end_offset": 313}, {"id": 1090471, "label": "ENT", "start_offset": 329, "end_offset": 364}, {"id": 1090472, "label": "ENT", "start_offset": 407, "end_offset": 413}], "relations": [{"id": 174136, "from_id": 1090466, "to_id": 1090465, "type": "USED-FOR"}, {"id": 174137, "from_id": 1090467, "to_id": 1090469, "type": "USED-FOR"}, {"id": 174138, "from_id": 1090467, "to_id": 1090468, "type": "USED-FOR"}, {"id": 174139, "from_id": 1090470, "to_id": 1090467, "type": "COREF"}, {"id": 174140, "from_id": 1090472, "to_id": 1090470, "type": "COREF"}, {"id": 174141, "from_id": 1090469, "to_id": 1090466, "type": "COREF"}, {"id": 174142, "from_id": 1090471, "to_id": 1090470, "type": "USED-FOR"}]}
{"id": "H89-2019", "text": " This paper proposes an automatic, essentially  domain-independent means of evaluating Spoken Language Systems (SLS)  which combines  software  we have developed for that purpose (the \" Comparator \") and a set of  specifications  for  answer expressions  (the \" Common Answer Specification \", or  CAS ). The  Comparator  checks whether the answer provided by a  SLS  accords with a  canonical answer , returning either true or false. The  Common Answer Specification  determines the  syntax  of  answer expressions , the minimal  content  that must be included in them, the  data  to be included in and excluded from  test corpora , and the  procedures  used by the  Comparator . Though some details of the  CAS  are particular to individual  domains , the  Comparator software  is  domain-independent , as is the  CAS approach . ", "Comments": [], "entities": [{"id": 1090490, "label": "ENT", "start_offset": 48, "end_offset": 116}, {"id": 1090491, "label": "ENT", "start_offset": 134, "end_offset": 142}, {"id": 1090492, "label": "ENT", "start_offset": 186, "end_offset": 196}, {"id": 1090493, "label": "ENT", "start_offset": 214, "end_offset": 228}, {"id": 1090494, "label": "ENT", "start_offset": 235, "end_offset": 253}, {"id": 1090495, "label": "ENT", "start_offset": 262, "end_offset": 289}, {"id": 1090496, "label": "ENT", "start_offset": 297, "end_offset": 300}, {"id": 1090497, "label": "ENT", "start_offset": 309, "end_offset": 319}, {"id": 1090498, "label": "ENT", "start_offset": 362, "end_offset": 365}, {"id": 1090499, "label": "ENT", "start_offset": 439, "end_offset": 466}, {"id": 1090500, "label": "ENT", "start_offset": 484, "end_offset": 514}, {"id": 1090501, "label": "ENT", "start_offset": 667, "end_offset": 677}, {"id": 1090502, "label": "ENT", "start_offset": 708, "end_offset": 711}, {"id": 1090503, "label": "ENT", "start_offset": 758, "end_offset": 777}, {"id": 1090504, "label": "ENT", "start_offset": 815, "end_offset": 827}], "relations": [{"id": 174157, "from_id": 1090492, "to_id": 1090491, "type": "COREF"}, {"id": 174158, "from_id": 1090496, "to_id": 1090495, "type": "COREF"}, {"id": 174159, "from_id": 1090497, "to_id": 1090492, "type": "COREF"}, {"id": 174160, "from_id": 1090498, "to_id": 1090490, "type": "COREF"}, {"id": 174161, "from_id": 1090499, "to_id": 1090496, "type": "COREF"}, {"id": 174162, "from_id": 1090501, "to_id": 1090497, "type": "COREF"}, {"id": 174163, "from_id": 1090502, "to_id": 1090499, "type": "COREF"}, {"id": 174164, "from_id": 1090504, "to_id": 1090502, "type": "COREF"}, {"id": 174165, "from_id": 1090503, "to_id": 1090497, "type": "COREF"}, {"id": 174166, "from_id": 1090499, "to_id": 1090500, "type": "USED-FOR"}, {"id": 174167, "from_id": 1090495, "to_id": 1090493, "type": "COREF"}, {"id": 174168, "from_id": 1090493, "to_id": 1090494, "type": "USED-FOR"}, {"id": 174169, "from_id": 1090491, "to_id": 1090493, "type": "CONJUNCTION"}, {"id": 174170, "from_id": 1090491, "to_id": 1090490, "type": "PART-OF"}, {"id": 174171, "from_id": 1090493, "to_id": 1090490, "type": "PART-OF"}]}
{"id": "CVPR_2016_413_abs", "text": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision. However, acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction, active sensing devices and/or synthetic scenes. To overcome this problem, we propose a new, flexible , and scalable way for generating training data that only requires a set of stereo images as input. The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm. This enables us to generate a huge amount of training data in a fully automated manner. Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data.", "Comments": [], "entities": [{"id": 1090594, "label": "ENT", "start_offset": 0, "end_offset": 27}, {"id": 1090595, "label": "ENT", "start_offset": 59, "end_offset": 74}, {"id": 1090596, "label": "ENT", "start_offset": 79, "end_offset": 98}, {"id": 1090597, "label": "ENT", "start_offset": 102, "end_offset": 115}, {"id": 1090598, "label": "ENT", "start_offset": 206, "end_offset": 210}, {"id": 1090599, "label": "ENT", "start_offset": 225, "end_offset": 243}, {"id": 1090600, "label": "ENT", "start_offset": 245, "end_offset": 267}, {"id": 1090601, "label": "ENT", "start_offset": 275, "end_offset": 291}, {"id": 1090602, "label": "ENT", "start_offset": 310, "end_offset": 317}, {"id": 1090603, "label": "ENT", "start_offset": 422, "end_offset": 435}, {"id": 1090604, "label": "ENT", "start_offset": 466, "end_offset": 474}, {"id": 1090605, "label": "ENT", "start_offset": 495, "end_offset": 506}, {"id": 1090606, "label": "ENT", "start_offset": 568, "end_offset": 587}, {"id": 1090607, "label": "ENT", "start_offset": 612, "end_offset": 628}, {"id": 1090608, "label": "ENT", "start_offset": 779, "end_offset": 787}, {"id": 1090609, "label": "ENT", "start_offset": 825, "end_offset": 852}, {"id": 1090610, "label": "ENT", "start_offset": 860, "end_offset": 877}, {"id": 1090611, "label": "ENT", "start_offset": 897, "end_offset": 901}, {"id": 1090612, "label": "ENT", "start_offset": 922, "end_offset": 959}, {"id": 1090613, "label": "ENT", "start_offset": 992, "end_offset": 1015}], "relations": [{"id": 174222, "from_id": 1090596, "to_id": 1090597, "type": "PART-OF"}, {"id": 174223, "from_id": 1090595, "to_id": 1090597, "type": "PART-OF"}, {"id": 174224, "from_id": 1090595, "to_id": 1090596, "type": "CONJUNCTION"}, {"id": 174225, "from_id": 1090594, "to_id": 1090595, "type": "USED-FOR"}, {"id": 174226, "from_id": 1090594, "to_id": 1090596, "type": "USED-FOR"}, {"id": 174227, "from_id": 1090599, "to_id": 1090600, "type": "CONJUNCTION"}, {"id": 174228, "from_id": 1090600, "to_id": 1090601, "type": "CONJUNCTION"}, {"id": 174229, "from_id": 1090599, "to_id": 1090598, "type": "USED-FOR"}, {"id": 174230, "from_id": 1090600, "to_id": 1090598, "type": "USED-FOR"}, {"id": 174231, "from_id": 1090601, "to_id": 1090598, "type": "USED-FOR"}, {"id": 174232, "from_id": 1090602, "to_id": 1090598, "type": "COREF"}, {"id": 174233, "from_id": 1090605, "to_id": 1090604, "type": "USED-FOR"}, {"id": 174234, "from_id": 1090607, "to_id": 1090604, "type": "COREF"}, {"id": 174235, "from_id": 1090608, "to_id": 1090604, "type": "COREF"}, {"id": 174236, "from_id": 1090608, "to_id": 1090609, "type": "USED-FOR"}, {"id": 174237, "from_id": 1090610, "to_id": 1090609, "type": "EVALUATE-FOR"}, {"id": 174238, "from_id": 1090613, "to_id": 1090612, "type": "COMPARE"}, {"id": 174239, "from_id": 1090611, "to_id": 1090609, "type": "COREF"}, {"id": 174240, "from_id": 1090612, "to_id": 1090611, "type": "USED-FOR"}, {"id": 174241, "from_id": 1090609, "to_id": 1090594, "type": "COREF"}]}
{"id": "E91-1050", "text": "  Unification  is often the appropriate method for expressing  relations  between  representations  in the form of  feature structures ; however, there are circumstances in which a different approach is desirable. A  declarative formalism  is presented which permits direct  mappings  of one  feature structure  into another, and illustrative examples are given of its application to areas of current interest. ", "Comments": [], "entities": [{"id": 1090625, "label": "ENT", "start_offset": 2, "end_offset": 13}, {"id": 1090626, "label": "ENT", "start_offset": 40, "end_offset": 46}, {"id": 1090627, "label": "ENT", "start_offset": 63, "end_offset": 98}, {"id": 1090628, "label": "ENT", "start_offset": 116, "end_offset": 134}, {"id": 1090629, "label": "ENT", "start_offset": 191, "end_offset": 199}, {"id": 1090630, "label": "ENT", "start_offset": 217, "end_offset": 238}, {"id": 1090631, "label": "ENT", "start_offset": 267, "end_offset": 324}], "relations": [{"id": 174247, "from_id": 1090625, "to_id": 1090626, "type": "COREF"}, {"id": 174248, "from_id": 1090630, "to_id": 1090629, "type": "COREF"}, {"id": 174249, "from_id": 1090629, "to_id": 1090626, "type": "COMPARE"}, {"id": 174250, "from_id": 1090626, "to_id": 1090627, "type": "USED-FOR"}, {"id": 174251, "from_id": 1090631, "to_id": 1090630, "type": "FEATURE-OF"}, {"id": 174252, "from_id": 1090628, "to_id": 1090627, "type": "USED-FOR"}]}
{"id": "I05-2044", "text": " In the  Chinese language , a  verb  may have its  dependents  on its left, right or on both sides. The  ambiguity resolution  of  right-side dependencies  is essential for  dependency parsing  of  sentences  with two or more  verbs . Previous works on  shift-reduce dependency parsers  may not guarantee the  connectivity  of a  dependency tree  due to their weakness at resolving the  right-side dependencies . This paper proposes a  two-phase shift-reduce dependency parser  based on  SVM learning . The  left-side dependents  and  right-side nominal dependents  are detected in Phase I, and  right-side verbal dependents  are decided in Phase II. In experimental evaluation, our proposed method outperforms previous  shift-reduce dependency parsers  for the  Chine language , showing improvement of  dependency accuracy  by 10.08%. ", "Comments": [], "entities": [{"id": 1090698, "label": "ENT", "start_offset": 9, "end_offset": 25}, {"id": 1090699, "label": "ENT", "start_offset": 105, "end_offset": 154}, {"id": 1090700, "label": "ENT", "start_offset": 174, "end_offset": 192}, {"id": 1090701, "label": "ENT", "start_offset": 254, "end_offset": 285}, {"id": 1090702, "label": "ENT", "start_offset": 310, "end_offset": 322}, {"id": 1090703, "label": "ENT", "start_offset": 330, "end_offset": 345}, {"id": 1090704, "label": "ENT", "start_offset": 387, "end_offset": 410}, {"id": 1090705, "label": "ENT", "start_offset": 436, "end_offset": 476}, {"id": 1090706, "label": "ENT", "start_offset": 488, "end_offset": 500}, {"id": 1090707, "label": "ENT", "start_offset": 508, "end_offset": 528}, {"id": 1090708, "label": "ENT", "start_offset": 535, "end_offset": 564}, {"id": 1090709, "label": "ENT", "start_offset": 596, "end_offset": 624}, {"id": 1090710, "label": "ENT", "start_offset": 692, "end_offset": 698}, {"id": 1090711, "label": "ENT", "start_offset": 721, "end_offset": 752}, {"id": 1090712, "label": "ENT", "start_offset": 763, "end_offset": 777}, {"id": 1090713, "label": "ENT", "start_offset": 804, "end_offset": 823}], "relations": [{"id": 174303, "from_id": 1090706, "to_id": 1090705, "type": "USED-FOR"}, {"id": 174304, "from_id": 1090712, "to_id": 1090711, "type": "EVALUATE-FOR"}, {"id": 174305, "from_id": 1090707, "to_id": 1090708, "type": "CONJUNCTION"}, {"id": 174306, "from_id": 1090709, "to_id": 1090708, "type": "CONJUNCTION"}, {"id": 174307, "from_id": 1090711, "to_id": 1090701, "type": "COREF"}, {"id": 174308, "from_id": 1090713, "to_id": 1090711, "type": "EVALUATE-FOR"}, {"id": 174309, "from_id": 1090710, "to_id": 1090705, "type": "COREF"}, {"id": 174310, "from_id": 1090710, "to_id": 1090711, "type": "COMPARE"}, {"id": 174311, "from_id": 1090712, "to_id": 1090710, "type": "EVALUATE-FOR"}, {"id": 174312, "from_id": 1090712, "to_id": 1090698, "type": "COREF"}, {"id": 174313, "from_id": 1090713, "to_id": 1090710, "type": "EVALUATE-FOR"}, {"id": 174314, "from_id": 1090702, "to_id": 1090703, "type": "EVALUATE-FOR"}, {"id": 174315, "from_id": 1090699, "to_id": 1090700, "type": "USED-FOR"}]}
{"id": "P05-1073", "text": " Despite much recent progress on accurate  semantic role labeling , previous work has largely used  independent classifiers , possibly combined with separate  label sequence models  via  Viterbi decoding . This stands in stark contrast to the linguistic observation that a  core argument frame  is a joint structure, with strong  dependencies  between  arguments . We show how to build a  joint model  of  argument frames , incorporating novel  features  that model these interactions into  discriminative log-linear models . This system achieves an  error reduction  of 22% on all  arguments  and 32% on  core arguments  over a state-of-the art independent  classifier  for  gold-standard parse trees  on  PropBank . ", "Comments": [], "entities": [{"id": 1090792, "label": "ENT", "start_offset": 43, "end_offset": 65}, {"id": 1090793, "label": "ENT", "start_offset": 100, "end_offset": 123}, {"id": 1090794, "label": "ENT", "start_offset": 159, "end_offset": 180}, {"id": 1090795, "label": "ENT", "start_offset": 187, "end_offset": 203}, {"id": 1090796, "label": "ENT", "start_offset": 274, "end_offset": 293}, {"id": 1090797, "label": "ENT", "start_offset": 389, "end_offset": 421}, {"id": 1090798, "label": "ENT", "start_offset": 445, "end_offset": 453}, {"id": 1090799, "label": "ENT", "start_offset": 491, "end_offset": 523}, {"id": 1090800, "label": "ENT", "start_offset": 531, "end_offset": 537}, {"id": 1090801, "label": "ENT", "start_offset": 551, "end_offset": 566}, {"id": 1090802, "label": "ENT", "start_offset": 646, "end_offset": 669}, {"id": 1090803, "label": "ENT", "start_offset": 676, "end_offset": 701}, {"id": 1090804, "label": "ENT", "start_offset": 707, "end_offset": 715}], "relations": [{"id": 174368, "from_id": 1090793, "to_id": 1090792, "type": "USED-FOR"}, {"id": 174369, "from_id": 1090798, "to_id": 1090799, "type": "PART-OF"}, {"id": 174370, "from_id": 1090793, "to_id": 1090794, "type": "CONJUNCTION"}, {"id": 174371, "from_id": 1090797, "to_id": 1090800, "type": "COREF"}, {"id": 174372, "from_id": 1090802, "to_id": 1090800, "type": "COMPARE"}, {"id": 174373, "from_id": 1090803, "to_id": 1090804, "type": "PART-OF"}, {"id": 174374, "from_id": 1090793, "to_id": 1090802, "type": "COREF"}, {"id": 174375, "from_id": 1090801, "to_id": 1090800, "type": "EVALUATE-FOR"}, {"id": 174376, "from_id": 1090801, "to_id": 1090802, "type": "EVALUATE-FOR"}, {"id": 174377, "from_id": 1090795, "to_id": 1090794, "type": "USED-FOR"}, {"id": 174378, "from_id": 1090803, "to_id": 1090802, "type": "EVALUATE-FOR"}, {"id": 174379, "from_id": 1090803, "to_id": 1090800, "type": "EVALUATE-FOR"}]}
{"id": "CVPR_2008_100_abs", "text": "Structured-light methods actively generate geometric correspondence data between projectors and cameras in order to facilitate robust 3D reconstruction. In this paper, we present Photogeometric Structured Light whereby a standard structured light method is extended to include photometric methods. Photometric processing serves the double purpose of increasing the amount of recovered surface detail and of enabling the structured-light setup to be robustly self-calibrated. Further, our framework uses a photogeometric optimization that supports the simultaneous use of multiple cameras and projectors and yields a single and accurate multi-view 3D model which best complies with photometric and geometric data.", "Comments": [], "entities": [{"id": 1090847, "label": "ENT", "start_offset": 0, "end_offset": 24}, {"id": 1090848, "label": "ENT", "start_offset": 43, "end_offset": 72}, {"id": 1090849, "label": "ENT", "start_offset": 127, "end_offset": 151}, {"id": 1090850, "label": "ENT", "start_offset": 179, "end_offset": 210}, {"id": 1090851, "label": "ENT", "start_offset": 230, "end_offset": 253}, {"id": 1090852, "label": "ENT", "start_offset": 277, "end_offset": 296}, {"id": 1090853, "label": "ENT", "start_offset": 298, "end_offset": 320}, {"id": 1090854, "label": "ENT", "start_offset": 375, "end_offset": 399}, {"id": 1090855, "label": "ENT", "start_offset": 420, "end_offset": 442}, {"id": 1090856, "label": "ENT", "start_offset": 488, "end_offset": 497}, {"id": 1090857, "label": "ENT", "start_offset": 505, "end_offset": 532}, {"id": 1090858, "label": "ENT", "start_offset": 636, "end_offset": 655}, {"id": 1090859, "label": "ENT", "start_offset": 681, "end_offset": 711}], "relations": [{"id": 174420, "from_id": 1090848, "to_id": 1090849, "type": "USED-FOR"}, {"id": 174421, "from_id": 1090847, "to_id": 1090848, "type": "USED-FOR"}, {"id": 174422, "from_id": 1090853, "to_id": 1090852, "type": "COREF"}, {"id": 174423, "from_id": 1090853, "to_id": 1090854, "type": "USED-FOR"}, {"id": 174424, "from_id": 1090853, "to_id": 1090855, "type": "USED-FOR"}, {"id": 174425, "from_id": 1090856, "to_id": 1090850, "type": "COREF"}, {"id": 174426, "from_id": 1090857, "to_id": 1090856, "type": "USED-FOR"}, {"id": 174427, "from_id": 1090851, "to_id": 1090850, "type": "PART-OF"}, {"id": 174428, "from_id": 1090852, "to_id": 1090850, "type": "PART-OF"}, {"id": 174429, "from_id": 1090859, "to_id": 1090858, "type": "USED-FOR"}]}
{"id": "INTERSPEECH_2014_20_abs", "text": "In this paper, we explore multilingual feature-level data sharing via Deep Neural Network (DNN) stacked bottleneck features. Given a set of available source languages, we apply language identification to pick the language most similar to the target language , for more efficient use of multilingual resources. Our experiments with IARPA-Babel languages show that bottleneck features trained on the most similar source language perform better than those trained on all available source languages. Further analysis suggests that only data similar to the target language is useful for multilingual training.", "Comments": [], "entities": [{"id": 1090947, "label": "ENT", "start_offset": 26, "end_offset": 65}, {"id": 1090948, "label": "ENT", "start_offset": 70, "end_offset": 123}, {"id": 1090949, "label": "ENT", "start_offset": 177, "end_offset": 200}, {"id": 1090950, "label": "ENT", "start_offset": 286, "end_offset": 308}, {"id": 1090951, "label": "ENT", "start_offset": 331, "end_offset": 352}, {"id": 1090952, "label": "ENT", "start_offset": 363, "end_offset": 382}, {"id": 1090953, "label": "ENT", "start_offset": 447, "end_offset": 452}, {"id": 1090954, "label": "ENT", "start_offset": 532, "end_offset": 536}, {"id": 1090955, "label": "ENT", "start_offset": 582, "end_offset": 603}], "relations": [{"id": 174500, "from_id": 1090948, "to_id": 1090947, "type": "USED-FOR"}, {"id": 174501, "from_id": 1090949, "to_id": 1090950, "type": "USED-FOR"}, {"id": 174502, "from_id": 1090953, "to_id": 1090952, "type": "COMPARE"}, {"id": 174503, "from_id": 1090954, "to_id": 1090955, "type": "USED-FOR"}]}
{"id": "P86-1011", "text": "   We examine the relationship between the two  grammatical formalisms  :  Tree Adjoining Grammars  and  Head Grammars  . We briefly investigate the weak  equivalence  of the two  formalisms  . We then turn to a discussion comparing the  linguistic expressiveness  of the two  formalisms  . ", "Comments": [], "entities": [{"id": 1090956, "label": "ENT", "start_offset": 48, "end_offset": 70}, {"id": 1090957, "label": "ENT", "start_offset": 75, "end_offset": 98}, {"id": 1090958, "label": "ENT", "start_offset": 105, "end_offset": 118}, {"id": 1090959, "label": "ENT", "start_offset": 180, "end_offset": 190}, {"id": 1090960, "label": "ENT", "start_offset": 238, "end_offset": 263}, {"id": 1090961, "label": "ENT", "start_offset": 277, "end_offset": 287}], "relations": [{"id": 174504, "from_id": 1090957, "to_id": 1090958, "type": "COMPARE"}, {"id": 174505, "from_id": 1090960, "to_id": 1090961, "type": "FEATURE-OF"}, {"id": 174506, "from_id": 1090957, "to_id": 1090956, "type": "HYPONYM-OF"}, {"id": 174507, "from_id": 1090958, "to_id": 1090956, "type": "HYPONYM-OF"}, {"id": 174508, "from_id": 1090956, "to_id": 1090959, "type": "COREF"}, {"id": 174509, "from_id": 1090959, "to_id": 1090961, "type": "COREF"}]}
{"id": "CVPR_1996_15_abs", "text": "We previously presented a framework for segmentation of complex scenes using multiple physical hypotheses for simple image regions. A consequence of that framework was a proposal for a new approach to the segmentation of complex scenes into regions corresponding to coherent surfaces rather than merely regions of similar color. Herein we present an implementation of this new approach and show example segmentations for scenes containing multi-colored piece-wise uniform objects. Using our approach we are able to intelligently segment scenes with objects of greater complexity than previous physics-based segmentation algorithms. The results show that by using general physical models we obtain segmentations that correspond more closely to coherent surfaces in the scene than segmentations found using only color.", "Comments": [], "entities": [{"id": 1090962, "label": "ENT", "start_offset": 26, "end_offset": 35}, {"id": 1090963, "label": "ENT", "start_offset": 40, "end_offset": 70}, {"id": 1090964, "label": "ENT", "start_offset": 86, "end_offset": 105}, {"id": 1090965, "label": "ENT", "start_offset": 110, "end_offset": 130}, {"id": 1090966, "label": "ENT", "start_offset": 154, "end_offset": 163}, {"id": 1090967, "label": "ENT", "start_offset": 189, "end_offset": 197}, {"id": 1090968, "label": "ENT", "start_offset": 205, "end_offset": 235}, {"id": 1090969, "label": "ENT", "start_offset": 266, "end_offset": 283}, {"id": 1090970, "label": "ENT", "start_offset": 303, "end_offset": 327}, {"id": 1090971, "label": "ENT", "start_offset": 377, "end_offset": 385}, {"id": 1090972, "label": "ENT", "start_offset": 403, "end_offset": 416}, {"id": 1090973, "label": "ENT", "start_offset": 421, "end_offset": 427}, {"id": 1090974, "label": "ENT", "start_offset": 439, "end_offset": 479}, {"id": 1090975, "label": "ENT", "start_offset": 491, "end_offset": 499}, {"id": 1090976, "label": "ENT", "start_offset": 568, "end_offset": 578}, {"id": 1090977, "label": "ENT", "start_offset": 593, "end_offset": 630}, {"id": 1090978, "label": "ENT", "start_offset": 671, "end_offset": 686}, {"id": 1090979, "label": "ENT", "start_offset": 743, "end_offset": 760}], "relations": [{"id": 174510, "from_id": 1090964, "to_id": 1090965, "type": "USED-FOR"}, {"id": 174511, "from_id": 1090962, "to_id": 1090963, "type": "USED-FOR"}, {"id": 174512, "from_id": 1090964, "to_id": 1090962, "type": "USED-FOR"}, {"id": 174513, "from_id": 1090966, "to_id": 1090962, "type": "COREF"}, {"id": 174514, "from_id": 1090968, "to_id": 1090963, "type": "COREF"}, {"id": 174515, "from_id": 1090966, "to_id": 1090967, "type": "USED-FOR"}, {"id": 174516, "from_id": 1090967, "to_id": 1090968, "type": "USED-FOR"}, {"id": 174517, "from_id": 1090969, "to_id": 1090970, "type": "COMPARE"}, {"id": 174518, "from_id": 1090971, "to_id": 1090967, "type": "COREF"}, {"id": 174519, "from_id": 1090974, "to_id": 1090973, "type": "FEATURE-OF"}, {"id": 174520, "from_id": 1090972, "to_id": 1090973, "type": "USED-FOR"}, {"id": 174521, "from_id": 1090975, "to_id": 1090971, "type": "COREF"}, {"id": 174522, "from_id": 1090975, "to_id": 1090977, "type": "COMPARE"}]}
{"id": "C04-1106", "text": " The reality of  analogies between words  is refuted by noone (e.g., I walked is to to walk as I laughed is to to laugh, noted I walked : to walk :: I laughed : to laugh). But  computational linguists  seem to be quite dubious about  analogies between sentences  : they would not be enough numerous to be of any use. We report experiments conducted on a  multilingual corpus  to estimate the number of  analogies  among the  sentences  that it contains. We give two estimates, a lower one and a higher one. As an  analogy  must be valid on the level of  form  as well as on the level of  meaning  , we relied on the idea that  translation  should preserve  meaning  to test for similar  meanings  . ", "Comments": [], "entities": [{"id": 1091087, "label": "ENT", "start_offset": 17, "end_offset": 40}, {"id": 1091088, "label": "ENT", "start_offset": 234, "end_offset": 261}, {"id": 1091089, "label": "ENT", "start_offset": 355, "end_offset": 374}, {"id": 1091090, "label": "ENT", "start_offset": 403, "end_offset": 412}, {"id": 1091091, "label": "ENT", "start_offset": 514, "end_offset": 521}], "relations": [{"id": 174615, "from_id": 1091089, "to_id": 1091090, "type": "EVALUATE-FOR"}]}
{"id": "P06-4007", "text": "   This paper describes  FERRET  , an  interactive question-answering (Q/A) system  designed to address the challenges of integrating  automatic Q/A  applications into real-world environments.  FERRET  utilizes a novel approach to  Q/A  known as  predictive questioning  which attempts to identify the  questions  (and  answers  ) that  users  need by analyzing how a  user  interacts with a system while gathering information related to a particular scenario. ", "Comments": [], "entities": [{"id": 1091161, "label": "ENT", "start_offset": 25, "end_offset": 31}, {"id": 1091162, "label": "ENT", "start_offset": 39, "end_offset": 82}, {"id": 1091163, "label": "ENT", "start_offset": 122, "end_offset": 191}, {"id": 1091164, "label": "ENT", "start_offset": 194, "end_offset": 200}, {"id": 1091165, "label": "ENT", "start_offset": 219, "end_offset": 227}, {"id": 1091166, "label": "ENT", "start_offset": 232, "end_offset": 235}, {"id": 1091167, "label": "ENT", "start_offset": 247, "end_offset": 269}], "relations": [{"id": 174681, "from_id": 1091161, "to_id": 1091162, "type": "HYPONYM-OF"}, {"id": 174682, "from_id": 1091164, "to_id": 1091161, "type": "COREF"}, {"id": 174683, "from_id": 1091165, "to_id": 1091166, "type": "USED-FOR"}, {"id": 174684, "from_id": 1091165, "to_id": 1091164, "type": "USED-FOR"}, {"id": 174685, "from_id": 1091167, "to_id": 1091165, "type": "COREF"}, {"id": 174686, "from_id": 1091162, "to_id": 1091166, "type": "COREF"}, {"id": 174687, "from_id": 1091161, "to_id": 1091163, "type": "USED-FOR"}]}
{"id": "H01-1058", "text": " In this paper, we address the problem of combining several  language models (LMs)  . We find that simple  interpolation methods  , like  log-linear and linear interpolation  , improve the  performance  but fall short of the  performance  of an  oracle  . The  oracle  knows the  reference word string  and selects the  word string  with the best  performance  (typically,  word or semantic error rate  ) from a list of  word strings  , where each  word string  has been obtained by using a different  LM  . Actually, the  oracle  acts like a  dynamic combiner  with  hard decisions  using the  reference  . We provide experimental results that clearly show the need for a  dynamic language model combination  to improve the  performance  further . We suggest a method that mimics the behavior of the  oracle  using a  neural network  or a  decision tree  . The method amounts to tagging  LMs  with  confidence measures  and picking the best  hypothesis  corresponding to the  LM  with the best  confidence  . ", "Comments": [], "entities": [{"id": 1091168, "label": "ENT", "start_offset": 61, "end_offset": 82}, {"id": 1091169, "label": "ENT", "start_offset": 107, "end_offset": 128}, {"id": 1091170, "label": "ENT", "start_offset": 138, "end_offset": 173}, {"id": 1091171, "label": "ENT", "start_offset": 374, "end_offset": 401}, {"id": 1091172, "label": "ENT", "start_offset": 502, "end_offset": 504}, {"id": 1091173, "label": "ENT", "start_offset": 544, "end_offset": 560}, {"id": 1091174, "label": "ENT", "start_offset": 568, "end_offset": 582}, {"id": 1091175, "label": "ENT", "start_offset": 674, "end_offset": 708}, {"id": 1091176, "label": "ENT", "start_offset": 762, "end_offset": 768}, {"id": 1091177, "label": "ENT", "start_offset": 819, "end_offset": 833}, {"id": 1091178, "label": "ENT", "start_offset": 841, "end_offset": 854}, {"id": 1091179, "label": "ENT", "start_offset": 862, "end_offset": 868}, {"id": 1091180, "label": "ENT", "start_offset": 889, "end_offset": 892}, {"id": 1091181, "label": "ENT", "start_offset": 900, "end_offset": 919}, {"id": 1091182, "label": "ENT", "start_offset": 977, "end_offset": 979}], "relations": [{"id": 174688, "from_id": 1091170, "to_id": 1091169, "type": "HYPONYM-OF"}, {"id": 174689, "from_id": 1091175, "to_id": 1091173, "type": "COREF"}, {"id": 174690, "from_id": 1091177, "to_id": 1091176, "type": "USED-FOR"}, {"id": 174691, "from_id": 1091178, "to_id": 1091176, "type": "USED-FOR"}, {"id": 174692, "from_id": 1091178, "to_id": 1091177, "type": "CONJUNCTION"}, {"id": 174693, "from_id": 1091179, "to_id": 1091176, "type": "COREF"}, {"id": 174694, "from_id": 1091179, "to_id": 1091180, "type": "USED-FOR"}, {"id": 174695, "from_id": 1091182, "to_id": 1091180, "type": "COREF"}, {"id": 174696, "from_id": 1091174, "to_id": 1091173, "type": "FEATURE-OF"}, {"id": 174697, "from_id": 1091181, "to_id": 1091179, "type": "USED-FOR"}]}
{"id": "E89-1006", "text": " A proposal to deal with  French tenses  in the framework of  Discourse Representation Theory  is presented, as it has been implemented for a fragment at the  IMS . It is based on the  theory of tenses  of H. Kamp and Ch. Rohrer. Instead of using  operators  to express the  meaning  of the  tenses  the Reichenbachian point of view is adopted and refined such that the impact of the  tenses  with respect to the  meaning  of the  text  is understood as contribution to the integration of the  events  of a  sentence  in the  event structure  of the preceeding  text . Thereby a  system of relevant times  provided by the preceeding  text  and by the  temporal adverbials  of the  sentence  being processed is used. This system consists of one or more  reference times  and  temporal perspective times , the  speech time  and the  location time . The special interest of our proposal is to establish a plausible choice of anchors for the  new event  out of the  system of relevant times  and to update this  system of temporal coordinates  correctly. The problem of choice is largely neglected in the literature. In opposition to the approach of Kamp and Rohrer the exact  meaning  of the  tenses  is fixed by the  resolution component  and not in the process of  syntactic analysis . ", "Comments": [], "entities": [{"id": 1091357, "label": "ENT", "start_offset": 3, "end_offset": 11}, {"id": 1091358, "label": "ENT", "start_offset": 26, "end_offset": 39}, {"id": 1091359, "label": "ENT", "start_offset": 62, "end_offset": 93}, {"id": 1091360, "label": "ENT", "start_offset": 112, "end_offset": 114}, {"id": 1091361, "label": "ENT", "start_offset": 159, "end_offset": 162}, {"id": 1091362, "label": "ENT", "start_offset": 165, "end_offset": 167}, {"id": 1091363, "label": "ENT", "start_offset": 185, "end_offset": 201}, {"id": 1091364, "label": "ENT", "start_offset": 248, "end_offset": 257}, {"id": 1091365, "label": "ENT", "start_offset": 275, "end_offset": 298}, {"id": 1091366, "label": "ENT", "start_offset": 526, "end_offset": 541}, {"id": 1091367, "label": "ENT", "start_offset": 580, "end_offset": 604}, {"id": 1091368, "label": "ENT", "start_offset": 622, "end_offset": 638}, {"id": 1091369, "label": "ENT", "start_offset": 652, "end_offset": 671}, {"id": 1091370, "label": "ENT", "start_offset": 721, "end_offset": 727}, {"id": 1091371, "label": "ENT", "start_offset": 753, "end_offset": 768}, {"id": 1091372, "label": "ENT", "start_offset": 775, "end_offset": 801}, {"id": 1091373, "label": "ENT", "start_offset": 809, "end_offset": 820}, {"id": 1091374, "label": "ENT", "start_offset": 831, "end_offset": 844}, {"id": 1091375, "label": "ENT", "start_offset": 962, "end_offset": 986}, {"id": 1091376, "label": "ENT", "start_offset": 1008, "end_offset": 1038}, {"id": 1091377, "label": "ENT", "start_offset": 1173, "end_offset": 1196}, {"id": 1091378, "label": "ENT", "start_offset": 1215, "end_offset": 1235}, {"id": 1091379, "label": "ENT", "start_offset": 1264, "end_offset": 1282}], "relations": [{"id": 174828, "from_id": 1091378, "to_id": 1091379, "type": "COMPARE"}, {"id": 174829, "from_id": 1091359, "to_id": 1091358, "type": "USED-FOR"}, {"id": 174830, "from_id": 1091368, "to_id": 1091369, "type": "CONJUNCTION"}, {"id": 174831, "from_id": 1091368, "to_id": 1091367, "type": "USED-FOR"}, {"id": 174832, "from_id": 1091370, "to_id": 1091367, "type": "COREF"}, {"id": 174833, "from_id": 1091371, "to_id": 1091370, "type": "PART-OF"}, {"id": 174834, "from_id": 1091372, "to_id": 1091370, "type": "PART-OF"}, {"id": 174835, "from_id": 1091371, "to_id": 1091372, "type": "CONJUNCTION"}, {"id": 174836, "from_id": 1091373, "to_id": 1091370, "type": "PART-OF"}, {"id": 174837, "from_id": 1091374, "to_id": 1091370, "type": "PART-OF"}, {"id": 174838, "from_id": 1091372, "to_id": 1091373, "type": "CONJUNCTION"}, {"id": 174839, "from_id": 1091373, "to_id": 1091374, "type": "CONJUNCTION"}, {"id": 174840, "from_id": 1091375, "to_id": 1091370, "type": "COREF"}, {"id": 174841, "from_id": 1091376, "to_id": 1091375, "type": "COREF"}, {"id": 174842, "from_id": 1091360, "to_id": 1091357, "type": "COREF"}, {"id": 174843, "from_id": 1091360, "to_id": 1091361, "type": "USED-FOR"}, {"id": 174844, "from_id": 1091360, "to_id": 1091362, "type": "COREF"}, {"id": 174845, "from_id": 1091363, "to_id": 1091362, "type": "USED-FOR"}, {"id": 174846, "from_id": 1091364, "to_id": 1091365, "type": "USED-FOR"}, {"id": 174847, "from_id": 1091369, "to_id": 1091367, "type": "USED-FOR"}, {"id": 174848, "from_id": 1091378, "to_id": 1091377, "type": "USED-FOR"}]}
{"id": "N03-1001", "text": " This paper describes a method for  utterance classification  that does not require  manual transcription  of  training data  . The method combines  domain independent acoustic models  with off-the-shelf  classifiers  to give  utterance classification performance  that is surprisingly close to what can be achieved using conventional  word-trigram recognition  requiring  manual transcription  . In our method,  unsupervised training  is first used to train a  phone n-gram model  for a particular  domain  ; the  output  of  recognition  with this  model  is then passed to a  phone-string classifier  . The  classification accuracy  of the method is evaluated on three different  spoken language system domains  . ", "Comments": [], "entities": [{"id": 1091380, "label": "ENT", "start_offset": 24, "end_offset": 30}, {"id": 1091381, "label": "ENT", "start_offset": 36, "end_offset": 60}, {"id": 1091382, "label": "ENT", "start_offset": 85, "end_offset": 105}, {"id": 1091383, "label": "ENT", "start_offset": 132, "end_offset": 138}, {"id": 1091384, "label": "ENT", "start_offset": 149, "end_offset": 183}, {"id": 1091385, "label": "ENT", "start_offset": 205, "end_offset": 216}, {"id": 1091386, "label": "ENT", "start_offset": 227, "end_offset": 251}, {"id": 1091387, "label": "ENT", "start_offset": 336, "end_offset": 360}, {"id": 1091388, "label": "ENT", "start_offset": 373, "end_offset": 393}, {"id": 1091389, "label": "ENT", "start_offset": 404, "end_offset": 410}, {"id": 1091390, "label": "ENT", "start_offset": 413, "end_offset": 434}, {"id": 1091391, "label": "ENT", "start_offset": 462, "end_offset": 480}, {"id": 1091392, "label": "ENT", "start_offset": 500, "end_offset": 506}, {"id": 1091393, "label": "ENT", "start_offset": 551, "end_offset": 556}, {"id": 1091394, "label": "ENT", "start_offset": 579, "end_offset": 602}, {"id": 1091395, "label": "ENT", "start_offset": 611, "end_offset": 634}, {"id": 1091396, "label": "ENT", "start_offset": 643, "end_offset": 649}, {"id": 1091397, "label": "ENT", "start_offset": 683, "end_offset": 713}], "relations": [{"id": 174849, "from_id": 1091388, "to_id": 1091387, "type": "USED-FOR"}, {"id": 174850, "from_id": 1091390, "to_id": 1091391, "type": "USED-FOR"}, {"id": 174851, "from_id": 1091380, "to_id": 1091381, "type": "USED-FOR"}, {"id": 174852, "from_id": 1091383, "to_id": 1091380, "type": "COREF"}, {"id": 174853, "from_id": 1091384, "to_id": 1091383, "type": "PART-OF"}, {"id": 174854, "from_id": 1091385, "to_id": 1091384, "type": "CONJUNCTION"}, {"id": 174855, "from_id": 1091387, "to_id": 1091383, "type": "USED-FOR"}, {"id": 174856, "from_id": 1091389, "to_id": 1091383, "type": "COREF"}, {"id": 174857, "from_id": 1091390, "to_id": 1091389, "type": "PART-OF"}, {"id": 174858, "from_id": 1091390, "to_id": 1091392, "type": "USED-FOR"}, {"id": 174859, "from_id": 1091393, "to_id": 1091391, "type": "COREF"}, {"id": 174860, "from_id": 1091396, "to_id": 1091389, "type": "COREF"}, {"id": 174861, "from_id": 1091397, "to_id": 1091396, "type": "EVALUATE-FOR"}, {"id": 174862, "from_id": 1091395, "to_id": 1091396, "type": "EVALUATE-FOR"}, {"id": 174863, "from_id": 1091383, "to_id": 1091386, "type": "USED-FOR"}, {"id": 174864, "from_id": 1091386, "to_id": 1091381, "type": "COREF"}, {"id": 174865, "from_id": 1091385, "to_id": 1091383, "type": "PART-OF"}]}
{"id": "C90-3007", "text": " This paper examines the properties of  feature-based partial descriptions  built on top of  Halliday's systemic networks . We show that the crucial operation of  consistency checking  for such descriptions is NP-complete, and therefore probably intractable, but proceed to develop  algorithms  which can sometimes alleviate the unpleasant consequences of this  intractability . ", "Comments": [], "entities": [{"id": 1091398, "label": "ENT", "start_offset": 40, "end_offset": 74}, {"id": 1091399, "label": "ENT", "start_offset": 93, "end_offset": 121}, {"id": 1091400, "label": "ENT", "start_offset": 163, "end_offset": 183}, {"id": 1091401, "label": "ENT", "start_offset": 194, "end_offset": 206}], "relations": [{"id": 174866, "from_id": 1091401, "to_id": 1091398, "type": "COREF"}, {"id": 174867, "from_id": 1091400, "to_id": 1091401, "type": "USED-FOR"}, {"id": 174868, "from_id": 1091399, "to_id": 1091398, "type": "USED-FOR"}]}
{"id": "AAAI_2015_10_abs", "text": "Machine reading is a relatively new field that features computer programs designed to read flowing text and extract fact assertions expressed by the narrative content. This task involves two core technologies: natural language processing (NLP) and information extraction (IE). In this paper we describe a machine reading system that we have developed within a cognitive architecture. We show how we have integrated into the framework several levels of knowledge for a particular domain , ideas from cognitive semantics and construction grammar, plus tools from prior NLP and IE research. The result is a system that is capable of reading and interpreting complex and fairly idiosyncratic texts in the family history domain. We describe the architecture and performance of the system. After presenting the results from several evaluations that we have carried out, we summarize possible future directions.", "Comments": [], "entities": [{"id": 1091402, "label": "ENT", "start_offset": 0, "end_offset": 15}, {"id": 1091403, "label": "ENT", "start_offset": 36, "end_offset": 41}, {"id": 1091404, "label": "ENT", "start_offset": 56, "end_offset": 73}, {"id": 1091405, "label": "ENT", "start_offset": 91, "end_offset": 103}, {"id": 1091406, "label": "ENT", "start_offset": 116, "end_offset": 131}, {"id": 1091407, "label": "ENT", "start_offset": 149, "end_offset": 166}, {"id": 1091408, "label": "ENT", "start_offset": 173, "end_offset": 177}, {"id": 1091409, "label": "ENT", "start_offset": 210, "end_offset": 243}, {"id": 1091410, "label": "ENT", "start_offset": 248, "end_offset": 275}, {"id": 1091411, "label": "ENT", "start_offset": 305, "end_offset": 327}, {"id": 1091412, "label": "ENT", "start_offset": 360, "end_offset": 382}, {"id": 1091413, "label": "ENT", "start_offset": 499, "end_offset": 518}, {"id": 1091414, "label": "ENT", "start_offset": 523, "end_offset": 543}, {"id": 1091415, "label": "ENT", "start_offset": 561, "end_offset": 570}, {"id": 1091416, "label": "ENT", "start_offset": 575, "end_offset": 586}, {"id": 1091417, "label": "ENT", "start_offset": 604, "end_offset": 610}, {"id": 1091418, "label": "ENT", "start_offset": 674, "end_offset": 693}, {"id": 1091419, "label": "ENT", "start_offset": 701, "end_offset": 722}, {"id": 1091420, "label": "ENT", "start_offset": 776, "end_offset": 782}], "relations": [{"id": 174869, "from_id": 1091402, "to_id": 1091403, "type": "COREF"}, {"id": 174870, "from_id": 1091404, "to_id": 1091405, "type": "USED-FOR"}, {"id": 174871, "from_id": 1091404, "to_id": 1091406, "type": "USED-FOR"}, {"id": 174872, "from_id": 1091406, "to_id": 1091407, "type": "FEATURE-OF"}, {"id": 174873, "from_id": 1091408, "to_id": 1091402, "type": "COREF"}, {"id": 174874, "from_id": 1091409, "to_id": 1091408, "type": "PART-OF"}, {"id": 174875, "from_id": 1091410, "to_id": 1091408, "type": "PART-OF"}, {"id": 174876, "from_id": 1091412, "to_id": 1091411, "type": "FEATURE-OF"}, {"id": 174877, "from_id": 1091413, "to_id": 1091414, "type": "CONJUNCTION"}, {"id": 174878, "from_id": 1091415, "to_id": 1091416, "type": "CONJUNCTION"}, {"id": 174879, "from_id": 1091419, "to_id": 1091418, "type": "FEATURE-OF"}, {"id": 174880, "from_id": 1091417, "to_id": 1091411, "type": "COREF"}, {"id": 174881, "from_id": 1091417, "to_id": 1091418, "type": "USED-FOR"}, {"id": 174882, "from_id": 1091420, "to_id": 1091417, "type": "COREF"}]}
{"id": "N06-1037", "text": " This paper proposes to use a  convolution kernel  over  parse trees  to model  syntactic structure information  for  relation extraction . Our study reveals that the  syntactic structure features  embedded in a  parse tree  are very effective for  relation extraction  and these features can be well captured by the  convolution tree kernel . Evaluation on the  ACE 2003 corpus  shows that the  convolution kernel  over  parse trees  can achieve comparable performance with the previous best-reported feature-based methods on the 24  ACE relation subtypes . It also shows that our method significantly outperforms the previous two  dependency tree kernels  on the 5  ACE relation major types . ", "Comments": [], "entities": [{"id": 1091427, "label": "ENT", "start_offset": 31, "end_offset": 68}, {"id": 1091428, "label": "ENT", "start_offset": 80, "end_offset": 111}, {"id": 1091429, "label": "ENT", "start_offset": 118, "end_offset": 137}, {"id": 1091430, "label": "ENT", "start_offset": 168, "end_offset": 196}, {"id": 1091431, "label": "ENT", "start_offset": 213, "end_offset": 223}, {"id": 1091432, "label": "ENT", "start_offset": 249, "end_offset": 268}, {"id": 1091433, "label": "ENT", "start_offset": 280, "end_offset": 288}, {"id": 1091434, "label": "ENT", "start_offset": 318, "end_offset": 341}, {"id": 1091435, "label": "ENT", "start_offset": 363, "end_offset": 378}, {"id": 1091436, "label": "ENT", "start_offset": 396, "end_offset": 433}, {"id": 1091437, "label": "ENT", "start_offset": 502, "end_offset": 523}, {"id": 1091438, "label": "ENT", "start_offset": 582, "end_offset": 588}, {"id": 1091439, "label": "ENT", "start_offset": 633, "end_offset": 656}], "relations": [{"id": 174886, "from_id": 1091430, "to_id": 1091431, "type": "FEATURE-OF"}, {"id": 174887, "from_id": 1091428, "to_id": 1091429, "type": "USED-FOR"}, {"id": 174888, "from_id": 1091430, "to_id": 1091432, "type": "USED-FOR"}, {"id": 174889, "from_id": 1091433, "to_id": 1091430, "type": "COREF"}, {"id": 174890, "from_id": 1091434, "to_id": 1091433, "type": "USED-FOR"}, {"id": 174891, "from_id": 1091438, "to_id": 1091439, "type": "COMPARE"}, {"id": 174892, "from_id": 1091427, "to_id": 1091428, "type": "USED-FOR"}, {"id": 174893, "from_id": 1091427, "to_id": 1091434, "type": "COREF"}, {"id": 174894, "from_id": 1091435, "to_id": 1091436, "type": "EVALUATE-FOR"}, {"id": 174895, "from_id": 1091438, "to_id": 1091436, "type": "COREF"}, {"id": 174896, "from_id": 1091436, "to_id": 1091434, "type": "COREF"}, {"id": 174897, "from_id": 1091437, "to_id": 1091436, "type": "COMPARE"}]}
{"id": "P01-1047", "text": " We provide a  logical definition  of  Minimalist grammars  , that are  Stabler's formalization  of  Chomsky's minimalist program  . Our  logical definition  leads to a neat relation to  categorial grammar  , (yielding a treatment of  Montague semantics  ), a  parsing-as-deduction  in a  resource sensitive logic  , and a  learning algorithm  from  structured data  (based on a  typing-algorithm  and  type-unification  ). Here we emphasize the connection to  Montague semantics  which can be viewed as a  formal computation  of the  logical form  . ", "Comments": [], "entities": [{"id": 1091479, "label": "ENT", "start_offset": 15, "end_offset": 58}, {"id": 1091480, "label": "ENT", "start_offset": 72, "end_offset": 129}, {"id": 1091481, "label": "ENT", "start_offset": 138, "end_offset": 156}, {"id": 1091482, "label": "ENT", "start_offset": 187, "end_offset": 205}, {"id": 1091483, "label": "ENT", "start_offset": 235, "end_offset": 253}, {"id": 1091484, "label": "ENT", "start_offset": 261, "end_offset": 281}, {"id": 1091485, "label": "ENT", "start_offset": 289, "end_offset": 313}, {"id": 1091486, "label": "ENT", "start_offset": 324, "end_offset": 342}, {"id": 1091487, "label": "ENT", "start_offset": 350, "end_offset": 365}, {"id": 1091488, "label": "ENT", "start_offset": 380, "end_offset": 396}, {"id": 1091489, "label": "ENT", "start_offset": 403, "end_offset": 419}, {"id": 1091490, "label": "ENT", "start_offset": 461, "end_offset": 479}, {"id": 1091491, "label": "ENT", "start_offset": 507, "end_offset": 547}], "relations": [{"id": 174916, "from_id": 1091487, "to_id": 1091486, "type": "USED-FOR"}, {"id": 174917, "from_id": 1091479, "to_id": 1091481, "type": "COREF"}, {"id": 174918, "from_id": 1091488, "to_id": 1091486, "type": "USED-FOR"}, {"id": 174919, "from_id": 1091489, "to_id": 1091486, "type": "USED-FOR"}, {"id": 174920, "from_id": 1091488, "to_id": 1091489, "type": "CONJUNCTION"}, {"id": 174921, "from_id": 1091480, "to_id": 1091479, "type": "HYPONYM-OF"}, {"id": 174922, "from_id": 1091481, "to_id": 1091483, "type": "USED-FOR"}, {"id": 174923, "from_id": 1091484, "to_id": 1091485, "type": "USED-FOR"}]}
{"id": "L08-1110", "text": " We describe a set of experiments to explore  statistical techniques  for ranking and selecting the best  translations  in a  graph  of  translation hypotheses . In a previous paper (Carl, 2007) we have described how the  hypotheses graph  is generated through  shallow mapping  and  permutation rules . We have given examples of its  nodes  consisting of  vectors representing morpho-syntactic properties  of  words  and  phrases . This paper describes a number of methods for elaborating  statistical feature functions  from some of the  vector components . The  feature functions  are trained off-line on different types of  text  and their  log-linear combination  is then used to retrieve the best M  translation paths  in the  graph . We compare two  language modelling toolkits , the  CMU  and the  SRI toolkit  and arrive at three results: 1)  word-lemma based feature function models  produce better results than  token-based models , 2) adding a  PoS-tag feature function  to the  word-lemma model  improves the output and 3)  weights  for  lexical translations  are suitable if the  training material  is similar to the  texts  to be translated.", "Comments": [], "entities": [{"id": 1091532, "label": "ENT", "start_offset": 46, "end_offset": 68}, {"id": 1091533, "label": "ENT", "start_offset": 74, "end_offset": 81}, {"id": 1091534, "label": "ENT", "start_offset": 126, "end_offset": 159}, {"id": 1091535, "label": "ENT", "start_offset": 222, "end_offset": 238}, {"id": 1091536, "label": "ENT", "start_offset": 262, "end_offset": 277}, {"id": 1091537, "label": "ENT", "start_offset": 284, "end_offset": 301}, {"id": 1091538, "label": "ENT", "start_offset": 335, "end_offset": 340}, {"id": 1091539, "label": "ENT", "start_offset": 357, "end_offset": 405}, {"id": 1091540, "label": "ENT", "start_offset": 466, "end_offset": 473}, {"id": 1091541, "label": "ENT", "start_offset": 491, "end_offset": 520}, {"id": 1091542, "label": "ENT", "start_offset": 540, "end_offset": 557}, {"id": 1091543, "label": "ENT", "start_offset": 565, "end_offset": 582}, {"id": 1091544, "label": "ENT", "start_offset": 645, "end_offset": 667}, {"id": 1091545, "label": "ENT", "start_offset": 706, "end_offset": 723}, {"id": 1091546, "label": "ENT", "start_offset": 733, "end_offset": 738}, {"id": 1091547, "label": "ENT", "start_offset": 757, "end_offset": 784}, {"id": 1091548, "label": "ENT", "start_offset": 792, "end_offset": 817}, {"id": 1091549, "label": "ENT", "start_offset": 852, "end_offset": 892}, {"id": 1091550, "label": "ENT", "start_offset": 923, "end_offset": 941}, {"id": 1091551, "label": "ENT", "start_offset": 957, "end_offset": 981}, {"id": 1091552, "label": "ENT", "start_offset": 991, "end_offset": 1007}, {"id": 1091553, "label": "ENT", "start_offset": 1051, "end_offset": 1071}], "relations": [{"id": 174965, "from_id": 1091536, "to_id": 1091535, "type": "USED-FOR"}, {"id": 174966, "from_id": 1091549, "to_id": 1091550, "type": "COMPARE"}, {"id": 174967, "from_id": 1091551, "to_id": 1091552, "type": "PART-OF"}, {"id": 174968, "from_id": 1091532, "to_id": 1091533, "type": "USED-FOR"}, {"id": 174969, "from_id": 1091537, "to_id": 1091535, "type": "USED-FOR"}, {"id": 174970, "from_id": 1091536, "to_id": 1091537, "type": "CONJUNCTION"}, {"id": 174971, "from_id": 1091543, "to_id": 1091541, "type": "COREF"}, {"id": 174972, "from_id": 1091540, "to_id": 1091541, "type": "USED-FOR"}, {"id": 174973, "from_id": 1091542, "to_id": 1091540, "type": "USED-FOR"}, {"id": 174974, "from_id": 1091552, "to_id": 1091549, "type": "COREF"}, {"id": 174975, "from_id": 1091535, "to_id": 1091546, "type": "COREF"}, {"id": 174976, "from_id": 1091535, "to_id": 1091534, "type": "COREF"}, {"id": 174977, "from_id": 1091544, "to_id": 1091545, "type": "USED-FOR"}, {"id": 174978, "from_id": 1091545, "to_id": 1091546, "type": "PART-OF"}, {"id": 174979, "from_id": 1091548, "to_id": 1091547, "type": "HYPONYM-OF"}]}
{"id": "C92-1055", "text": "   In this paper, a discrimination and robustness oriented  adaptive learning procedure  is proposed to deal with the task of  syntactic ambiguity resolution  . Owing to the problem of  insufficient training data  and  approximation error  introduced by the  language model  , traditional  statistical approaches  , which resolve  ambiguities  by indirectly and implicitly using  maximum likelihood method  , fail to achieve high  performance  in real applications. The proposed method remedies these problems by adjusting the parameters to maximize the  accuracy rate  directly. To make the proposed algorithm robust, the possible variations between the  training corpus  and the real tasks are also taken into consideration by enlarging the  separation margin  between the correct candidate and its competing members. Significant improvement has been observed in the test. The  accuracy rate  of  syntactic disambiguation  is raised from 46.0% to 60.62% by using this novel approach. ", "Comments": [], "entities": [{"id": 1091606, "label": "ENT", "start_offset": 60, "end_offset": 87}, {"id": 1091607, "label": "ENT", "start_offset": 127, "end_offset": 157}, {"id": 1091608, "label": "ENT", "start_offset": 186, "end_offset": 212}, {"id": 1091609, "label": "ENT", "start_offset": 219, "end_offset": 238}, {"id": 1091610, "label": "ENT", "start_offset": 259, "end_offset": 273}, {"id": 1091611, "label": "ENT", "start_offset": 290, "end_offset": 312}, {"id": 1091612, "label": "ENT", "start_offset": 331, "end_offset": 342}, {"id": 1091613, "label": "ENT", "start_offset": 380, "end_offset": 405}, {"id": 1091614, "label": "ENT", "start_offset": 479, "end_offset": 485}, {"id": 1091615, "label": "ENT", "start_offset": 501, "end_offset": 509}, {"id": 1091616, "label": "ENT", "start_offset": 601, "end_offset": 610}, {"id": 1091617, "label": "ENT", "start_offset": 744, "end_offset": 761}, {"id": 1091618, "label": "ENT", "start_offset": 880, "end_offset": 893}, {"id": 1091619, "label": "ENT", "start_offset": 899, "end_offset": 923}, {"id": 1091620, "label": "ENT", "start_offset": 976, "end_offset": 984}], "relations": [{"id": 175024, "from_id": 1091606, "to_id": 1091607, "type": "USED-FOR"}, {"id": 175025, "from_id": 1091613, "to_id": 1091611, "type": "USED-FOR"}, {"id": 175026, "from_id": 1091608, "to_id": 1091609, "type": "CONJUNCTION"}, {"id": 175027, "from_id": 1091611, "to_id": 1091612, "type": "USED-FOR"}, {"id": 175028, "from_id": 1091616, "to_id": 1091614, "type": "COREF"}, {"id": 175029, "from_id": 1091619, "to_id": 1091607, "type": "COREF"}, {"id": 175030, "from_id": 1091618, "to_id": 1091619, "type": "EVALUATE-FOR"}, {"id": 175031, "from_id": 1091614, "to_id": 1091606, "type": "COREF"}, {"id": 175032, "from_id": 1091608, "to_id": 1091615, "type": "HYPONYM-OF"}, {"id": 175033, "from_id": 1091609, "to_id": 1091615, "type": "HYPONYM-OF"}, {"id": 175034, "from_id": 1091620, "to_id": 1091616, "type": "COREF"}, {"id": 175035, "from_id": 1091619, "to_id": 1091620, "type": "EVALUATE-FOR"}]}
{"id": "INTERSPEECH_2014_28_abs", "text": "This paper presents a novel statistical singing voice conversion (SVC) technique with direct waveform modification based on the spectrum differential that can convert voice timbre of a source singer into that of a target singer without using a vocoder to generate converted singing voice waveforms. SVC makes it possible to convert singing voice characteristics of an arbitrary source singer into those of an arbitrary target singer. However, speech quality of the converted singing voice is significantly degraded compared to that of a natural singing voice due to various factors, such as analysis and modeling errors in the vocoder-based framework. To alleviate this degradation, we propose a statistical conversion process that directly modifies the signal in the waveform domain by estimating the difference in the spectra of the source and target singers' singing voices. The differential spectral feature is directly estimated using a differential Gaussian mixture model (GMM) that is analytically derived from the traditional GMM used as a conversion model in the conventional SVC. The experimental results demonstrate that the proposed method makes it possible to significantly improve speech quality in the converted singing voice while preserving the conversion accuracy of singer identity compared to the conventional SVC.", "Comments": [], "entities": [{"id": 1091827, "label": "ENT", "start_offset": 28, "end_offset": 80}, {"id": 1091828, "label": "ENT", "start_offset": 86, "end_offset": 114}, {"id": 1091829, "label": "ENT", "start_offset": 128, "end_offset": 149}, {"id": 1091830, "label": "ENT", "start_offset": 167, "end_offset": 179}, {"id": 1091831, "label": "ENT", "start_offset": 244, "end_offset": 251}, {"id": 1091832, "label": "ENT", "start_offset": 264, "end_offset": 297}, {"id": 1091833, "label": "ENT", "start_offset": 299, "end_offset": 302}, {"id": 1091834, "label": "ENT", "start_offset": 332, "end_offset": 361}, {"id": 1091835, "label": "ENT", "start_offset": 443, "end_offset": 457}, {"id": 1091836, "label": "ENT", "start_offset": 465, "end_offset": 488}, {"id": 1091837, "label": "ENT", "start_offset": 537, "end_offset": 558}, {"id": 1091838, "label": "ENT", "start_offset": 627, "end_offset": 650}, {"id": 1091839, "label": "ENT", "start_offset": 696, "end_offset": 726}, {"id": 1091840, "label": "ENT", "start_offset": 820, "end_offset": 827}, {"id": 1091841, "label": "ENT", "start_offset": 882, "end_offset": 911}, {"id": 1091842, "label": "ENT", "start_offset": 942, "end_offset": 983}, {"id": 1091843, "label": "ENT", "start_offset": 1034, "end_offset": 1037}, {"id": 1091844, "label": "ENT", "start_offset": 1048, "end_offset": 1064}, {"id": 1091845, "label": "ENT", "start_offset": 1085, "end_offset": 1088}, {"id": 1091846, "label": "ENT", "start_offset": 1145, "end_offset": 1151}, {"id": 1091847, "label": "ENT", "start_offset": 1195, "end_offset": 1209}, {"id": 1091848, "label": "ENT", "start_offset": 1262, "end_offset": 1300}, {"id": 1091849, "label": "ENT", "start_offset": 1330, "end_offset": 1333}], "relations": [{"id": 175193, "from_id": 1091828, "to_id": 1091827, "type": "USED-FOR"}, {"id": 175194, "from_id": 1091829, "to_id": 1091828, "type": "USED-FOR"}, {"id": 175195, "from_id": 1091833, "to_id": 1091827, "type": "COREF"}, {"id": 175196, "from_id": 1091833, "to_id": 1091834, "type": "USED-FOR"}, {"id": 175197, "from_id": 1091831, "to_id": 1091832, "type": "USED-FOR"}, {"id": 175198, "from_id": 1091835, "to_id": 1091836, "type": "EVALUATE-FOR"}, {"id": 175199, "from_id": 1091836, "to_id": 1091837, "type": "COMPARE"}, {"id": 175200, "from_id": 1091835, "to_id": 1091837, "type": "EVALUATE-FOR"}, {"id": 175201, "from_id": 1091842, "to_id": 1091841, "type": "USED-FOR"}, {"id": 175202, "from_id": 1091843, "to_id": 1091842, "type": "USED-FOR"}, {"id": 175203, "from_id": 1091843, "to_id": 1091844, "type": "USED-FOR"}, {"id": 175204, "from_id": 1091844, "to_id": 1091845, "type": "USED-FOR"}, {"id": 175205, "from_id": 1091847, "to_id": 1091846, "type": "EVALUATE-FOR"}, {"id": 175206, "from_id": 1091846, "to_id": 1091849, "type": "COMPARE"}, {"id": 175207, "from_id": 1091848, "to_id": 1091846, "type": "EVALUATE-FOR"}, {"id": 175208, "from_id": 1091848, "to_id": 1091849, "type": "USED-FOR"}, {"id": 175209, "from_id": 1091847, "to_id": 1091849, "type": "EVALUATE-FOR"}, {"id": 175210, "from_id": 1091839, "to_id": 1091846, "type": "COREF"}, {"id": 175211, "from_id": 1091839, "to_id": 1091827, "type": "COREF"}, {"id": 175212, "from_id": 1091829, "to_id": 1091830, "type": "USED-FOR"}]}
{"id": "N03-1004", "text": " Motivated by the success of  ensemble methods  in  machine learning  and other areas of  natural language processing  , we developed a  multi-strategy and multi-source approach to question answering  which is based on combining the results from different  answering agents  searching for  answers  in multiple  corpora  . The  answering agents  adopt fundamentally different strategies, one utilizing primarily  knowledge-based mechanisms  and the other adopting  statistical techniques  . We present our  multi-level answer resolution algorithm  that combines results from the  answering agents  at the  question, passage, and/or answer levels  . Experiments evaluating the effectiveness of our  answer resolution algorithm  show a 35.0% relative improvement over our  baseline system  in the number of  questions correctly answered  , and a 32.8% improvement according to the  average precision metric  . ", "Comments": [], "entities": [{"id": 1091858, "label": "ENT", "start_offset": 30, "end_offset": 46}, {"id": 1091859, "label": "ENT", "start_offset": 52, "end_offset": 68}, {"id": 1091860, "label": "ENT", "start_offset": 90, "end_offset": 117}, {"id": 1091861, "label": "ENT", "start_offset": 137, "end_offset": 177}, {"id": 1091862, "label": "ENT", "start_offset": 181, "end_offset": 199}, {"id": 1091863, "label": "ENT", "start_offset": 257, "end_offset": 273}, {"id": 1091864, "label": "ENT", "start_offset": 328, "end_offset": 344}, {"id": 1091865, "label": "ENT", "start_offset": 376, "end_offset": 386}, {"id": 1091866, "label": "ENT", "start_offset": 388, "end_offset": 391}, {"id": 1091867, "label": "ENT", "start_offset": 413, "end_offset": 439}, {"id": 1091868, "label": "ENT", "start_offset": 449, "end_offset": 454}, {"id": 1091869, "label": "ENT", "start_offset": 465, "end_offset": 487}, {"id": 1091870, "label": "ENT", "start_offset": 507, "end_offset": 546}, {"id": 1091871, "label": "ENT", "start_offset": 580, "end_offset": 596}, {"id": 1091872, "label": "ENT", "start_offset": 606, "end_offset": 645}, {"id": 1091873, "label": "ENT", "start_offset": 698, "end_offset": 725}, {"id": 1091874, "label": "ENT", "start_offset": 771, "end_offset": 786}, {"id": 1091875, "label": "ENT", "start_offset": 880, "end_offset": 904}], "relations": [{"id": 175220, "from_id": 1091873, "to_id": 1091874, "type": "COMPARE"}, {"id": 175221, "from_id": 1091858, "to_id": 1091859, "type": "USED-FOR"}, {"id": 175222, "from_id": 1091858, "to_id": 1091860, "type": "USED-FOR"}, {"id": 175223, "from_id": 1091866, "to_id": 1091865, "type": "HYPONYM-OF"}, {"id": 175224, "from_id": 1091868, "to_id": 1091865, "type": "HYPONYM-OF"}, {"id": 175225, "from_id": 1091867, "to_id": 1091866, "type": "USED-FOR"}, {"id": 175226, "from_id": 1091869, "to_id": 1091868, "type": "USED-FOR"}, {"id": 175227, "from_id": 1091865, "to_id": 1091864, "type": "USED-FOR"}, {"id": 175228, "from_id": 1091871, "to_id": 1091870, "type": "USED-FOR"}, {"id": 175229, "from_id": 1091873, "to_id": 1091870, "type": "COREF"}, {"id": 175230, "from_id": 1091875, "to_id": 1091873, "type": "EVALUATE-FOR"}, {"id": 175231, "from_id": 1091875, "to_id": 1091874, "type": "EVALUATE-FOR"}, {"id": 175232, "from_id": 1091861, "to_id": 1091862, "type": "USED-FOR"}, {"id": 175233, "from_id": 1091864, "to_id": 1091863, "type": "COREF"}]}
{"id": "C04-1128", "text": " While  sentence extraction  as an approach to  summarization  has been shown to work in  documents  of certain  genres , because of the conversational nature of  email communication  where  utterances  are made in relation to one made previously,  sentence extraction  may not capture the necessary  segments  of  dialogue  that would make a  summary  coherent. In this paper, we present our work on the detection of  question-answer pairs  in an  email conversation  for the task of  email summarization . We show that various  features  based on the structure of email-threads can be used to improve upon  lexical similarity  of  discourse segments  for  question-answer pairing . ", "Comments": [], "entities": [{"id": 1091911, "label": "ENT", "start_offset": 8, "end_offset": 27}, {"id": 1091912, "label": "ENT", "start_offset": 48, "end_offset": 61}, {"id": 1091913, "label": "ENT", "start_offset": 163, "end_offset": 182}, {"id": 1091914, "label": "ENT", "start_offset": 249, "end_offset": 268}, {"id": 1091915, "label": "ENT", "start_offset": 405, "end_offset": 440}, {"id": 1091916, "label": "ENT", "start_offset": 449, "end_offset": 467}, {"id": 1091917, "label": "ENT", "start_offset": 486, "end_offset": 505}, {"id": 1091918, "label": "ENT", "start_offset": 530, "end_offset": 538}, {"id": 1091919, "label": "ENT", "start_offset": 553, "end_offset": 579}, {"id": 1091920, "label": "ENT", "start_offset": 609, "end_offset": 627}, {"id": 1091921, "label": "ENT", "start_offset": 633, "end_offset": 651}, {"id": 1091922, "label": "ENT", "start_offset": 658, "end_offset": 681}], "relations": [{"id": 175266, "from_id": 1091911, "to_id": 1091912, "type": "USED-FOR"}, {"id": 175267, "from_id": 1091918, "to_id": 1091920, "type": "USED-FOR"}, {"id": 175268, "from_id": 1091914, "to_id": 1091911, "type": "COREF"}, {"id": 175269, "from_id": 1091920, "to_id": 1091921, "type": "FEATURE-OF"}, {"id": 175270, "from_id": 1091918, "to_id": 1091922, "type": "USED-FOR"}, {"id": 175271, "from_id": 1091916, "to_id": 1091915, "type": "USED-FOR"}, {"id": 175272, "from_id": 1091915, "to_id": 1091917, "type": "USED-FOR"}, {"id": 175273, "from_id": 1091919, "to_id": 1091918, "type": "USED-FOR"}]}
{"id": "INTERSPEECH_2008_21_abs", "text": "This paper presents a research on the Czech talking head system. It gives an overview of methods used for visual speech animation, parameterization of a human face and a tongue, necessary data sources and a synthesis method. A 3D animation model is used for a pseudo-muscular animation schema to create such animation of visual speech which is usable for a lipreading. An extension of animation schema is presented to reach more precise deformations mainly in a lip area. Furthermore , a problem of forming articulatory trajectories is formulated to solve labial coarticulation effects. It is used for the synthesis method based on a selection of articulatory targets and interpolation technique.", "Comments": [], "entities": [{"id": 1091923, "label": "ENT", "start_offset": 38, "end_offset": 63}, {"id": 1091924, "label": "ENT", "start_offset": 89, "end_offset": 96}, {"id": 1091925, "label": "ENT", "start_offset": 106, "end_offset": 129}, {"id": 1091926, "label": "ENT", "start_offset": 207, "end_offset": 223}, {"id": 1091927, "label": "ENT", "start_offset": 227, "end_offset": 245}, {"id": 1091928, "label": "ENT", "start_offset": 260, "end_offset": 292}, {"id": 1091929, "label": "ENT", "start_offset": 308, "end_offset": 334}, {"id": 1091930, "label": "ENT", "start_offset": 357, "end_offset": 367}, {"id": 1091931, "label": "ENT", "start_offset": 385, "end_offset": 401}, {"id": 1091932, "label": "ENT", "start_offset": 499, "end_offset": 532}, {"id": 1091933, "label": "ENT", "start_offset": 556, "end_offset": 585}, {"id": 1091934, "label": "ENT", "start_offset": 587, "end_offset": 589}, {"id": 1091935, "label": "ENT", "start_offset": 606, "end_offset": 622}, {"id": 1091936, "label": "ENT", "start_offset": 634, "end_offset": 667}, {"id": 1091937, "label": "ENT", "start_offset": 672, "end_offset": 695}], "relations": [{"id": 175274, "from_id": 1091924, "to_id": 1091925, "type": "USED-FOR"}, {"id": 175275, "from_id": 1091927, "to_id": 1091928, "type": "USED-FOR"}, {"id": 175276, "from_id": 1091928, "to_id": 1091929, "type": "USED-FOR"}, {"id": 175277, "from_id": 1091925, "to_id": 1091929, "type": "COREF"}, {"id": 175278, "from_id": 1091929, "to_id": 1091930, "type": "USED-FOR"}, {"id": 175279, "from_id": 1091932, "to_id": 1091933, "type": "USED-FOR"}, {"id": 175280, "from_id": 1091932, "to_id": 1091934, "type": "COREF"}, {"id": 175281, "from_id": 1091934, "to_id": 1091935, "type": "USED-FOR"}, {"id": 175282, "from_id": 1091936, "to_id": 1091934, "type": "USED-FOR"}, {"id": 175283, "from_id": 1091937, "to_id": 1091934, "type": "USED-FOR"}, {"id": 175284, "from_id": 1091936, "to_id": 1091937, "type": "CONJUNCTION"}]}
{"id": "CVPR_2010_11_abs", "text": "When classifying high-dimensional sequence data, traditional methods (e.g., HMMs, CRFs) may require large amounts of training data to avoid overfitting. In such cases dimensionality reduction can be employed to find a low-dimensional representation on which classification can be done more efficiently. Existing methods for supervised dimensionality reduction often presume that the data is densely sampled so that a neighborhood graph structure can be formed, or that the data arises from a known distribution. Sufficient dimension reduction techniques aim to find a low dimensional representation such that the remaining degrees of freedom become conditionally independent of the output values. In this paper we develop a novel sequence kernel dimension reduction approach (S-KDR). Our approach does not make strong assumptions on the distribution of the input data. Spatial, temporal and periodic information is combined in a principled manner, and an optimal manifold is learned for the end-task. We demonstrate the effectiveness of our approach on several tasks involving the discrimination of human gesture and motion categories, as well as on a database of dynamic textures.", "Comments": [], "entities": [{"id": 1092030, "label": "ENT", "start_offset": 5, "end_offset": 47}, {"id": 1092031, "label": "ENT", "start_offset": 76, "end_offset": 80}, {"id": 1092032, "label": "ENT", "start_offset": 82, "end_offset": 86}, {"id": 1092033, "label": "ENT", "start_offset": 140, "end_offset": 151}, {"id": 1092034, "label": "ENT", "start_offset": 167, "end_offset": 191}, {"id": 1092035, "label": "ENT", "start_offset": 218, "end_offset": 248}, {"id": 1092036, "label": "ENT", "start_offset": 258, "end_offset": 272}, {"id": 1092037, "label": "ENT", "start_offset": 303, "end_offset": 319}, {"id": 1092038, "label": "ENT", "start_offset": 324, "end_offset": 359}, {"id": 1092039, "label": "ENT", "start_offset": 417, "end_offset": 445}, {"id": 1092040, "label": "ENT", "start_offset": 492, "end_offset": 510}, {"id": 1092041, "label": "ENT", "start_offset": 512, "end_offset": 553}, {"id": 1092042, "label": "ENT", "start_offset": 568, "end_offset": 598}, {"id": 1092043, "label": "ENT", "start_offset": 730, "end_offset": 782}, {"id": 1092044, "label": "ENT", "start_offset": 788, "end_offset": 796}, {"id": 1092045, "label": "ENT", "start_offset": 869, "end_offset": 911}, {"id": 1092046, "label": "ENT", "start_offset": 963, "end_offset": 971}, {"id": 1092047, "label": "ENT", "start_offset": 991, "end_offset": 999}, {"id": 1092048, "label": "ENT", "start_offset": 1041, "end_offset": 1049}, {"id": 1092049, "label": "ENT", "start_offset": 1081, "end_offset": 1134}, {"id": 1092050, "label": "ENT", "start_offset": 1152, "end_offset": 1180}], "relations": [{"id": 175350, "from_id": 1092031, "to_id": 1092032, "type": "CONJUNCTION"}, {"id": 175351, "from_id": 1092031, "to_id": 1092030, "type": "USED-FOR"}, {"id": 175352, "from_id": 1092032, "to_id": 1092030, "type": "USED-FOR"}, {"id": 175353, "from_id": 1092034, "to_id": 1092035, "type": "USED-FOR"}, {"id": 175354, "from_id": 1092035, "to_id": 1092036, "type": "USED-FOR"}, {"id": 175355, "from_id": 1092037, "to_id": 1092038, "type": "USED-FOR"}, {"id": 175356, "from_id": 1092041, "to_id": 1092042, "type": "USED-FOR"}, {"id": 175357, "from_id": 1092043, "to_id": 1092044, "type": "COREF"}, {"id": 175358, "from_id": 1092046, "to_id": 1092047, "type": "USED-FOR"}, {"id": 175359, "from_id": 1092049, "to_id": 1092048, "type": "EVALUATE-FOR"}, {"id": 175360, "from_id": 1092050, "to_id": 1092048, "type": "EVALUATE-FOR"}, {"id": 175361, "from_id": 1092044, "to_id": 1092048, "type": "COREF"}]}
{"id": "N06-4001", "text": "   We introduce a new  interactive corpus exploration tool  called  InfoMagnets  .  InfoMagnets  aims at making  exploratory corpus analysis  accessible to researchers who are not experts in  text mining  . As evidence of its usefulness and usability, it has been used successfully in a research context to uncover relationships between  language  and  behavioral patterns  in two distinct domains:  tutorial dialogue (Kumar et al., submitted) and  on-line communities  (Arguello et al., 2006). As an  educational tool  , it has been used as part of a unit on  protocol analysis  in an  Educational Research Methods course  . ", "Comments": [], "entities": [{"id": 1092094, "label": "ENT", "start_offset": 23, "end_offset": 58}, {"id": 1092095, "label": "ENT", "start_offset": 68, "end_offset": 79}, {"id": 1092096, "label": "ENT", "start_offset": 84, "end_offset": 95}, {"id": 1092097, "label": "ENT", "start_offset": 113, "end_offset": 140}, {"id": 1092098, "label": "ENT", "start_offset": 192, "end_offset": 203}, {"id": 1092099, "label": "ENT", "start_offset": 252, "end_offset": 254}, {"id": 1092100, "label": "ENT", "start_offset": 390, "end_offset": 397}, {"id": 1092101, "label": "ENT", "start_offset": 400, "end_offset": 417}, {"id": 1092102, "label": "ENT", "start_offset": 449, "end_offset": 468}, {"id": 1092103, "label": "ENT", "start_offset": 502, "end_offset": 518}, {"id": 1092104, "label": "ENT", "start_offset": 522, "end_offset": 524}, {"id": 1092105, "label": "ENT", "start_offset": 561, "end_offset": 578}], "relations": [{"id": 175403, "from_id": 1092096, "to_id": 1092097, "type": "USED-FOR"}, {"id": 175404, "from_id": 1092103, "to_id": 1092105, "type": "USED-FOR"}, {"id": 175405, "from_id": 1092095, "to_id": 1092094, "type": "HYPONYM-OF"}, {"id": 175406, "from_id": 1092096, "to_id": 1092095, "type": "COREF"}, {"id": 175407, "from_id": 1092099, "to_id": 1092096, "type": "COREF"}, {"id": 175408, "from_id": 1092101, "to_id": 1092100, "type": "HYPONYM-OF"}, {"id": 175409, "from_id": 1092102, "to_id": 1092100, "type": "HYPONYM-OF"}, {"id": 175410, "from_id": 1092101, "to_id": 1092102, "type": "CONJUNCTION"}, {"id": 175411, "from_id": 1092099, "to_id": 1092100, "type": "USED-FOR"}, {"id": 175412, "from_id": 1092103, "to_id": 1092096, "type": "COREF"}, {"id": 175413, "from_id": 1092103, "to_id": 1092104, "type": "COREF"}]}
{"id": "CVPR_2015_300_abs", "text": "We address the problem of estimating location information of an image using principles from automated representation learning. We pursue a hierarchical sparse coding approach that learns features useful in discriminating images across locations, by initializing it with a geometric prior corresponding to transformations between image appearance space and their corresponding location grouping space using the notion of parallel transport on manifolds. We then extend this approach to account for the availability of heterogeneous data modalities such as geo-tags and videos pertaining to different locations, and also study a relatively under-addressed problem of transferring knowledge available from certain locations to infer the grouping of data from novel locations. We evaluate our approach on several standard datasets such as im2gps, San Francisco and MediaEval2010, and obtain state-of-the-art results.", "Comments": [], "entities": [{"id": 1092106, "label": "ENT", "start_offset": 26, "end_offset": 57}, {"id": 1092107, "label": "ENT", "start_offset": 64, "end_offset": 69}, {"id": 1092108, "label": "ENT", "start_offset": 92, "end_offset": 125}, {"id": 1092109, "label": "ENT", "start_offset": 139, "end_offset": 174}, {"id": 1092110, "label": "ENT", "start_offset": 187, "end_offset": 195}, {"id": 1092111, "label": "ENT", "start_offset": 262, "end_offset": 264}, {"id": 1092112, "label": "ENT", "start_offset": 272, "end_offset": 287}, {"id": 1092113, "label": "ENT", "start_offset": 329, "end_offset": 351}, {"id": 1092114, "label": "ENT", "start_offset": 376, "end_offset": 399}, {"id": 1092115, "label": "ENT", "start_offset": 420, "end_offset": 451}, {"id": 1092116, "label": "ENT", "start_offset": 473, "end_offset": 481}, {"id": 1092117, "label": "ENT", "start_offset": 517, "end_offset": 546}, {"id": 1092118, "label": "ENT", "start_offset": 555, "end_offset": 563}, {"id": 1092119, "label": "ENT", "start_offset": 568, "end_offset": 574}, {"id": 1092120, "label": "ENT", "start_offset": 665, "end_offset": 687}, {"id": 1092121, "label": "ENT", "start_offset": 734, "end_offset": 750}, {"id": 1092122, "label": "ENT", "start_offset": 789, "end_offset": 797}, {"id": 1092123, "label": "ENT", "start_offset": 818, "end_offset": 826}, {"id": 1092124, "label": "ENT", "start_offset": 835, "end_offset": 841}, {"id": 1092125, "label": "ENT", "start_offset": 843, "end_offset": 856}, {"id": 1092126, "label": "ENT", "start_offset": 861, "end_offset": 874}], "relations": [{"id": 175414, "from_id": 1092107, "to_id": 1092106, "type": "USED-FOR"}, {"id": 175415, "from_id": 1092108, "to_id": 1092106, "type": "USED-FOR"}, {"id": 175416, "from_id": 1092111, "to_id": 1092109, "type": "COREF"}, {"id": 175417, "from_id": 1092116, "to_id": 1092109, "type": "COREF"}, {"id": 175418, "from_id": 1092115, "to_id": 1092112, "type": "USED-FOR"}, {"id": 175419, "from_id": 1092112, "to_id": 1092111, "type": "USED-FOR"}, {"id": 175420, "from_id": 1092118, "to_id": 1092119, "type": "CONJUNCTION"}, {"id": 175421, "from_id": 1092118, "to_id": 1092117, "type": "HYPONYM-OF"}, {"id": 175422, "from_id": 1092119, "to_id": 1092117, "type": "HYPONYM-OF"}, {"id": 175423, "from_id": 1092116, "to_id": 1092117, "type": "USED-FOR"}, {"id": 175424, "from_id": 1092120, "to_id": 1092121, "type": "USED-FOR"}, {"id": 175425, "from_id": 1092122, "to_id": 1092116, "type": "COREF"}, {"id": 175426, "from_id": 1092124, "to_id": 1092125, "type": "CONJUNCTION"}, {"id": 175427, "from_id": 1092125, "to_id": 1092126, "type": "CONJUNCTION"}, {"id": 175428, "from_id": 1092124, "to_id": 1092123, "type": "HYPONYM-OF"}, {"id": 175429, "from_id": 1092125, "to_id": 1092123, "type": "HYPONYM-OF"}, {"id": 175430, "from_id": 1092126, "to_id": 1092123, "type": "HYPONYM-OF"}, {"id": 175431, "from_id": 1092123, "to_id": 1092122, "type": "EVALUATE-FOR"}]}
{"id": "CVPR_2007_10_abs", "text": "Traditional linear Fukunaga-Koontz Transform (FKT) [1] is a powerful discriminative subspaces building approach. Previous work has successfully extended FKT to be able to deal with small-sample-size. In this paper, we extend traditional linear FKT to enable it to work in multi-class problem and also in higher dimensional (kernel) subspaces and therefore provide enhanced discrimination ability. We verify the effectiveness of the proposed Kernel Fukunaga-Koontz Transform by demonstrating its effectiveness in face recognition applications; however the proposed non-linear generalization can be applied to any other domain specific problems.", "Comments": [], "entities": [{"id": 1092173, "label": "ENT", "start_offset": 12, "end_offset": 50}, {"id": 1092174, "label": "ENT", "start_offset": 69, "end_offset": 111}, {"id": 1092175, "label": "ENT", "start_offset": 153, "end_offset": 156}, {"id": 1092176, "label": "ENT", "start_offset": 181, "end_offset": 198}, {"id": 1092177, "label": "ENT", "start_offset": 237, "end_offset": 247}, {"id": 1092178, "label": "ENT", "start_offset": 258, "end_offset": 260}, {"id": 1092179, "label": "ENT", "start_offset": 272, "end_offset": 291}, {"id": 1092180, "label": "ENT", "start_offset": 304, "end_offset": 341}, {"id": 1092181, "label": "ENT", "start_offset": 373, "end_offset": 395}, {"id": 1092182, "label": "ENT", "start_offset": 441, "end_offset": 473}, {"id": 1092183, "label": "ENT", "start_offset": 512, "end_offset": 541}, {"id": 1092184, "label": "ENT", "start_offset": 564, "end_offset": 589}, {"id": 1092185, "label": "ENT", "start_offset": 618, "end_offset": 642}], "relations": [{"id": 175466, "from_id": 1092173, "to_id": 1092174, "type": "HYPONYM-OF"}, {"id": 175467, "from_id": 1092175, "to_id": 1092173, "type": "COREF"}, {"id": 175468, "from_id": 1092175, "to_id": 1092176, "type": "USED-FOR"}, {"id": 175469, "from_id": 1092177, "to_id": 1092175, "type": "COREF"}, {"id": 175470, "from_id": 1092177, "to_id": 1092178, "type": "USED-FOR"}, {"id": 175471, "from_id": 1092178, "to_id": 1092179, "type": "USED-FOR"}, {"id": 175472, "from_id": 1092178, "to_id": 1092180, "type": "USED-FOR"}, {"id": 175473, "from_id": 1092178, "to_id": 1092181, "type": "FEATURE-OF"}, {"id": 175474, "from_id": 1092179, "to_id": 1092180, "type": "CONJUNCTION"}, {"id": 175475, "from_id": 1092183, "to_id": 1092182, "type": "EVALUATE-FOR"}, {"id": 175476, "from_id": 1092184, "to_id": 1092185, "type": "USED-FOR"}, {"id": 175477, "from_id": 1092182, "to_id": 1092184, "type": "COREF"}]}
{"id": "H89-1027", "text": " Recently, we initiated a project to develop a  phonetically-based spoken language understanding system  called  SUMMIT . In contrast to many of the past efforts that make use of  heuristic rules  whose development requires intense  knowledge engineering , our approach attempts to express the  speech knowledge  within a formal framework using well-defined mathematical tools. In our system,  features  and  decision strategies  are discovered and trained automatically, using a large body of  speech data . This paper describes the system, and documents its current performance. ", "Comments": [], "entities": [{"id": 1092231, "label": "ENT", "start_offset": 48, "end_offset": 103}, {"id": 1092232, "label": "ENT", "start_offset": 113, "end_offset": 119}, {"id": 1092233, "label": "ENT", "start_offset": 180, "end_offset": 195}, {"id": 1092234, "label": "ENT", "start_offset": 233, "end_offset": 254}, {"id": 1092235, "label": "ENT", "start_offset": 261, "end_offset": 269}, {"id": 1092236, "label": "ENT", "start_offset": 295, "end_offset": 311}, {"id": 1092237, "label": "ENT", "start_offset": 358, "end_offset": 376}, {"id": 1092238, "label": "ENT", "start_offset": 385, "end_offset": 391}, {"id": 1092239, "label": "ENT", "start_offset": 394, "end_offset": 402}, {"id": 1092240, "label": "ENT", "start_offset": 409, "end_offset": 428}, {"id": 1092241, "label": "ENT", "start_offset": 495, "end_offset": 506}, {"id": 1092242, "label": "ENT", "start_offset": 534, "end_offset": 540}], "relations": [{"id": 175517, "from_id": 1092234, "to_id": 1092233, "type": "USED-FOR"}, {"id": 175518, "from_id": 1092241, "to_id": 1092240, "type": "USED-FOR"}, {"id": 175519, "from_id": 1092232, "to_id": 1092231, "type": "HYPONYM-OF"}, {"id": 175520, "from_id": 1092237, "to_id": 1092236, "type": "USED-FOR"}, {"id": 175521, "from_id": 1092235, "to_id": 1092232, "type": "COREF"}, {"id": 175522, "from_id": 1092238, "to_id": 1092235, "type": "COREF"}, {"id": 175523, "from_id": 1092239, "to_id": 1092240, "type": "CONJUNCTION"}, {"id": 175524, "from_id": 1092242, "to_id": 1092238, "type": "COREF"}, {"id": 175525, "from_id": 1092235, "to_id": 1092236, "type": "USED-FOR"}]}
{"id": "X96-1041", "text": " The  TIPSTER Architecture  has been designed to enable a variety of different  text applications  to use a set of  common text processing modules . Since  user interfaces  work best when customized for  particular applications  , it is appropriator that no particular  user interface styles or conventions  are described in the  TIPSTER Architecture specification . However, the  Computing Research Laboratory (CRL)  has constructed several  TIPSTER applications  that use a common set of configurable  Graphical User Interface (GUI) functions . These  GUIs  were constructed using  CRL's TIPSTER User Interface Toolkit (TUIT) .  TUIT  is a  software library  that can be used to construct  multilingual TIPSTER user interfaces  for a set of common user tasks.  CRL  developed  TUIT  to support their work to integrate  TIPSTER modules  for the 6 and 12 month TIPSTER II demonstrations as well as their Oleada and Temple demonstration projects. This paper briefly describes  TUIT  and its capabilities.  ", "Comments": [], "entities": [{"id": 1092243, "label": "ENT", "start_offset": 6, "end_offset": 26}, {"id": 1092244, "label": "ENT", "start_offset": 80, "end_offset": 97}, {"id": 1092245, "label": "ENT", "start_offset": 116, "end_offset": 146}, {"id": 1092246, "label": "ENT", "start_offset": 156, "end_offset": 171}, {"id": 1092247, "label": "ENT", "start_offset": 215, "end_offset": 227}, {"id": 1092248, "label": "ENT", "start_offset": 270, "end_offset": 306}, {"id": 1092249, "label": "ENT", "start_offset": 330, "end_offset": 364}, {"id": 1092250, "label": "ENT", "start_offset": 443, "end_offset": 463}, {"id": 1092251, "label": "ENT", "start_offset": 504, "end_offset": 544}, {"id": 1092252, "label": "ENT", "start_offset": 554, "end_offset": 558}, {"id": 1092253, "label": "ENT", "start_offset": 584, "end_offset": 627}, {"id": 1092254, "label": "ENT", "start_offset": 631, "end_offset": 635}, {"id": 1092255, "label": "ENT", "start_offset": 643, "end_offset": 659}, {"id": 1092256, "label": "ENT", "start_offset": 692, "end_offset": 728}, {"id": 1092257, "label": "ENT", "start_offset": 779, "end_offset": 783}, {"id": 1092258, "label": "ENT", "start_offset": 821, "end_offset": 836}, {"id": 1092259, "label": "ENT", "start_offset": 976, "end_offset": 980}], "relations": [{"id": 175526, "from_id": 1092243, "to_id": 1092244, "type": "USED-FOR"}, {"id": 175527, "from_id": 1092245, "to_id": 1092244, "type": "USED-FOR"}, {"id": 175528, "from_id": 1092246, "to_id": 1092247, "type": "USED-FOR"}, {"id": 175529, "from_id": 1092251, "to_id": 1092250, "type": "USED-FOR"}, {"id": 175530, "from_id": 1092252, "to_id": 1092251, "type": "COREF"}, {"id": 175531, "from_id": 1092253, "to_id": 1092252, "type": "USED-FOR"}, {"id": 175532, "from_id": 1092254, "to_id": 1092253, "type": "COREF"}, {"id": 175533, "from_id": 1092254, "to_id": 1092255, "type": "HYPONYM-OF"}, {"id": 175534, "from_id": 1092254, "to_id": 1092256, "type": "USED-FOR"}, {"id": 175535, "from_id": 1092257, "to_id": 1092254, "type": "COREF"}, {"id": 175536, "from_id": 1092257, "to_id": 1092258, "type": "USED-FOR"}, {"id": 175537, "from_id": 1092259, "to_id": 1092257, "type": "COREF"}, {"id": 175538, "from_id": 1092258, "to_id": 1092243, "type": "COREF"}]}
{"id": "P03-1022", "text": " We apply a  decision tree based approach  to  pronoun resolution  in  spoken dialogue  . Our system deals with  pronouns  with  NP- and non-NP-antecedents  . We present a set of  features  designed for  pronoun resolution  in  spoken dialogue  and determine the most promising  features  . We evaluate the system on twenty  Switchboard dialogues  and show that it compares well to  Byron's (2002) manually tuned system  . ", "Comments": [], "entities": [{"id": 1092291, "label": "ENT", "start_offset": 13, "end_offset": 41}, {"id": 1092292, "label": "ENT", "start_offset": 47, "end_offset": 65}, {"id": 1092293, "label": "ENT", "start_offset": 71, "end_offset": 86}, {"id": 1092294, "label": "ENT", "start_offset": 94, "end_offset": 100}, {"id": 1092295, "label": "ENT", "start_offset": 113, "end_offset": 121}, {"id": 1092296, "label": "ENT", "start_offset": 129, "end_offset": 155}, {"id": 1092297, "label": "ENT", "start_offset": 180, "end_offset": 188}, {"id": 1092298, "label": "ENT", "start_offset": 204, "end_offset": 222}, {"id": 1092299, "label": "ENT", "start_offset": 228, "end_offset": 243}, {"id": 1092300, "label": "ENT", "start_offset": 279, "end_offset": 287}, {"id": 1092301, "label": "ENT", "start_offset": 307, "end_offset": 313}, {"id": 1092302, "label": "ENT", "start_offset": 325, "end_offset": 346}, {"id": 1092303, "label": "ENT", "start_offset": 362, "end_offset": 364}, {"id": 1092304, "label": "ENT", "start_offset": 383, "end_offset": 419}], "relations": [{"id": 175568, "from_id": 1092291, "to_id": 1092292, "type": "USED-FOR"}, {"id": 175569, "from_id": 1092296, "to_id": 1092295, "type": "USED-FOR"}, {"id": 175570, "from_id": 1092298, "to_id": 1092299, "type": "USED-FOR"}, {"id": 175571, "from_id": 1092292, "to_id": 1092293, "type": "USED-FOR"}, {"id": 175572, "from_id": 1092297, "to_id": 1092298, "type": "USED-FOR"}, {"id": 175573, "from_id": 1092291, "to_id": 1092294, "type": "COREF"}, {"id": 175574, "from_id": 1092294, "to_id": 1092295, "type": "USED-FOR"}, {"id": 175575, "from_id": 1092294, "to_id": 1092301, "type": "COREF"}, {"id": 175576, "from_id": 1092302, "to_id": 1092301, "type": "EVALUATE-FOR"}, {"id": 175577, "from_id": 1092301, "to_id": 1092303, "type": "COREF"}, {"id": 175578, "from_id": 1092303, "to_id": 1092304, "type": "COMPARE"}, {"id": 175579, "from_id": 1092293, "to_id": 1092299, "type": "COREF"}, {"id": 175580, "from_id": 1092292, "to_id": 1092298, "type": "COREF"}]}
{"id": "ECCV_2016_100_abs", "text": "In this paper, we present an approach for learning a visual representation from the raw spatiotemporal signals in videos. Our representation is learned without supervision from semantic labels. We formulate our method as an unsupervised sequential verification task, i.e., we determine whether a sequence of frames from a video is in the correct temporal order. With this simple task and no semantic labels, we learn a powerful visual representation using a Convolutional Neural Network (CNN). The representation contains complementary information to that learned from supervised image datasets like ImageNet. Qualitative results show that our method captures information that is temporally varying, such as human pose. When used as pre-training for action recognition , our method gives significant gains over learning without external data on benchmark datasets like UCF101 and HMDB51. To demonstrate its sensitivity to human pose, we show results for pose estimation on the FLIC and MPII datasets that are competitive, or better than approaches using significantly more supervision. Our method can be combined with supervised representations to provide an additional boost in accuracy.", "Comments": [], "entities": [{"id": 1092426, "label": "ENT", "start_offset": 29, "end_offset": 37}, {"id": 1092427, "label": "ENT", "start_offset": 53, "end_offset": 74}, {"id": 1092428, "label": "ENT", "start_offset": 84, "end_offset": 120}, {"id": 1092429, "label": "ENT", "start_offset": 126, "end_offset": 140}, {"id": 1092430, "label": "ENT", "start_offset": 160, "end_offset": 192}, {"id": 1092431, "label": "ENT", "start_offset": 211, "end_offset": 217}, {"id": 1092432, "label": "ENT", "start_offset": 224, "end_offset": 265}, {"id": 1092433, "label": "ENT", "start_offset": 346, "end_offset": 360}, {"id": 1092434, "label": "ENT", "start_offset": 379, "end_offset": 383}, {"id": 1092435, "label": "ENT", "start_offset": 391, "end_offset": 406}, {"id": 1092436, "label": "ENT", "start_offset": 428, "end_offset": 449}, {"id": 1092437, "label": "ENT", "start_offset": 458, "end_offset": 492}, {"id": 1092438, "label": "ENT", "start_offset": 498, "end_offset": 512}, {"id": 1092439, "label": "ENT", "start_offset": 522, "end_offset": 547}, {"id": 1092440, "label": "ENT", "start_offset": 569, "end_offset": 594}, {"id": 1092441, "label": "ENT", "start_offset": 600, "end_offset": 608}, {"id": 1092442, "label": "ENT", "start_offset": 644, "end_offset": 650}, {"id": 1092443, "label": "ENT", "start_offset": 708, "end_offset": 718}, {"id": 1092444, "label": "ENT", "start_offset": 733, "end_offset": 745}, {"id": 1092445, "label": "ENT", "start_offset": 750, "end_offset": 768}, {"id": 1092446, "label": "ENT", "start_offset": 771, "end_offset": 781}, {"id": 1092447, "label": "ENT", "start_offset": 811, "end_offset": 841}, {"id": 1092448, "label": "ENT", "start_offset": 845, "end_offset": 863}, {"id": 1092449, "label": "ENT", "start_offset": 869, "end_offset": 875}, {"id": 1092450, "label": "ENT", "start_offset": 880, "end_offset": 886}, {"id": 1092451, "label": "ENT", "start_offset": 922, "end_offset": 932}, {"id": 1092452, "label": "ENT", "start_offset": 954, "end_offset": 969}, {"id": 1092453, "label": "ENT", "start_offset": 977, "end_offset": 999}, {"id": 1092454, "label": "ENT", "start_offset": 1037, "end_offset": 1047}, {"id": 1092455, "label": "ENT", "start_offset": 1073, "end_offset": 1084}, {"id": 1092456, "label": "ENT", "start_offset": 1086, "end_offset": 1096}, {"id": 1092457, "label": "ENT", "start_offset": 1118, "end_offset": 1144}, {"id": 1092458, "label": "ENT", "start_offset": 1179, "end_offset": 1187}], "relations": [{"id": 175691, "from_id": 1092428, "to_id": 1092427, "type": "USED-FOR"}, {"id": 175692, "from_id": 1092426, "to_id": 1092427, "type": "USED-FOR"}, {"id": 175693, "from_id": 1092427, "to_id": 1092429, "type": "COREF"}, {"id": 175694, "from_id": 1092432, "to_id": 1092431, "type": "USED-FOR"}, {"id": 175695, "from_id": 1092426, "to_id": 1092431, "type": "COREF"}, {"id": 175696, "from_id": 1092432, "to_id": 1092434, "type": "COREF"}, {"id": 175697, "from_id": 1092434, "to_id": 1092436, "type": "USED-FOR"}, {"id": 175698, "from_id": 1092437, "to_id": 1092436, "type": "USED-FOR"}, {"id": 175699, "from_id": 1092438, "to_id": 1092436, "type": "COREF"}, {"id": 175700, "from_id": 1092439, "to_id": 1092438, "type": "PART-OF"}, {"id": 175701, "from_id": 1092441, "to_id": 1092440, "type": "HYPONYM-OF"}, {"id": 175702, "from_id": 1092440, "to_id": 1092439, "type": "USED-FOR"}, {"id": 175703, "from_id": 1092431, "to_id": 1092442, "type": "COREF"}, {"id": 175704, "from_id": 1092444, "to_id": 1092445, "type": "USED-FOR"}, {"id": 175705, "from_id": 1092442, "to_id": 1092446, "type": "COREF"}, {"id": 175706, "from_id": 1092446, "to_id": 1092447, "type": "COMPARE"}, {"id": 175707, "from_id": 1092449, "to_id": 1092448, "type": "HYPONYM-OF"}, {"id": 175708, "from_id": 1092450, "to_id": 1092448, "type": "HYPONYM-OF"}, {"id": 175709, "from_id": 1092449, "to_id": 1092450, "type": "CONJUNCTION"}, {"id": 175710, "from_id": 1092448, "to_id": 1092447, "type": "EVALUATE-FOR"}, {"id": 175711, "from_id": 1092448, "to_id": 1092446, "type": "EVALUATE-FOR"}, {"id": 175712, "from_id": 1092446, "to_id": 1092444, "type": "USED-FOR"}, {"id": 175713, "from_id": 1092453, "to_id": 1092452, "type": "EVALUATE-FOR"}, {"id": 175714, "from_id": 1092456, "to_id": 1092446, "type": "COREF"}, {"id": 175715, "from_id": 1092457, "to_id": 1092456, "type": "CONJUNCTION"}, {"id": 175716, "from_id": 1092458, "to_id": 1092456, "type": "EVALUATE-FOR"}, {"id": 175717, "from_id": 1092442, "to_id": 1092443, "type": "USED-FOR"}, {"id": 175718, "from_id": 1092455, "to_id": 1092454, "type": "USED-FOR"}]}
{"id": "NIPS_2001_21_abs", "text": "We consider a problem of blind source separation from a set of instantaneous linear mixtures, where the mixing matrix is unknown. It was discovered recently, that exploiting the sparsity of sources in an appropriate representation according to some signal dictionary, dramatically improves the quality of separation. In this work we use the property of multi scale transforms, such as wavelet or wavelet packets, to decompose signals into sets of local features with various degrees of sparsity. We use this intrinsic property for selecting the best (most sparse) subsets of features for further separation. The performance of the algorithm is verified on noise-free and noisy data. Experiments with simulated signals, musical sounds and images demonstrate significant improvement of separation quality over previously reported results.", "Comments": [], "entities": [{"id": 1092490, "label": "ENT", "start_offset": 25, "end_offset": 48}, {"id": 1092491, "label": "ENT", "start_offset": 63, "end_offset": 92}, {"id": 1092492, "label": "ENT", "start_offset": 104, "end_offset": 117}, {"id": 1092493, "label": "ENT", "start_offset": 178, "end_offset": 197}, {"id": 1092494, "label": "ENT", "start_offset": 249, "end_offset": 266}, {"id": 1092495, "label": "ENT", "start_offset": 294, "end_offset": 315}, {"id": 1092496, "label": "ENT", "start_offset": 353, "end_offset": 375}, {"id": 1092497, "label": "ENT", "start_offset": 385, "end_offset": 411}, {"id": 1092498, "label": "ENT", "start_offset": 447, "end_offset": 461}, {"id": 1092499, "label": "ENT", "start_offset": 486, "end_offset": 494}, {"id": 1092500, "label": "ENT", "start_offset": 575, "end_offset": 583}, {"id": 1092501, "label": "ENT", "start_offset": 631, "end_offset": 640}, {"id": 1092502, "label": "ENT", "start_offset": 656, "end_offset": 681}, {"id": 1092503, "label": "ENT", "start_offset": 700, "end_offset": 717}, {"id": 1092504, "label": "ENT", "start_offset": 719, "end_offset": 733}, {"id": 1092505, "label": "ENT", "start_offset": 738, "end_offset": 744}, {"id": 1092506, "label": "ENT", "start_offset": 784, "end_offset": 802}], "relations": [{"id": 175738, "from_id": 1092491, "to_id": 1092490, "type": "USED-FOR"}, {"id": 175739, "from_id": 1092494, "to_id": 1092493, "type": "USED-FOR"}, {"id": 175740, "from_id": 1092495, "to_id": 1092493, "type": "EVALUATE-FOR"}, {"id": 175741, "from_id": 1092502, "to_id": 1092501, "type": "EVALUATE-FOR"}, {"id": 175742, "from_id": 1092503, "to_id": 1092504, "type": "CONJUNCTION"}, {"id": 175743, "from_id": 1092504, "to_id": 1092505, "type": "CONJUNCTION"}, {"id": 175744, "from_id": 1092497, "to_id": 1092496, "type": "HYPONYM-OF"}, {"id": 175745, "from_id": 1092505, "to_id": 1092506, "type": "EVALUATE-FOR"}, {"id": 175746, "from_id": 1092504, "to_id": 1092506, "type": "EVALUATE-FOR"}, {"id": 175747, "from_id": 1092503, "to_id": 1092506, "type": "EVALUATE-FOR"}]}
{"id": "E85-1041", "text": " We propose a draft scheme of the  model  formalizing the  structure of communicative context  in  dialogue interaction . The relationships between the interacting partners are considered as system of three automata representing the partners of the  dialogue  and environment. ", "Comments": [], "entities": [{"id": 1092554, "label": "ENT", "start_offset": 35, "end_offset": 40}, {"id": 1092555, "label": "ENT", "start_offset": 59, "end_offset": 93}, {"id": 1092556, "label": "ENT", "start_offset": 99, "end_offset": 119}], "relations": [{"id": 175788, "from_id": 1092556, "to_id": 1092555, "type": "FEATURE-OF"}, {"id": 175789, "from_id": 1092554, "to_id": 1092555, "type": "USED-FOR"}]}
{"id": "J81-1002", "text": " This paper reports recent research into methods for  creating natural language text . A new  processing paradigm  called  Fragment-and-Compose  has been created and an experimental system implemented in it. The  knowledge  to be expressed in  text  is first divided into small  propositional units , which are then composed into appropriate combinations and converted into  text . KDS (Knowledge Delivery System) , which embodies this paradigm, has distinct parts devoted to creation of the  propositional units , to organization of the  text , to prevention of  excess redundancy , to creation of combinations of units, to evaluation of these combinations as potential  sentences , to selection of the best among competing combinations, and to creation of the  final text . The  Fragment-and-Compose paradigm  and the  computational methods  of  KDS  are described. ", "Comments": [], "entities": [{"id": 1092580, "label": "ENT", "start_offset": 41, "end_offset": 48}, {"id": 1092581, "label": "ENT", "start_offset": 54, "end_offset": 84}, {"id": 1092582, "label": "ENT", "start_offset": 94, "end_offset": 113}, {"id": 1092583, "label": "ENT", "start_offset": 123, "end_offset": 143}, {"id": 1092584, "label": "ENT", "start_offset": 382, "end_offset": 413}, {"id": 1092585, "label": "ENT", "start_offset": 436, "end_offset": 444}, {"id": 1092586, "label": "ENT", "start_offset": 781, "end_offset": 810}, {"id": 1092587, "label": "ENT", "start_offset": 821, "end_offset": 842}, {"id": 1092588, "label": "ENT", "start_offset": 848, "end_offset": 851}], "relations": [{"id": 175809, "from_id": 1092587, "to_id": 1092588, "type": "USED-FOR"}, {"id": 175810, "from_id": 1092580, "to_id": 1092581, "type": "USED-FOR"}, {"id": 175811, "from_id": 1092583, "to_id": 1092582, "type": "COREF"}, {"id": 175812, "from_id": 1092585, "to_id": 1092582, "type": "COREF"}, {"id": 175813, "from_id": 1092586, "to_id": 1092585, "type": "COREF"}, {"id": 175814, "from_id": 1092588, "to_id": 1092584, "type": "COREF"}, {"id": 175815, "from_id": 1092582, "to_id": 1092580, "type": "COREF"}, {"id": 175816, "from_id": 1092585, "to_id": 1092584, "type": "PART-OF"}]}
{"id": "P03-1009", "text": " Previous research has demonstrated the utility of  clustering  in inducing  semantic verb classes  from undisambiguated  corpus data  . We describe a new approach which involves clustering  subcategorization frame (SCF)  distributions using the  Information Bottleneck  and  nearest neighbour  methods. In contrast to previous work, we particularly focus on clustering  polysemic verbs  . A novel  evaluation scheme  is proposed which accounts for the effect of  polysemy  on the  clusters  , offering us a good insight into the potential and limitations of  semantically classifying   undisambiguated SCF data  . ", "Comments": [], "entities": [{"id": 1092677, "label": "ENT", "start_offset": 52, "end_offset": 62}, {"id": 1092678, "label": "ENT", "start_offset": 67, "end_offset": 98}, {"id": 1092679, "label": "ENT", "start_offset": 105, "end_offset": 133}, {"id": 1092680, "label": "ENT", "start_offset": 155, "end_offset": 163}, {"id": 1092681, "label": "ENT", "start_offset": 179, "end_offset": 235}, {"id": 1092682, "label": "ENT", "start_offset": 247, "end_offset": 302}, {"id": 1092683, "label": "ENT", "start_offset": 359, "end_offset": 386}, {"id": 1092684, "label": "ENT", "start_offset": 399, "end_offset": 416}, {"id": 1092685, "label": "ENT", "start_offset": 464, "end_offset": 472}, {"id": 1092686, "label": "ENT", "start_offset": 482, "end_offset": 490}, {"id": 1092687, "label": "ENT", "start_offset": 560, "end_offset": 611}], "relations": [{"id": 175897, "from_id": 1092685, "to_id": 1092686, "type": "FEATURE-OF"}, {"id": 175898, "from_id": 1092677, "to_id": 1092678, "type": "USED-FOR"}, {"id": 175899, "from_id": 1092679, "to_id": 1092677, "type": "USED-FOR"}, {"id": 175900, "from_id": 1092681, "to_id": 1092680, "type": "PART-OF"}, {"id": 175901, "from_id": 1092684, "to_id": 1092685, "type": "USED-FOR"}, {"id": 175902, "from_id": 1092682, "to_id": 1092681, "type": "USED-FOR"}, {"id": 175903, "from_id": 1092684, "to_id": 1092687, "type": "EVALUATE-FOR"}]}
{"id": "CVPR_2007_18_abs", "text": "In this paper, we propose a human action recognition system suitable for embedded computer vision applications in security systems, human-computer interaction and intelligent environments. Our system is suitable for embedded computer vision application based on three reasons. Firstly, the system was based on a linear Support Vector Machine (SVM) classifier where classification progress can be implemented easily and quickly in embedded hardware. Secondly , we use compacted motion features easily obtained from videos. We address the limitations of the well known Motion History Image (MHI) and propose a new Hierarchical Motion History Histogram (HMHH) feature to represent the motion information. HMHH not only provides rich motion information, but also remains computationally inexpensive. Finally, we combine MHI and HMHH together and extract a low dimension feature vector to be used in the SVM classifiers. Experimental results show that our system achieves significant improvement on the recognition performance .", "Comments": [], "entities": [{"id": 1092767, "label": "ENT", "start_offset": 28, "end_offset": 59}, {"id": 1092768, "label": "ENT", "start_offset": 73, "end_offset": 110}, {"id": 1092769, "label": "ENT", "start_offset": 114, "end_offset": 130}, {"id": 1092770, "label": "ENT", "start_offset": 132, "end_offset": 158}, {"id": 1092771, "label": "ENT", "start_offset": 163, "end_offset": 187}, {"id": 1092772, "label": "ENT", "start_offset": 193, "end_offset": 199}, {"id": 1092773, "label": "ENT", "start_offset": 216, "end_offset": 252}, {"id": 1092774, "label": "ENT", "start_offset": 290, "end_offset": 296}, {"id": 1092775, "label": "ENT", "start_offset": 312, "end_offset": 358}, {"id": 1092776, "label": "ENT", "start_offset": 365, "end_offset": 388}, {"id": 1092777, "label": "ENT", "start_offset": 430, "end_offset": 447}, {"id": 1092778, "label": "ENT", "start_offset": 467, "end_offset": 492}, {"id": 1092779, "label": "ENT", "start_offset": 514, "end_offset": 520}, {"id": 1092780, "label": "ENT", "start_offset": 567, "end_offset": 593}, {"id": 1092781, "label": "ENT", "start_offset": 612, "end_offset": 664}, {"id": 1092782, "label": "ENT", "start_offset": 682, "end_offset": 700}, {"id": 1092783, "label": "ENT", "start_offset": 702, "end_offset": 706}, {"id": 1092784, "label": "ENT", "start_offset": 725, "end_offset": 748}, {"id": 1092785, "label": "ENT", "start_offset": 816, "end_offset": 819}, {"id": 1092786, "label": "ENT", "start_offset": 824, "end_offset": 828}, {"id": 1092787, "label": "ENT", "start_offset": 852, "end_offset": 880}, {"id": 1092788, "label": "ENT", "start_offset": 899, "end_offset": 914}, {"id": 1092789, "label": "ENT", "start_offset": 951, "end_offset": 957}, {"id": 1092790, "label": "ENT", "start_offset": 998, "end_offset": 1009}], "relations": [{"id": 175969, "from_id": 1092769, "to_id": 1092770, "type": "CONJUNCTION"}, {"id": 175970, "from_id": 1092770, "to_id": 1092771, "type": "CONJUNCTION"}, {"id": 175971, "from_id": 1092767, "to_id": 1092768, "type": "USED-FOR"}, {"id": 175972, "from_id": 1092772, "to_id": 1092767, "type": "COREF"}, {"id": 175973, "from_id": 1092768, "to_id": 1092769, "type": "USED-FOR"}, {"id": 175974, "from_id": 1092768, "to_id": 1092770, "type": "USED-FOR"}, {"id": 175975, "from_id": 1092768, "to_id": 1092771, "type": "USED-FOR"}, {"id": 175976, "from_id": 1092772, "to_id": 1092773, "type": "USED-FOR"}, {"id": 175977, "from_id": 1092773, "to_id": 1092768, "type": "COREF"}, {"id": 175978, "from_id": 1092774, "to_id": 1092772, "type": "COREF"}, {"id": 175979, "from_id": 1092775, "to_id": 1092774, "type": "USED-FOR"}, {"id": 175980, "from_id": 1092779, "to_id": 1092778, "type": "USED-FOR"}, {"id": 175981, "from_id": 1092777, "to_id": 1092776, "type": "USED-FOR"}, {"id": 175982, "from_id": 1092783, "to_id": 1092781, "type": "COREF"}, {"id": 175983, "from_id": 1092783, "to_id": 1092784, "type": "USED-FOR"}, {"id": 175984, "from_id": 1092785, "to_id": 1092786, "type": "CONJUNCTION"}, {"id": 175985, "from_id": 1092787, "to_id": 1092788, "type": "USED-FOR"}, {"id": 175986, "from_id": 1092789, "to_id": 1092774, "type": "COREF"}, {"id": 175987, "from_id": 1092790, "to_id": 1092789, "type": "EVALUATE-FOR"}, {"id": 175988, "from_id": 1092775, "to_id": 1092776, "type": "COREF"}, {"id": 175989, "from_id": 1092788, "to_id": 1092776, "type": "COREF"}, {"id": 175990, "from_id": 1092786, "to_id": 1092787, "type": "USED-FOR"}, {"id": 175991, "from_id": 1092785, "to_id": 1092787, "type": "USED-FOR"}, {"id": 175992, "from_id": 1092781, "to_id": 1092782, "type": "USED-FOR"}]}
{"id": "ECCV_2016_215_abs", "text": "Joint image filters can leverage the guidance image as a prior and transfer the structural details from the guidance image to the target image for suppressing noise or enhancing spatial resolution. Existing methods rely on various kinds of explicit filter construction or hand-designed objective functions. It is thus difficult to understand, improve, and accelerate them in a coherent framework. In this paper, we propose a learning-based approach to construct a joint filter based on Convolution-al Neural Networks. In contrast to existing methods that consider only the guidance image, our method can selectively transfer salient structures that are consistent in both guidance and target images. We show that the model trained on a certain type of data, e.g., RGB and depth images, generalizes well for other modalities, e.g., Flash/Non-Flash and RGB/NIR images. We validate the effectiveness of the proposed joint filter through extensive comparisons with state-of-the-art methods.", "Comments": [], "entities": [{"id": 1092906, "label": "ENT", "start_offset": 0, "end_offset": 19}, {"id": 1092907, "label": "ENT", "start_offset": 37, "end_offset": 51}, {"id": 1092908, "label": "ENT", "start_offset": 108, "end_offset": 122}, {"id": 1092909, "label": "ENT", "start_offset": 147, "end_offset": 164}, {"id": 1092910, "label": "ENT", "start_offset": 168, "end_offset": 196}, {"id": 1092911, "label": "ENT", "start_offset": 198, "end_offset": 214}, {"id": 1092912, "label": "ENT", "start_offset": 240, "end_offset": 268}, {"id": 1092913, "label": "ENT", "start_offset": 272, "end_offset": 305}, {"id": 1092914, "label": "ENT", "start_offset": 367, "end_offset": 371}, {"id": 1092915, "label": "ENT", "start_offset": 377, "end_offset": 395}, {"id": 1092916, "label": "ENT", "start_offset": 425, "end_offset": 448}, {"id": 1092917, "label": "ENT", "start_offset": 464, "end_offset": 476}, {"id": 1092918, "label": "ENT", "start_offset": 486, "end_offset": 516}, {"id": 1092919, "label": "ENT", "start_offset": 542, "end_offset": 549}, {"id": 1092920, "label": "ENT", "start_offset": 573, "end_offset": 587}, {"id": 1092921, "label": "ENT", "start_offset": 593, "end_offset": 599}, {"id": 1092922, "label": "ENT", "start_offset": 616, "end_offset": 643}, {"id": 1092923, "label": "ENT", "start_offset": 717, "end_offset": 722}, {"id": 1092924, "label": "ENT", "start_offset": 752, "end_offset": 756}, {"id": 1092925, "label": "ENT", "start_offset": 764, "end_offset": 784}, {"id": 1092926, "label": "ENT", "start_offset": 813, "end_offset": 823}, {"id": 1092927, "label": "ENT", "start_offset": 831, "end_offset": 865}, {"id": 1092928, "label": "ENT", "start_offset": 913, "end_offset": 925}, {"id": 1092929, "label": "ENT", "start_offset": 961, "end_offset": 985}], "relations": [{"id": 176084, "from_id": 1092912, "to_id": 1092911, "type": "USED-FOR"}, {"id": 176085, "from_id": 1092913, "to_id": 1092911, "type": "USED-FOR"}, {"id": 176086, "from_id": 1092912, "to_id": 1092913, "type": "CONJUNCTION"}, {"id": 176087, "from_id": 1092911, "to_id": 1092914, "type": "COREF"}, {"id": 176088, "from_id": 1092919, "to_id": 1092911, "type": "COREF"}, {"id": 176089, "from_id": 1092920, "to_id": 1092919, "type": "USED-FOR"}, {"id": 176090, "from_id": 1092919, "to_id": 1092921, "type": "COMPARE"}, {"id": 176091, "from_id": 1092923, "to_id": 1092921, "type": "COREF"}, {"id": 176092, "from_id": 1092925, "to_id": 1092924, "type": "HYPONYM-OF"}, {"id": 176093, "from_id": 1092924, "to_id": 1092923, "type": "USED-FOR"}, {"id": 176094, "from_id": 1092927, "to_id": 1092926, "type": "HYPONYM-OF"}, {"id": 176095, "from_id": 1092923, "to_id": 1092926, "type": "USED-FOR"}, {"id": 176096, "from_id": 1092928, "to_id": 1092929, "type": "COMPARE"}, {"id": 176097, "from_id": 1092915, "to_id": 1092914, "type": "USED-FOR"}, {"id": 176098, "from_id": 1092916, "to_id": 1092917, "type": "USED-FOR"}, {"id": 176099, "from_id": 1092907, "to_id": 1092906, "type": "USED-FOR"}, {"id": 176100, "from_id": 1092906, "to_id": 1092917, "type": "COREF"}, {"id": 176101, "from_id": 1092918, "to_id": 1092916, "type": "USED-FOR"}, {"id": 176102, "from_id": 1092916, "to_id": 1092921, "type": "COREF"}, {"id": 176103, "from_id": 1092921, "to_id": 1092922, "type": "USED-FOR"}, {"id": 176104, "from_id": 1092917, "to_id": 1092928, "type": "COREF"}, {"id": 176105, "from_id": 1092906, "to_id": 1092909, "type": "USED-FOR"}, {"id": 176106, "from_id": 1092906, "to_id": 1092910, "type": "USED-FOR"}, {"id": 176107, "from_id": 1092909, "to_id": 1092910, "type": "CONJUNCTION"}]}
{"id": "C88-2086", "text": "   Soames 1979 provides some counterexamples to the  theory of natural language presuppositions  that is presented in Gazdar 1979. Soames 1982 provides a theory which explains these counterexamples. Mercer 1987 rejects the solution found in Soames 1982 leaving these counterexamples unexplained. By reappraising these insightful counterexamples, the  inferential theory for natural language presuppositions  described in Mercer 1987, 1988 gives a simple and straightforward explanation for the  presuppositional nature  of these  sentences  . ", "Comments": [], "entities": [{"id": 1092930, "label": "ENT", "start_offset": 63, "end_offset": 95}, {"id": 1092931, "label": "ENT", "start_offset": 374, "end_offset": 406}, {"id": 1092932, "label": "ENT", "start_offset": 495, "end_offset": 518}], "relations": [{"id": 176108, "from_id": 1092930, "to_id": 1092931, "type": "COREF"}]}
{"id": "P03-1030", "text": "  Link detection  has been regarded as a core technology for the  Topic Detection and Tracking tasks  of  new event detection  . In this paper we formulate  story link detection  and  new event detection  as  information retrieval task  and hypothesize on the impact of  precision  and  recall  on both systems. Motivated by these arguments, we introduce a number of new performance enhancing techniques including  part of speech tagging  , new  similarity measures  and expanded  stop lists  . Experimental results validate our hypothesis. ", "Comments": [], "entities": [{"id": 1093159, "label": "ENT", "start_offset": 2, "end_offset": 16}, {"id": 1093160, "label": "ENT", "start_offset": 66, "end_offset": 125}, {"id": 1093161, "label": "ENT", "start_offset": 157, "end_offset": 177}, {"id": 1093162, "label": "ENT", "start_offset": 184, "end_offset": 203}, {"id": 1093163, "label": "ENT", "start_offset": 209, "end_offset": 235}, {"id": 1093164, "label": "ENT", "start_offset": 271, "end_offset": 280}, {"id": 1093165, "label": "ENT", "start_offset": 287, "end_offset": 293}, {"id": 1093166, "label": "ENT", "start_offset": 303, "end_offset": 310}, {"id": 1093167, "label": "ENT", "start_offset": 371, "end_offset": 403}, {"id": 1093168, "label": "ENT", "start_offset": 415, "end_offset": 437}, {"id": 1093169, "label": "ENT", "start_offset": 446, "end_offset": 465}, {"id": 1093170, "label": "ENT", "start_offset": 471, "end_offset": 491}], "relations": [{"id": 176294, "from_id": 1093159, "to_id": 1093160, "type": "USED-FOR"}, {"id": 176295, "from_id": 1093163, "to_id": 1093162, "type": "USED-FOR"}, {"id": 176296, "from_id": 1093163, "to_id": 1093161, "type": "USED-FOR"}, {"id": 176297, "from_id": 1093161, "to_id": 1093162, "type": "CONJUNCTION"}, {"id": 176298, "from_id": 1093162, "to_id": 1093166, "type": "HYPONYM-OF"}, {"id": 176299, "from_id": 1093161, "to_id": 1093166, "type": "HYPONYM-OF"}, {"id": 176300, "from_id": 1093165, "to_id": 1093166, "type": "EVALUATE-FOR"}, {"id": 176301, "from_id": 1093164, "to_id": 1093166, "type": "EVALUATE-FOR"}, {"id": 176302, "from_id": 1093164, "to_id": 1093165, "type": "CONJUNCTION"}, {"id": 176303, "from_id": 1093168, "to_id": 1093167, "type": "PART-OF"}, {"id": 176304, "from_id": 1093169, "to_id": 1093167, "type": "PART-OF"}, {"id": 176305, "from_id": 1093168, "to_id": 1093169, "type": "CONJUNCTION"}, {"id": 176306, "from_id": 1093170, "to_id": 1093167, "type": "PART-OF"}, {"id": 176307, "from_id": 1093169, "to_id": 1093170, "type": "CONJUNCTION"}]}
{"id": "C88-2130", "text": "   We have developed a  computational model  of the process of describing the layout of an apartment or house, a much-studied  discourse task  first characterized linguistically by Linde (1974). The  model  is embodied in a program,  APT  , that can reproduce segments of actual tape-recorded descriptions, using  organizational and discourse strategies  derived through analysis of our  corpus  . ", "Comments": [], "entities": [{"id": 1093187, "label": "ENT", "start_offset": 24, "end_offset": 43}, {"id": 1093188, "label": "ENT", "start_offset": 127, "end_offset": 141}, {"id": 1093189, "label": "ENT", "start_offset": 200, "end_offset": 205}, {"id": 1093190, "label": "ENT", "start_offset": 224, "end_offset": 231}, {"id": 1093191, "label": "ENT", "start_offset": 234, "end_offset": 237}, {"id": 1093192, "label": "ENT", "start_offset": 314, "end_offset": 353}], "relations": [{"id": 176324, "from_id": 1093187, "to_id": 1093188, "type": "USED-FOR"}, {"id": 176325, "from_id": 1093189, "to_id": 1093187, "type": "COREF"}, {"id": 176326, "from_id": 1093189, "to_id": 1093190, "type": "PART-OF"}, {"id": 176327, "from_id": 1093190, "to_id": 1093191, "type": "COREF"}, {"id": 176328, "from_id": 1093192, "to_id": 1093191, "type": "USED-FOR"}]}
{"id": "N06-1007", "text": " The study addresses the problem of  automatic acquisition  of  entailment relations  between  verbs . While this task has much in common with  paraphrases acquisition  which aims to discover  semantic equivalence  between  verbs , the main challenge of  entailment acquisition  is to capture  asymmetric, or directional, relations . Motivated by the intuition that it often underlies the  local structure  of  coherent text , we develop a method that discovers  verb entailment  using evidence about  discourse relations  between  clauses  available in a  parsed corpus . In comparison with earlier work, the proposed method covers a much wider range of  verb entailment types  and learns the  mapping  between  verbs  with highly varied  argument structures . ", "Comments": [], "entities": [{"id": 1093193, "label": "ENT", "start_offset": 37, "end_offset": 84}, {"id": 1093194, "label": "ENT", "start_offset": 114, "end_offset": 118}, {"id": 1093195, "label": "ENT", "start_offset": 144, "end_offset": 167}, {"id": 1093196, "label": "ENT", "start_offset": 193, "end_offset": 213}, {"id": 1093197, "label": "ENT", "start_offset": 255, "end_offset": 277}, {"id": 1093198, "label": "ENT", "start_offset": 294, "end_offset": 331}, {"id": 1093199, "label": "ENT", "start_offset": 390, "end_offset": 424}, {"id": 1093200, "label": "ENT", "start_offset": 440, "end_offset": 446}, {"id": 1093201, "label": "ENT", "start_offset": 463, "end_offset": 478}, {"id": 1093202, "label": "ENT", "start_offset": 502, "end_offset": 521}, {"id": 1093203, "label": "ENT", "start_offset": 557, "end_offset": 570}, {"id": 1093204, "label": "ENT", "start_offset": 619, "end_offset": 625}, {"id": 1093205, "label": "ENT", "start_offset": 656, "end_offset": 677}, {"id": 1093206, "label": "ENT", "start_offset": 695, "end_offset": 718}, {"id": 1093207, "label": "ENT", "start_offset": 725, "end_offset": 759}], "relations": [{"id": 176329, "from_id": 1093197, "to_id": 1093198, "type": "USED-FOR"}, {"id": 176330, "from_id": 1093194, "to_id": 1093195, "type": "COMPARE"}, {"id": 176331, "from_id": 1093200, "to_id": 1093201, "type": "USED-FOR"}, {"id": 176332, "from_id": 1093202, "to_id": 1093200, "type": "USED-FOR"}, {"id": 176333, "from_id": 1093203, "to_id": 1093202, "type": "USED-FOR"}, {"id": 176334, "from_id": 1093204, "to_id": 1093200, "type": "COREF"}, {"id": 176335, "from_id": 1093194, "to_id": 1093193, "type": "COREF"}, {"id": 176336, "from_id": 1093197, "to_id": 1093194, "type": "COREF"}, {"id": 176337, "from_id": 1093195, "to_id": 1093196, "type": "USED-FOR"}, {"id": 176338, "from_id": 1093204, "to_id": 1093206, "type": "USED-FOR"}, {"id": 176339, "from_id": 1093207, "to_id": 1093206, "type": "FEATURE-OF"}]}
{"id": "N03-1033", "text": " We present a new  part-of-speech tagger  that demonstrates the following ideas: (i) explicit use of both preceding and following  tag contexts  via a  dependency network representation  , (ii) broad use of  lexical features  , including  jointly conditioning on multiple consecutive words  , (iii) effective use of  priors  in  conditional loglinear models  , and (iv) fine-grained modeling of  unknown word features  . Using these ideas together, the resulting  tagger  gives a 97.24%  accuracy  on the  Penn Treebank WSJ  , an  error reduction  of 4.4% on the best previous single automatically learned  tagging  result. ", "Comments": [], "entities": [{"id": 1093386, "label": "ENT", "start_offset": 19, "end_offset": 40}, {"id": 1093387, "label": "ENT", "start_offset": 131, "end_offset": 143}, {"id": 1093388, "label": "ENT", "start_offset": 152, "end_offset": 185}, {"id": 1093389, "label": "ENT", "start_offset": 208, "end_offset": 224}, {"id": 1093390, "label": "ENT", "start_offset": 263, "end_offset": 289}, {"id": 1093391, "label": "ENT", "start_offset": 317, "end_offset": 357}, {"id": 1093392, "label": "ENT", "start_offset": 370, "end_offset": 417}, {"id": 1093393, "label": "ENT", "start_offset": 464, "end_offset": 470}, {"id": 1093394, "label": "ENT", "start_offset": 488, "end_offset": 496}, {"id": 1093395, "label": "ENT", "start_offset": 506, "end_offset": 523}, {"id": 1093396, "label": "ENT", "start_offset": 531, "end_offset": 536}, {"id": 1093397, "label": "ENT", "start_offset": 607, "end_offset": 614}], "relations": [{"id": 176508, "from_id": 1093394, "to_id": 1093393, "type": "EVALUATE-FOR"}, {"id": 176509, "from_id": 1093389, "to_id": 1093386, "type": "USED-FOR"}, {"id": 176510, "from_id": 1093393, "to_id": 1093386, "type": "COREF"}, {"id": 176511, "from_id": 1093395, "to_id": 1093393, "type": "EVALUATE-FOR"}, {"id": 176512, "from_id": 1093391, "to_id": 1093386, "type": "USED-FOR"}, {"id": 176513, "from_id": 1093392, "to_id": 1093386, "type": "USED-FOR"}, {"id": 176514, "from_id": 1093396, "to_id": 1093393, "type": "EVALUATE-FOR"}, {"id": 176515, "from_id": 1093387, "to_id": 1093386, "type": "USED-FOR"}, {"id": 176516, "from_id": 1093388, "to_id": 1093387, "type": "USED-FOR"}]}
{"id": "ICML_2016_10_abs", "text": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases. The goal is to sample a small set of records over which evaluating aggregate queries can be done both efficiently and accurately. We provide a principled and provable solution for this problem; it is parameterless and requires no data insights. Unlike standard regression problems , the loss is inversely proportional to the regressed-to values. Moreover, a cost zero solution always exists and can only be excluded by hard budget constraints. A unique form of reg-ularization is also needed. We provide an efficient and simple regularized Empirical Risk Minimization (ERM) algorithm along with a theoretical generalization result. Our extensive experimental results significantly improve over both uniform sampling and standard stratified sampling which are de-facto the industry standards.", "Comments": [], "entities": [{"id": 1093433, "label": "ENT", "start_offset": 20, "end_offset": 50}, {"id": 1093434, "label": "ENT", "start_offset": 61, "end_offset": 83}, {"id": 1093435, "label": "ENT", "start_offset": 88, "end_offset": 95}, {"id": 1093436, "label": "ENT", "start_offset": 99, "end_offset": 108}, {"id": 1093437, "label": "ENT", "start_offset": 147, "end_offset": 154}, {"id": 1093438, "label": "ENT", "start_offset": 177, "end_offset": 194}, {"id": 1093439, "label": "ENT", "start_offset": 253, "end_offset": 285}, {"id": 1093440, "label": "ENT", "start_offset": 295, "end_offset": 302}, {"id": 1093441, "label": "ENT", "start_offset": 304, "end_offset": 306}, {"id": 1093442, "label": "ENT", "start_offset": 371, "end_offset": 390}, {"id": 1093443, "label": "ENT", "start_offset": 397, "end_offset": 401}, {"id": 1093444, "label": "ENT", "start_offset": 435, "end_offset": 454}, {"id": 1093445, "label": "ENT", "start_offset": 468, "end_offset": 486}, {"id": 1093446, "label": "ENT", "start_offset": 529, "end_offset": 552}, {"id": 1093447, "label": "ENT", "start_offset": 571, "end_offset": 586}, {"id": 1093448, "label": "ENT", "start_offset": 638, "end_offset": 693}, {"id": 1093449, "label": "ENT", "start_offset": 809, "end_offset": 825}, {"id": 1093450, "label": "ENT", "start_offset": 839, "end_offset": 858}], "relations": [{"id": 176552, "from_id": 1093433, "to_id": 1093434, "type": "USED-FOR"}, {"id": 176553, "from_id": 1093438, "to_id": 1093437, "type": "EVALUATE-FOR"}, {"id": 176554, "from_id": 1093446, "to_id": 1093445, "type": "USED-FOR"}, {"id": 176555, "from_id": 1093435, "to_id": 1093436, "type": "PART-OF"}, {"id": 176556, "from_id": 1093434, "to_id": 1093435, "type": "USED-FOR"}, {"id": 176557, "from_id": 1093437, "to_id": 1093435, "type": "COREF"}, {"id": 176558, "from_id": 1093449, "to_id": 1093450, "type": "CONJUNCTION"}, {"id": 176559, "from_id": 1093433, "to_id": 1093440, "type": "COREF"}, {"id": 176560, "from_id": 1093439, "to_id": 1093440, "type": "USED-FOR"}, {"id": 176561, "from_id": 1093439, "to_id": 1093441, "type": "COREF"}]}
{"id": "C96-1055", "text": " This paper addresses the issue of  word-sense ambiguity  in extraction from  machine-readable resources  for the construction of  large-scale knowledge sources . We describe two experiments: one which ignored  word-sense distinctions , resulting in 6.3% accuracy for  semantic classification  of  verbs  based on (Levin, 1993); and one which exploited  word-sense distinctions , resulting in 97.9% accuracy. These experiments were dual purpose: (1) to validate the central thesis of the work of (Levin, 1993), i.e., that  verb semantics  and  syntactic behavior  are predictably related; (2) to demonstrate that a 15-fold improvement can be achieved in deriving  semantic information  from  syntactic cues  if we first divide the  syntactic cues  into distinct groupings that correlate with different  word senses . Finally, we show that we can provide effective acquisition techniques for novel  word senses  using a combination of online sources. ", "Comments": [], "entities": [{"id": 1093451, "label": "ENT", "start_offset": 36, "end_offset": 56}, {"id": 1093452, "label": "ENT", "start_offset": 78, "end_offset": 104}, {"id": 1093453, "label": "ENT", "start_offset": 114, "end_offset": 160}, {"id": 1093454, "label": "ENT", "start_offset": 211, "end_offset": 234}, {"id": 1093455, "label": "ENT", "start_offset": 255, "end_offset": 263}, {"id": 1093456, "label": "ENT", "start_offset": 269, "end_offset": 292}, {"id": 1093457, "label": "ENT", "start_offset": 354, "end_offset": 377}, {"id": 1093458, "label": "ENT", "start_offset": 399, "end_offset": 407}, {"id": 1093459, "label": "ENT", "start_offset": 523, "end_offset": 537}, {"id": 1093460, "label": "ENT", "start_offset": 544, "end_offset": 562}, {"id": 1093461, "label": "ENT", "start_offset": 664, "end_offset": 684}, {"id": 1093462, "label": "ENT", "start_offset": 692, "end_offset": 706}, {"id": 1093463, "label": "ENT", "start_offset": 732, "end_offset": 746}, {"id": 1093464, "label": "ENT", "start_offset": 803, "end_offset": 814}, {"id": 1093465, "label": "ENT", "start_offset": 876, "end_offset": 886}, {"id": 1093466, "label": "ENT", "start_offset": 898, "end_offset": 909}, {"id": 1093467, "label": "ENT", "start_offset": 934, "end_offset": 948}], "relations": [{"id": 176562, "from_id": 1093459, "to_id": 1093460, "type": "CONJUNCTION"}, {"id": 176563, "from_id": 1093452, "to_id": 1093451, "type": "USED-FOR"}, {"id": 176564, "from_id": 1093457, "to_id": 1093454, "type": "COREF"}, {"id": 176565, "from_id": 1093454, "to_id": 1093451, "type": "COREF"}, {"id": 176566, "from_id": 1093465, "to_id": 1093466, "type": "USED-FOR"}, {"id": 176567, "from_id": 1093467, "to_id": 1093465, "type": "USED-FOR"}, {"id": 176568, "from_id": 1093452, "to_id": 1093453, "type": "USED-FOR"}, {"id": 176569, "from_id": 1093455, "to_id": 1093456, "type": "EVALUATE-FOR"}, {"id": 176570, "from_id": 1093462, "to_id": 1093461, "type": "USED-FOR"}]}
{"id": "P83-1003", "text": " An extension to the  GPSG grammatical formalism  is proposed, allowing  non-terminals  to consist of finite sequences of  category labels , and allowing  schematic variables  to range over such sequences. The extension is shown to be sufficient to provide a strongly adequate  grammar  for  crossed serial dependencies , as found in e.g.  Dutch subordinate clauses . The structures induced for such  constructions  are argued to be more appropriate to data involving  conjunction  than some previous proposals have been. The extension is shown to be parseable by a simple extension to an existing  parsing method  for  GPSG . ", "Comments": [], "entities": [{"id": 1093526, "label": "ENT", "start_offset": 4, "end_offset": 13}, {"id": 1093527, "label": "ENT", "start_offset": 22, "end_offset": 48}, {"id": 1093528, "label": "ENT", "start_offset": 73, "end_offset": 86}, {"id": 1093529, "label": "ENT", "start_offset": 155, "end_offset": 174}, {"id": 1093530, "label": "ENT", "start_offset": 210, "end_offset": 219}, {"id": 1093531, "label": "ENT", "start_offset": 278, "end_offset": 285}, {"id": 1093532, "label": "ENT", "start_offset": 292, "end_offset": 319}, {"id": 1093533, "label": "ENT", "start_offset": 340, "end_offset": 365}, {"id": 1093534, "label": "ENT", "start_offset": 401, "end_offset": 414}, {"id": 1093535, "label": "ENT", "start_offset": 526, "end_offset": 535}, {"id": 1093536, "label": "ENT", "start_offset": 573, "end_offset": 582}, {"id": 1093537, "label": "ENT", "start_offset": 599, "end_offset": 613}, {"id": 1093538, "label": "ENT", "start_offset": 620, "end_offset": 624}], "relations": [{"id": 176620, "from_id": 1093537, "to_id": 1093538, "type": "USED-FOR"}, {"id": 176621, "from_id": 1093526, "to_id": 1093530, "type": "COREF"}, {"id": 176622, "from_id": 1093527, "to_id": 1093526, "type": "USED-FOR"}, {"id": 176623, "from_id": 1093530, "to_id": 1093535, "type": "COREF"}, {"id": 176624, "from_id": 1093536, "to_id": 1093535, "type": "USED-FOR"}, {"id": 176625, "from_id": 1093537, "to_id": 1093536, "type": "USED-FOR"}, {"id": 176626, "from_id": 1093527, "to_id": 1093538, "type": "COREF"}, {"id": 176627, "from_id": 1093531, "to_id": 1093532, "type": "USED-FOR"}, {"id": 176628, "from_id": 1093530, "to_id": 1093531, "type": "USED-FOR"}]}
{"id": "C04-1068", "text": " The work presented in this paper is the first step in a project which aims to cluster and summarise  electronic discussions  in the context of  help-desk applications . The eventual objective of this project is to use these  summaries  to assist help-desk users and operators. In this paper, we identify  features  of  electronic discussions  that influence the  clustering process , and offer a  filtering mechanism  that removes undesirable  influences . We tested the  clustering and filtering processes  on  electronic newsgroup discussions , and evaluated their  performance  by means of two experiments :  coarse-level clustering  simple  information retrieval . ", "Comments": [], "entities": [{"id": 1093573, "label": "ENT", "start_offset": 102, "end_offset": 124}, {"id": 1093574, "label": "ENT", "start_offset": 145, "end_offset": 167}, {"id": 1093575, "label": "ENT", "start_offset": 306, "end_offset": 314}, {"id": 1093576, "label": "ENT", "start_offset": 320, "end_offset": 342}, {"id": 1093577, "label": "ENT", "start_offset": 364, "end_offset": 382}, {"id": 1093578, "label": "ENT", "start_offset": 398, "end_offset": 417}, {"id": 1093579, "label": "ENT", "start_offset": 473, "end_offset": 507}, {"id": 1093580, "label": "ENT", "start_offset": 513, "end_offset": 545}, {"id": 1093581, "label": "ENT", "start_offset": 598, "end_offset": 609}, {"id": 1093582, "label": "ENT", "start_offset": 613, "end_offset": 636}, {"id": 1093583, "label": "ENT", "start_offset": 646, "end_offset": 667}], "relations": [{"id": 176661, "from_id": 1093580, "to_id": 1093579, "type": "EVALUATE-FOR"}, {"id": 176662, "from_id": 1093582, "to_id": 1093581, "type": "HYPONYM-OF"}, {"id": 176663, "from_id": 1093583, "to_id": 1093581, "type": "HYPONYM-OF"}, {"id": 176664, "from_id": 1093581, "to_id": 1093579, "type": "EVALUATE-FOR"}, {"id": 176665, "from_id": 1093576, "to_id": 1093573, "type": "COREF"}, {"id": 176666, "from_id": 1093577, "to_id": 1093579, "type": "HYPONYM-OF"}, {"id": 176667, "from_id": 1093578, "to_id": 1093579, "type": "HYPONYM-OF"}, {"id": 176668, "from_id": 1093573, "to_id": 1093574, "type": "PART-OF"}, {"id": 176669, "from_id": 1093575, "to_id": 1093576, "type": "FEATURE-OF"}, {"id": 176670, "from_id": 1093581, "to_id": 1093579, "type": "EVALUATE-FOR"}]}
{"id": "C96-2213", "text": " Porting a  Natural Language Processing (NLP) system  to a  new domain  remains one of the bottlenecks in  syntactic parsing , because of the amount of effort required to fix gaps in the  lexicon , and to attune the  existing grammar  to the idiosyncracies of the  new sublanguage . This paper shows how the process of fitting a  lexicalized grammar  to a  domain  can be automated to a great extent by using a  hybrid system  that combines  traditional knowledge-based techniques  with a  corpus-based approach . ", "Comments": [], "entities": [{"id": 1093659, "label": "ENT", "start_offset": 12, "end_offset": 52}, {"id": 1093660, "label": "ENT", "start_offset": 60, "end_offset": 70}, {"id": 1093661, "label": "ENT", "start_offset": 107, "end_offset": 124}, {"id": 1093662, "label": "ENT", "start_offset": 226, "end_offset": 233}, {"id": 1093663, "label": "ENT", "start_offset": 242, "end_offset": 280}, {"id": 1093664, "label": "ENT", "start_offset": 330, "end_offset": 349}, {"id": 1093665, "label": "ENT", "start_offset": 412, "end_offset": 425}, {"id": 1093666, "label": "ENT", "start_offset": 454, "end_offset": 480}, {"id": 1093667, "label": "ENT", "start_offset": 490, "end_offset": 511}], "relations": [{"id": 176736, "from_id": 1093666, "to_id": 1093667, "type": "CONJUNCTION"}, {"id": 176737, "from_id": 1093666, "to_id": 1093665, "type": "PART-OF"}, {"id": 176738, "from_id": 1093667, "to_id": 1093665, "type": "PART-OF"}, {"id": 176739, "from_id": 1093662, "to_id": 1093663, "type": "USED-FOR"}, {"id": 176740, "from_id": 1093659, "to_id": 1093660, "type": "USED-FOR"}]}
{"id": "P05-1056", "text": "  Sentence boundary detection  in  speech  is important for enriching  speech recognition  output, making it easier for humans to read and downstream modules to process. In previous work, we have developed  hidden Markov model (HMM) and maximum entropy (Maxent) classifiers  that integrate textual and prosodic  knowledge sources  for detecting  sentence boundaries . In this paper, we evaluate the use of a  conditional random field (CRF)  for this task and relate results with this model to our prior work. We evaluate across two corpora (conversational  telephone speech  and  broadcast news speech ) on both  human transcriptions  and  speech recognition  output. In general, our  CRF  model yields a lower error rate than the  HMM and Max-ent models  on the  NIST sentence boundary detection task  in  speech , although it is interesting to note that the best results are achieved by  three-way voting  among the  classifiers . This probably occurs because each  model  has different strengths and weaknesses for modeling the  knowledge sources . ", "Comments": [], "entities": [{"id": 1093668, "label": "ENT", "start_offset": 2, "end_offset": 29}, {"id": 1093669, "label": "ENT", "start_offset": 35, "end_offset": 41}, {"id": 1093670, "label": "ENT", "start_offset": 71, "end_offset": 97}, {"id": 1093671, "label": "ENT", "start_offset": 106, "end_offset": 108}, {"id": 1093672, "label": "ENT", "start_offset": 207, "end_offset": 273}, {"id": 1093673, "label": "ENT", "start_offset": 290, "end_offset": 329}, {"id": 1093674, "label": "ENT", "start_offset": 335, "end_offset": 365}, {"id": 1093675, "label": "ENT", "start_offset": 409, "end_offset": 439}, {"id": 1093676, "label": "ENT", "start_offset": 450, "end_offset": 454}, {"id": 1093677, "label": "ENT", "start_offset": 484, "end_offset": 489}, {"id": 1093678, "label": "ENT", "start_offset": 532, "end_offset": 539}, {"id": 1093679, "label": "ENT", "start_offset": 541, "end_offset": 573}, {"id": 1093680, "label": "ENT", "start_offset": 580, "end_offset": 601}, {"id": 1093681, "label": "ENT", "start_offset": 613, "end_offset": 633}, {"id": 1093682, "label": "ENT", "start_offset": 640, "end_offset": 666}, {"id": 1093683, "label": "ENT", "start_offset": 685, "end_offset": 695}, {"id": 1093684, "label": "ENT", "start_offset": 711, "end_offset": 721}, {"id": 1093685, "label": "ENT", "start_offset": 732, "end_offset": 754}, {"id": 1093686, "label": "ENT", "start_offset": 764, "end_offset": 801}, {"id": 1093687, "label": "ENT", "start_offset": 807, "end_offset": 813}, {"id": 1093688, "label": "ENT", "start_offset": 890, "end_offset": 906}, {"id": 1093689, "label": "ENT", "start_offset": 919, "end_offset": 930}, {"id": 1093690, "label": "ENT", "start_offset": 968, "end_offset": 973}, {"id": 1093691, "label": "ENT", "start_offset": 1032, "end_offset": 1049}], "relations": [{"id": 176741, "from_id": 1093673, "to_id": 1093672, "type": "USED-FOR"}, {"id": 176742, "from_id": 1093668, "to_id": 1093674, "type": "COREF"}, {"id": 176743, "from_id": 1093674, "to_id": 1093676, "type": "COREF"}, {"id": 176744, "from_id": 1093675, "to_id": 1093676, "type": "USED-FOR"}, {"id": 176745, "from_id": 1093675, "to_id": 1093677, "type": "COREF"}, {"id": 176746, "from_id": 1093679, "to_id": 1093678, "type": "HYPONYM-OF"}, {"id": 176747, "from_id": 1093680, "to_id": 1093678, "type": "HYPONYM-OF"}, {"id": 176748, "from_id": 1093679, "to_id": 1093680, "type": "CONJUNCTION"}, {"id": 176749, "from_id": 1093669, "to_id": 1093668, "type": "USED-FOR"}, {"id": 176750, "from_id": 1093668, "to_id": 1093670, "type": "USED-FOR"}, {"id": 176751, "from_id": 1093670, "to_id": 1093671, "type": "COREF"}, {"id": 176752, "from_id": 1093681, "to_id": 1093682, "type": "CONJUNCTION"}, {"id": 176753, "from_id": 1093678, "to_id": 1093681, "type": "EVALUATE-FOR"}, {"id": 176754, "from_id": 1093678, "to_id": 1093682, "type": "EVALUATE-FOR"}, {"id": 176755, "from_id": 1093675, "to_id": 1093683, "type": "COREF"}, {"id": 176756, "from_id": 1093684, "to_id": 1093683, "type": "EVALUATE-FOR"}, {"id": 176757, "from_id": 1093684, "to_id": 1093685, "type": "EVALUATE-FOR"}, {"id": 176758, "from_id": 1093683, "to_id": 1093685, "type": "COMPARE"}, {"id": 176759, "from_id": 1093687, "to_id": 1093686, "type": "FEATURE-OF"}, {"id": 176760, "from_id": 1093686, "to_id": 1093685, "type": "EVALUATE-FOR"}, {"id": 176761, "from_id": 1093686, "to_id": 1093683, "type": "EVALUATE-FOR"}, {"id": 176762, "from_id": 1093690, "to_id": 1093691, "type": "USED-FOR"}, {"id": 176763, "from_id": 1093672, "to_id": 1093674, "type": "USED-FOR"}, {"id": 176764, "from_id": 1093689, "to_id": 1093688, "type": "USED-FOR"}]}
{"id": "C04-1147", "text": " We present a framework for the fast  computation  of  lexical affinity models . The framework is composed of a novel algorithm to efficiently compute the  co-occurrence distribution  between pairs of  terms , an  independence model , and a  parametric affinity model . In comparison with previous  models , which either use arbitrary windows to compute  similarity  between  words  or use  lexical affinity  to create  sequential models , in this paper we focus on  models  intended to capture the  co-occurrence patterns  of any pair of  words  or  phrases  at any distance in the  corpus . The framework is flexible, allowing fast  adaptation  to  applications  and it is scalable. We apply it in combination with a  terabyte corpus  to answer  natural language tests , achieving encouraging results. ", "Comments": [], "entities": [{"id": 1093843, "label": "ENT", "start_offset": 14, "end_offset": 23}, {"id": 1093844, "label": "ENT", "start_offset": 32, "end_offset": 78}, {"id": 1093845, "label": "ENT", "start_offset": 85, "end_offset": 94}, {"id": 1093846, "label": "ENT", "start_offset": 118, "end_offset": 127}, {"id": 1093847, "label": "ENT", "start_offset": 156, "end_offset": 182}, {"id": 1093848, "label": "ENT", "start_offset": 214, "end_offset": 232}, {"id": 1093849, "label": "ENT", "start_offset": 242, "end_offset": 267}, {"id": 1093850, "label": "ENT", "start_offset": 299, "end_offset": 305}, {"id": 1093851, "label": "ENT", "start_offset": 355, "end_offset": 365}, {"id": 1093852, "label": "ENT", "start_offset": 391, "end_offset": 407}, {"id": 1093853, "label": "ENT", "start_offset": 420, "end_offset": 437}, {"id": 1093854, "label": "ENT", "start_offset": 467, "end_offset": 473}, {"id": 1093855, "label": "ENT", "start_offset": 500, "end_offset": 522}, {"id": 1093856, "label": "ENT", "start_offset": 597, "end_offset": 606}, {"id": 1093857, "label": "ENT", "start_offset": 694, "end_offset": 696}, {"id": 1093858, "label": "ENT", "start_offset": 720, "end_offset": 735}, {"id": 1093859, "label": "ENT", "start_offset": 748, "end_offset": 770}], "relations": [{"id": 176895, "from_id": 1093852, "to_id": 1093853, "type": "USED-FOR"}, {"id": 176896, "from_id": 1093845, "to_id": 1093843, "type": "COREF"}, {"id": 176897, "from_id": 1093846, "to_id": 1093845, "type": "PART-OF"}, {"id": 176898, "from_id": 1093848, "to_id": 1093845, "type": "PART-OF"}, {"id": 176899, "from_id": 1093849, "to_id": 1093845, "type": "PART-OF"}, {"id": 176900, "from_id": 1093854, "to_id": 1093850, "type": "COMPARE"}, {"id": 176901, "from_id": 1093854, "to_id": 1093855, "type": "USED-FOR"}, {"id": 176902, "from_id": 1093846, "to_id": 1093847, "type": "USED-FOR"}, {"id": 176903, "from_id": 1093856, "to_id": 1093845, "type": "COREF"}, {"id": 176904, "from_id": 1093857, "to_id": 1093856, "type": "COREF"}, {"id": 176905, "from_id": 1093858, "to_id": 1093857, "type": "EVALUATE-FOR"}, {"id": 176906, "from_id": 1093857, "to_id": 1093859, "type": "USED-FOR"}, {"id": 176907, "from_id": 1093843, "to_id": 1093844, "type": "USED-FOR"}, {"id": 176908, "from_id": 1093846, "to_id": 1093848, "type": "CONJUNCTION"}, {"id": 176909, "from_id": 1093848, "to_id": 1093849, "type": "CONJUNCTION"}]}
{"id": "P01-1007", "text": " The theoretical study of the  range concatenation grammar [RCG] formalism  has revealed many attractive properties which may be used in  NLP  . In particular,  range concatenation languages [RCL]  can be parsed in  polynomial time  and many classical  grammatical formalisms  can be translated into equivalent  RCGs  without increasing their  worst-case parsing time complexity  . For example, after  translation  into an equivalent  RCG  , any  tree adjoining grammar  can be parsed in  O(n6) time  . In this paper, we study a  parsing technique  whose purpose is to improve the practical efficiency of  RCL parsers  . The  non-deterministic parsing choices  of the  main parser  for a  language L  are directed by a  guide  which uses the  shared derivation forest  output by a prior  RCL parser  for a suitable  superset of L  . The results of a practical evaluation of this method on a  wide coverage English grammar  are given. ", "Comments": [], "entities": [{"id": 1093860, "label": "ENT", "start_offset": 31, "end_offset": 74}, {"id": 1093861, "label": "ENT", "start_offset": 138, "end_offset": 141}, {"id": 1093862, "label": "ENT", "start_offset": 161, "end_offset": 196}, {"id": 1093863, "label": "ENT", "start_offset": 216, "end_offset": 231}, {"id": 1093864, "label": "ENT", "start_offset": 253, "end_offset": 275}, {"id": 1093865, "label": "ENT", "start_offset": 312, "end_offset": 316}, {"id": 1093866, "label": "ENT", "start_offset": 344, "end_offset": 378}, {"id": 1093867, "label": "ENT", "start_offset": 435, "end_offset": 438}, {"id": 1093868, "label": "ENT", "start_offset": 447, "end_offset": 469}, {"id": 1093869, "label": "ENT", "start_offset": 489, "end_offset": 499}, {"id": 1093870, "label": "ENT", "start_offset": 530, "end_offset": 547}, {"id": 1093871, "label": "ENT", "start_offset": 606, "end_offset": 617}, {"id": 1093872, "label": "ENT", "start_offset": 626, "end_offset": 651}, {"id": 1093873, "label": "ENT", "start_offset": 669, "end_offset": 680}, {"id": 1093874, "label": "ENT", "start_offset": 689, "end_offset": 699}, {"id": 1093875, "label": "ENT", "start_offset": 743, "end_offset": 767}, {"id": 1093876, "label": "ENT", "start_offset": 788, "end_offset": 798}, {"id": 1093877, "label": "ENT", "start_offset": 879, "end_offset": 885}, {"id": 1093878, "label": "ENT", "start_offset": 892, "end_offset": 921}], "relations": [{"id": 176910, "from_id": 1093860, "to_id": 1093861, "type": "USED-FOR"}, {"id": 176911, "from_id": 1093863, "to_id": 1093862, "type": "FEATURE-OF"}, {"id": 176912, "from_id": 1093869, "to_id": 1093868, "type": "FEATURE-OF"}, {"id": 176913, "from_id": 1093870, "to_id": 1093871, "type": "USED-FOR"}, {"id": 176914, "from_id": 1093860, "to_id": 1093865, "type": "COREF"}, {"id": 176915, "from_id": 1093866, "to_id": 1093864, "type": "EVALUATE-FOR"}, {"id": 176916, "from_id": 1093865, "to_id": 1093867, "type": "COREF"}, {"id": 176917, "from_id": 1093873, "to_id": 1093874, "type": "USED-FOR"}, {"id": 176918, "from_id": 1093878, "to_id": 1093877, "type": "EVALUATE-FOR"}, {"id": 176919, "from_id": 1093871, "to_id": 1093876, "type": "COREF"}, {"id": 176920, "from_id": 1093870, "to_id": 1093877, "type": "COREF"}, {"id": 176921, "from_id": 1093876, "to_id": 1093875, "type": "USED-FOR"}]}
{"id": "CVPR_2010_21_abs", "text": "Conditional Random Field models have proved effective for several low-level computer vision problems. Inference in these models involves solving a combinatorial optimization problem, with methods such as graph cuts, belief propagation. Although several methods have been proposed to learn the model parameters from training data, they suffer from various drawbacks. Learning these parameters involves computing the partition function, which is intractable. To overcome this, state-of-the-art structured learning methods frame the problem as one of large margin estimation. Iterative solutions have been proposed to solve the resulting convex optimization problem. Each iteration involves solving an inference problem over all the labels , which limits the efficiency of these structured methods. In this paper we present an efficient large margin piece-wise learning method which is widely applicable. We show how the resulting optimization problem can be reduced to an equivalent convex problem with a small number of constraints , and solve it using an efficient scheme. Our method is both memory and computationally efficient. We show results on publicly available standard datasets.", "Comments": [], "entities": [{"id": 1093901, "label": "ENT", "start_offset": 0, "end_offset": 31}, {"id": 1093902, "label": "ENT", "start_offset": 66, "end_offset": 100}, {"id": 1093903, "label": "ENT", "start_offset": 102, "end_offset": 111}, {"id": 1093904, "label": "ENT", "start_offset": 121, "end_offset": 127}, {"id": 1093905, "label": "ENT", "start_offset": 147, "end_offset": 181}, {"id": 1093906, "label": "ENT", "start_offset": 188, "end_offset": 195}, {"id": 1093907, "label": "ENT", "start_offset": 204, "end_offset": 214}, {"id": 1093908, "label": "ENT", "start_offset": 216, "end_offset": 234}, {"id": 1093909, "label": "ENT", "start_offset": 293, "end_offset": 309}, {"id": 1093910, "label": "ENT", "start_offset": 381, "end_offset": 391}, {"id": 1093911, "label": "ENT", "start_offset": 415, "end_offset": 433}, {"id": 1093912, "label": "ENT", "start_offset": 492, "end_offset": 519}, {"id": 1093913, "label": "ENT", "start_offset": 530, "end_offset": 537}, {"id": 1093914, "label": "ENT", "start_offset": 548, "end_offset": 571}, {"id": 1093915, "label": "ENT", "start_offset": 573, "end_offset": 592}, {"id": 1093916, "label": "ENT", "start_offset": 635, "end_offset": 662}, {"id": 1093917, "label": "ENT", "start_offset": 699, "end_offset": 716}, {"id": 1093918, "label": "ENT", "start_offset": 776, "end_offset": 794}, {"id": 1093919, "label": "ENT", "start_offset": 834, "end_offset": 873}, {"id": 1093920, "label": "ENT", "start_offset": 928, "end_offset": 948}, {"id": 1093921, "label": "ENT", "start_offset": 981, "end_offset": 995}, {"id": 1093922, "label": "ENT", "start_offset": 1077, "end_offset": 1083}], "relations": [{"id": 176939, "from_id": 1093901, "to_id": 1093904, "type": "COREF"}, {"id": 176940, "from_id": 1093903, "to_id": 1093904, "type": "USED-FOR"}, {"id": 176941, "from_id": 1093905, "to_id": 1093903, "type": "PART-OF"}, {"id": 176942, "from_id": 1093906, "to_id": 1093905, "type": "USED-FOR"}, {"id": 176943, "from_id": 1093907, "to_id": 1093908, "type": "CONJUNCTION"}, {"id": 176944, "from_id": 1093907, "to_id": 1093906, "type": "USED-FOR"}, {"id": 176945, "from_id": 1093908, "to_id": 1093906, "type": "USED-FOR"}, {"id": 176946, "from_id": 1093910, "to_id": 1093909, "type": "COREF"}, {"id": 176947, "from_id": 1093914, "to_id": 1093913, "type": "USED-FOR"}, {"id": 176948, "from_id": 1093912, "to_id": 1093913, "type": "USED-FOR"}, {"id": 176949, "from_id": 1093915, "to_id": 1093916, "type": "USED-FOR"}, {"id": 176950, "from_id": 1093916, "to_id": 1093905, "type": "COREF"}, {"id": 176951, "from_id": 1093912, "to_id": 1093918, "type": "COREF"}, {"id": 176952, "from_id": 1093921, "to_id": 1093920, "type": "USED-FOR"}, {"id": 176953, "from_id": 1093919, "to_id": 1093922, "type": "COREF"}]}
{"id": "L08-1154", "text": " Existing techniques extract  term candidates  by looking for  internal and contextual information  associated with  domain specific terms . The algorithms always face the dilemma that fewer  features  are not enough to distinguish  terms  from  non-terms  whereas more  features  lead to more conflicts among selected  features . This paper presents a novel approach for  term extraction  based on  delimiters  which are much more stable and domain independent. The proposed approach is not as sensitive to  term frequency  as that of previous works. This approach has no strict limit or  hard rules  and thus they can deal with all kinds of  terms . It also requires no prior  domain knowledge  and no additional  training  to adapt to new  domains . Consequently, the proposed approach can be applied to different  domains  easily and it is especially useful for  resource-limited domains . Evaluations conducted on two different  domains  for  Chinese term extraction  show significant improvements over existing techniques which verifies its efficiency and domain independent nature. Experiments on  new term extraction  indicate that the proposed approach can also serve as an effective tool for  domain lexicon expansion . ", "Comments": [], "entities": [{"id": 1093959, "label": "ENT", "start_offset": 63, "end_offset": 98}, {"id": 1093960, "label": "ENT", "start_offset": 117, "end_offset": 138}, {"id": 1093961, "label": "ENT", "start_offset": 192, "end_offset": 200}, {"id": 1093962, "label": "ENT", "start_offset": 271, "end_offset": 279}, {"id": 1093963, "label": "ENT", "start_offset": 359, "end_offset": 367}, {"id": 1093964, "label": "ENT", "start_offset": 373, "end_offset": 388}, {"id": 1093965, "label": "ENT", "start_offset": 400, "end_offset": 410}, {"id": 1093966, "label": "ENT", "start_offset": 476, "end_offset": 484}, {"id": 1093967, "label": "ENT", "start_offset": 509, "end_offset": 523}, {"id": 1093968, "label": "ENT", "start_offset": 557, "end_offset": 565}, {"id": 1093969, "label": "ENT", "start_offset": 590, "end_offset": 600}, {"id": 1093970, "label": "ENT", "start_offset": 679, "end_offset": 695}, {"id": 1093971, "label": "ENT", "start_offset": 780, "end_offset": 788}, {"id": 1093972, "label": "ENT", "start_offset": 838, "end_offset": 840}, {"id": 1093973, "label": "ENT", "start_offset": 867, "end_offset": 891}, {"id": 1093974, "label": "ENT", "start_offset": 894, "end_offset": 905}, {"id": 1093975, "label": "ENT", "start_offset": 948, "end_offset": 971}, {"id": 1093976, "label": "ENT", "start_offset": 1105, "end_offset": 1124}, {"id": 1093977, "label": "ENT", "start_offset": 1153, "end_offset": 1161}, {"id": 1093978, "label": "ENT", "start_offset": 1193, "end_offset": 1197}, {"id": 1093979, "label": "ENT", "start_offset": 1203, "end_offset": 1227}], "relations": [{"id": 176978, "from_id": 1093960, "to_id": 1093959, "type": "FEATURE-OF"}, {"id": 176979, "from_id": 1093963, "to_id": 1093964, "type": "USED-FOR"}, {"id": 176980, "from_id": 1093965, "to_id": 1093963, "type": "USED-FOR"}, {"id": 176981, "from_id": 1093966, "to_id": 1093963, "type": "COREF"}, {"id": 176982, "from_id": 1093966, "to_id": 1093967, "type": "COMPARE"}, {"id": 176983, "from_id": 1093968, "to_id": 1093966, "type": "COREF"}, {"id": 176984, "from_id": 1093971, "to_id": 1093968, "type": "COREF"}, {"id": 176985, "from_id": 1093971, "to_id": 1093972, "type": "COREF"}, {"id": 176986, "from_id": 1093972, "to_id": 1093973, "type": "USED-FOR"}, {"id": 176987, "from_id": 1093974, "to_id": 1093975, "type": "EVALUATE-FOR"}, {"id": 176988, "from_id": 1093977, "to_id": 1093971, "type": "COREF"}, {"id": 176989, "from_id": 1093977, "to_id": 1093979, "type": "USED-FOR"}, {"id": 176990, "from_id": 1093978, "to_id": 1093977, "type": "COREF"}]}
{"id": "ICML_1995_30_abs", "text": "In this paper we introduce Ant-Q, a family of algorithms which present many similarities with Q-learning (Watkins, 1989), and which we apply to the solution of symmetric and asym-metric instances of the traveling salesman problem (TSP). Ant-Q algorithms were inspired by work on the ant system (AS), a distributed algorithm for combinatorial optimization based on the metaphor of ant colonies which was recently proposed in (Dorigo, 1992; Dorigo, Maniezzo and Colorni, 1996). We show that AS is a particular instance of the Ant-Q family, and that there are instances of this family which perform better than AS. We experimentally investigate the functioning of Ant-Q and we show that the results obtained by Ant-Q on symmetric TSP's are competitive with those obtained by other heuristic approaches based on neural networks or local search. Finally, we apply Ant-Q to some difficult asymmetric TSP's obtaining very good results: Ant-Q was able to find solutions of a quality which usually can be found only by very specialized algorithms.", "Comments": [], "entities": [{"id": 1094024, "label": "ENT", "start_offset": 27, "end_offset": 32}, {"id": 1094025, "label": "ENT", "start_offset": 94, "end_offset": 104}, {"id": 1094026, "label": "ENT", "start_offset": 160, "end_offset": 235}, {"id": 1094027, "label": "ENT", "start_offset": 237, "end_offset": 253}, {"id": 1094028, "label": "ENT", "start_offset": 283, "end_offset": 298}, {"id": 1094029, "label": "ENT", "start_offset": 302, "end_offset": 323}, {"id": 1094030, "label": "ENT", "start_offset": 328, "end_offset": 354}, {"id": 1094031, "label": "ENT", "start_offset": 489, "end_offset": 491}, {"id": 1094032, "label": "ENT", "start_offset": 524, "end_offset": 536}, {"id": 1094033, "label": "ENT", "start_offset": 557, "end_offset": 566}, {"id": 1094034, "label": "ENT", "start_offset": 575, "end_offset": 581}, {"id": 1094035, "label": "ENT", "start_offset": 608, "end_offset": 610}, {"id": 1094036, "label": "ENT", "start_offset": 661, "end_offset": 666}, {"id": 1094037, "label": "ENT", "start_offset": 708, "end_offset": 713}, {"id": 1094038, "label": "ENT", "start_offset": 717, "end_offset": 730}, {"id": 1094039, "label": "ENT", "start_offset": 778, "end_offset": 798}, {"id": 1094040, "label": "ENT", "start_offset": 808, "end_offset": 823}, {"id": 1094041, "label": "ENT", "start_offset": 827, "end_offset": 839}, {"id": 1094042, "label": "ENT", "start_offset": 859, "end_offset": 864}, {"id": 1094043, "label": "ENT", "start_offset": 883, "end_offset": 897}, {"id": 1094044, "label": "ENT", "start_offset": 929, "end_offset": 934}], "relations": [{"id": 177026, "from_id": 1094029, "to_id": 1094030, "type": "USED-FOR"}, {"id": 177027, "from_id": 1094031, "to_id": 1094032, "type": "HYPONYM-OF"}, {"id": 177028, "from_id": 1094032, "to_id": 1094027, "type": "COREF"}, {"id": 177029, "from_id": 1094044, "to_id": 1094042, "type": "COREF"}, {"id": 177030, "from_id": 1094042, "to_id": 1094043, "type": "USED-FOR"}, {"id": 177031, "from_id": 1094040, "to_id": 1094041, "type": "CONJUNCTION"}, {"id": 177032, "from_id": 1094037, "to_id": 1094039, "type": "COMPARE"}, {"id": 177033, "from_id": 1094037, "to_id": 1094038, "type": "USED-FOR"}, {"id": 177034, "from_id": 1094037, "to_id": 1094036, "type": "COREF"}, {"id": 177035, "from_id": 1094042, "to_id": 1094037, "type": "COREF"}, {"id": 177036, "from_id": 1094040, "to_id": 1094039, "type": "USED-FOR"}, {"id": 177037, "from_id": 1094041, "to_id": 1094039, "type": "USED-FOR"}, {"id": 177038, "from_id": 1094024, "to_id": 1094026, "type": "USED-FOR"}, {"id": 177039, "from_id": 1094028, "to_id": 1094029, "type": "HYPONYM-OF"}, {"id": 177040, "from_id": 1094028, "to_id": 1094027, "type": "USED-FOR"}, {"id": 177041, "from_id": 1094031, "to_id": 1094028, "type": "COREF"}, {"id": 177042, "from_id": 1094034, "to_id": 1094032, "type": "COREF"}, {"id": 177043, "from_id": 1094033, "to_id": 1094034, "type": "PART-OF"}, {"id": 177044, "from_id": 1094033, "to_id": 1094035, "type": "COMPARE"}, {"id": 177045, "from_id": 1094036, "to_id": 1094032, "type": "COREF"}, {"id": 177046, "from_id": 1094038, "to_id": 1094026, "type": "HYPONYM-OF"}, {"id": 177047, "from_id": 1094043, "to_id": 1094026, "type": "HYPONYM-OF"}]}
{"id": "CVPR_2016_416_abs", "text": "We investigate the problem of fine-grained sketch-based image retrieval (SBIR), where free-hand human sketches are used as queries to perform instance-level retrieval of images. This is an extremely challenging task because (i) visual comparisons not only need to be fine-grained but also executed cross-domain, (ii) free-hand (finger) sketches are highly abstract, making fine-grained matching harder, and most importantly (iii) annotated cross-domain sketch-photo datasets required for training are scarce, challenging many state-of-the-art machine learning techniques. In this paper, for the first time, we address all these challenges, providing a step towards the capabilities that would underpin a commercial sketch-based image retrieval application. We introduce a new database of 1,432 sketch-photo pairs from two categories with 32,000 fine-grained triplet ranking annotations. We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data. Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks.", "Comments": [], "entities": [{"id": 1094045, "label": "ENT", "start_offset": 30, "end_offset": 78}, {"id": 1094046, "label": "ENT", "start_offset": 86, "end_offset": 110}, {"id": 1094047, "label": "ENT", "start_offset": 142, "end_offset": 176}, {"id": 1094048, "label": "ENT", "start_offset": 228, "end_offset": 246}, {"id": 1094049, "label": "ENT", "start_offset": 317, "end_offset": 344}, {"id": 1094050, "label": "ENT", "start_offset": 373, "end_offset": 394}, {"id": 1094051, "label": "ENT", "start_offset": 430, "end_offset": 474}, {"id": 1094052, "label": "ENT", "start_offset": 543, "end_offset": 570}, {"id": 1094053, "label": "ENT", "start_offset": 715, "end_offset": 755}, {"id": 1094054, "label": "ENT", "start_offset": 845, "end_offset": 885}, {"id": 1094055, "label": "ENT", "start_offset": 905, "end_offset": 931}, {"id": 1094056, "label": "ENT", "start_offset": 936, "end_offset": 955}, {"id": 1094057, "label": "ENT", "start_offset": 969, "end_offset": 986}, {"id": 1094058, "label": "ENT", "start_offset": 991, "end_offset": 1019}, {"id": 1094059, "label": "ENT", "start_offset": 1046, "end_offset": 1085}, {"id": 1094060, "label": "ENT", "start_offset": 1184, "end_offset": 1200}, {"id": 1094061, "label": "ENT", "start_offset": 1205, "end_offset": 1227}, {"id": 1094062, "label": "ENT", "start_offset": 1242, "end_offset": 1255}, {"id": 1094063, "label": "ENT", "start_offset": 1260, "end_offset": 1299}], "relations": [{"id": 177048, "from_id": 1094046, "to_id": 1094047, "type": "USED-FOR"}, {"id": 177049, "from_id": 1094051, "to_id": 1094052, "type": "USED-FOR"}, {"id": 177050, "from_id": 1094055, "to_id": 1094056, "type": "USED-FOR"}, {"id": 177051, "from_id": 1094057, "to_id": 1094058, "type": "CONJUNCTION"}, {"id": 177052, "from_id": 1094057, "to_id": 1094055, "type": "USED-FOR"}, {"id": 177053, "from_id": 1094058, "to_id": 1094055, "type": "USED-FOR"}, {"id": 177054, "from_id": 1094055, "to_id": 1094059, "type": "USED-FOR"}, {"id": 177055, "from_id": 1094062, "to_id": 1094063, "type": "USED-FOR"}, {"id": 177056, "from_id": 1094060, "to_id": 1094061, "type": "CONJUNCTION"}]}
{"id": "H91-1077", "text": " A method of  sense resolution  is proposed that is based on  WordNet , an on-line  lexical database  that incorporates  semantic relations  ( synonymy ,  antonymy ,  hyponymy ,  meronymy ,  causal and troponymic entailment ) as  labeled pointers  between  word senses . With  WordNet , it is easy to retrieve sets of  semantically related words , a facility that will be used for  sense resolution  during  text processing , as follows. When a  word  with multiple  senses  is encountered, one of two procedures will be followed. Either, (1)  words  related in  meaning  to the  alternative senses  of the  polysemous word  will be retrieved; new  strings  will be derived by substituting these related  words  into the  context  of the  polysemous word ; a large  textual corpus  will then be searched for these  derived strings ; and that  sense  will be chosen that corresponds to the  derived string  that is found most often in the  corpus . Or, (2) the  context  of the  polysemous word  will be used as a key to search a large  corpus ; all  words  found to occur in that  context  will be noted;  WordNet  will then be used to estimate the  semantic distance  from those  words  to the  alternative senses  of the  polysemous word ; and that  sense  will be chosen that is closest in  meaning  to other  words  occurring in the same  context  If successful, this procedure could have practical applications to problems of  information retrieval ,  mechanical translation ,  intelligent tutoring systems , and elsewhere. ", "Comments": [], "entities": [{"id": 1094192, "label": "ENT", "start_offset": 3, "end_offset": 9}, {"id": 1094193, "label": "ENT", "start_offset": 14, "end_offset": 30}, {"id": 1094194, "label": "ENT", "start_offset": 62, "end_offset": 69}, {"id": 1094195, "label": "ENT", "start_offset": 75, "end_offset": 100}, {"id": 1094196, "label": "ENT", "start_offset": 121, "end_offset": 139}, {"id": 1094197, "label": "ENT", "start_offset": 143, "end_offset": 151}, {"id": 1094198, "label": "ENT", "start_offset": 155, "end_offset": 163}, {"id": 1094199, "label": "ENT", "start_offset": 167, "end_offset": 175}, {"id": 1094200, "label": "ENT", "start_offset": 179, "end_offset": 187}, {"id": 1094201, "label": "ENT", "start_offset": 191, "end_offset": 223}, {"id": 1094202, "label": "ENT", "start_offset": 277, "end_offset": 284}, {"id": 1094203, "label": "ENT", "start_offset": 319, "end_offset": 345}, {"id": 1094204, "label": "ENT", "start_offset": 382, "end_offset": 398}, {"id": 1094205, "label": "ENT", "start_offset": 408, "end_offset": 423}, {"id": 1094206, "label": "ENT", "start_offset": 502, "end_offset": 512}, {"id": 1094207, "label": "ENT", "start_offset": 580, "end_offset": 598}, {"id": 1094208, "label": "ENT", "start_offset": 608, "end_offset": 623}, {"id": 1094209, "label": "ENT", "start_offset": 739, "end_offset": 754}, {"id": 1094210, "label": "ENT", "start_offset": 978, "end_offset": 993}, {"id": 1094211, "label": "ENT", "start_offset": 1106, "end_offset": 1113}, {"id": 1094212, "label": "ENT", "start_offset": 1150, "end_offset": 1167}, {"id": 1094213, "label": "ENT", "start_offset": 1372, "end_offset": 1381}, {"id": 1094214, "label": "ENT", "start_offset": 1432, "end_offset": 1453}, {"id": 1094215, "label": "ENT", "start_offset": 1457, "end_offset": 1479}, {"id": 1094216, "label": "ENT", "start_offset": 1483, "end_offset": 1511}], "relations": [{"id": 177167, "from_id": 1094202, "to_id": 1094203, "type": "USED-FOR"}, {"id": 177168, "from_id": 1094204, "to_id": 1094205, "type": "USED-FOR"}, {"id": 177169, "from_id": 1094211, "to_id": 1094212, "type": "USED-FOR"}, {"id": 177170, "from_id": 1094192, "to_id": 1094193, "type": "USED-FOR"}, {"id": 177171, "from_id": 1094194, "to_id": 1094192, "type": "USED-FOR"}, {"id": 177172, "from_id": 1094197, "to_id": 1094196, "type": "HYPONYM-OF"}, {"id": 177173, "from_id": 1094198, "to_id": 1094196, "type": "HYPONYM-OF"}, {"id": 177174, "from_id": 1094199, "to_id": 1094196, "type": "HYPONYM-OF"}, {"id": 177175, "from_id": 1094200, "to_id": 1094196, "type": "HYPONYM-OF"}, {"id": 177176, "from_id": 1094201, "to_id": 1094196, "type": "HYPONYM-OF"}, {"id": 177177, "from_id": 1094197, "to_id": 1094198, "type": "CONJUNCTION"}, {"id": 177178, "from_id": 1094198, "to_id": 1094199, "type": "CONJUNCTION"}, {"id": 177179, "from_id": 1094199, "to_id": 1094200, "type": "CONJUNCTION"}, {"id": 177180, "from_id": 1094200, "to_id": 1094201, "type": "CONJUNCTION"}, {"id": 177181, "from_id": 1094202, "to_id": 1094194, "type": "COREF"}, {"id": 177182, "from_id": 1094203, "to_id": 1094204, "type": "USED-FOR"}, {"id": 177183, "from_id": 1094211, "to_id": 1094202, "type": "COREF"}, {"id": 177184, "from_id": 1094213, "to_id": 1094214, "type": "USED-FOR"}, {"id": 177185, "from_id": 1094213, "to_id": 1094215, "type": "USED-FOR"}, {"id": 177186, "from_id": 1094213, "to_id": 1094216, "type": "USED-FOR"}, {"id": 177187, "from_id": 1094214, "to_id": 1094215, "type": "CONJUNCTION"}, {"id": 177188, "from_id": 1094215, "to_id": 1094216, "type": "CONJUNCTION"}, {"id": 177189, "from_id": 1094213, "to_id": 1094206, "type": "HYPONYM-OF"}, {"id": 177190, "from_id": 1094196, "to_id": 1094194, "type": "PART-OF"}, {"id": 177191, "from_id": 1094194, "to_id": 1094195, "type": "HYPONYM-OF"}]}
{"id": "AAAI_1993_70_abs", "text": "The Rete and Treat algorithms are considered the most efficient implementation techniques for Forward Chaining rule systems. These algorithms support a language of limited expressive power. Assertions are not allowed to contain variables, making universal quantification impossible to express except as a rule. In this paper we show how to support full unification in these algorithms. We also show that: Supporting full unification is costly; Full unification is not used frequently; A combination of compile time and run time checks can determine when full unification is not needed. We present data to show that the cost of supporting full unification can be reduced in proportion to the degree that it isn't employed and that for many practical systems this cost is negligible.", "Comments": [], "entities": [{"id": 1094230, "label": "ENT", "start_offset": 4, "end_offset": 29}, {"id": 1094231, "label": "ENT", "start_offset": 64, "end_offset": 89}, {"id": 1094232, "label": "ENT", "start_offset": 94, "end_offset": 123}, {"id": 1094233, "label": "ENT", "start_offset": 131, "end_offset": 141}, {"id": 1094234, "label": "ENT", "start_offset": 152, "end_offset": 188}, {"id": 1094235, "label": "ENT", "start_offset": 190, "end_offset": 200}, {"id": 1094236, "label": "ENT", "start_offset": 228, "end_offset": 237}, {"id": 1094237, "label": "ENT", "start_offset": 246, "end_offset": 270}, {"id": 1094238, "label": "ENT", "start_offset": 305, "end_offset": 309}, {"id": 1094239, "label": "ENT", "start_offset": 348, "end_offset": 364}, {"id": 1094240, "label": "ENT", "start_offset": 374, "end_offset": 384}, {"id": 1094241, "label": "ENT", "start_offset": 416, "end_offset": 432}, {"id": 1094242, "label": "ENT", "start_offset": 444, "end_offset": 460}, {"id": 1094243, "label": "ENT", "start_offset": 502, "end_offset": 514}, {"id": 1094244, "label": "ENT", "start_offset": 519, "end_offset": 527}, {"id": 1094245, "label": "ENT", "start_offset": 554, "end_offset": 570}, {"id": 1094246, "label": "ENT", "start_offset": 638, "end_offset": 654}, {"id": 1094247, "label": "ENT", "start_offset": 703, "end_offset": 705}], "relations": [{"id": 177200, "from_id": 1094230, "to_id": 1094231, "type": "HYPONYM-OF"}, {"id": 177201, "from_id": 1094230, "to_id": 1094232, "type": "USED-FOR"}, {"id": 177202, "from_id": 1094233, "to_id": 1094230, "type": "COREF"}, {"id": 177203, "from_id": 1094240, "to_id": 1094233, "type": "COREF"}, {"id": 177204, "from_id": 1094240, "to_id": 1094239, "type": "USED-FOR"}, {"id": 177205, "from_id": 1094246, "to_id": 1094245, "type": "COREF"}, {"id": 177206, "from_id": 1094245, "to_id": 1094242, "type": "COREF"}, {"id": 177207, "from_id": 1094242, "to_id": 1094241, "type": "COREF"}, {"id": 177208, "from_id": 1094247, "to_id": 1094246, "type": "COREF"}, {"id": 177209, "from_id": 1094241, "to_id": 1094239, "type": "COREF"}, {"id": 177210, "from_id": 1094233, "to_id": 1094234, "type": "USED-FOR"}, {"id": 177211, "from_id": 1094243, "to_id": 1094244, "type": "CONJUNCTION"}, {"id": 177212, "from_id": 1094244, "to_id": 1094245, "type": "EVALUATE-FOR"}, {"id": 177213, "from_id": 1094243, "to_id": 1094245, "type": "EVALUATE-FOR"}]}
{"id": "I05-4010", "text": " In this paper we present our recent work on harvesting  English-Chinese bitexts  of the laws of Hong Kong from the  Web  and aligning them to the  subparagraph  level via utilizing the  numbering system  in the  legal text hierarchy  . Basic methodology and practical techniques are reported in detail. The resultant  bilingual corpus  , 10.4M  English words  and 18.3M  Chinese characters  , is an authoritative and comprehensive  text collection  covering the specific and special domain of HK laws. It is particularly valuable to  empirical MT research  . This piece of work has also laid a foundation for exploring and harvesting  English-Chinese bitexts  in a larger volume from the  Web  . ", "Comments": [], "entities": [{"id": 1094580, "label": "ENT", "start_offset": 57, "end_offset": 80}, {"id": 1094581, "label": "ENT", "start_offset": 135, "end_offset": 139}, {"id": 1094582, "label": "ENT", "start_offset": 187, "end_offset": 203}, {"id": 1094583, "label": "ENT", "start_offset": 213, "end_offset": 233}, {"id": 1094584, "label": "ENT", "start_offset": 319, "end_offset": 335}, {"id": 1094585, "label": "ENT", "start_offset": 503, "end_offset": 505}, {"id": 1094586, "label": "ENT", "start_offset": 535, "end_offset": 556}, {"id": 1094587, "label": "ENT", "start_offset": 636, "end_offset": 659}], "relations": [{"id": 177476, "from_id": 1094581, "to_id": 1094580, "type": "COREF"}, {"id": 177477, "from_id": 1094585, "to_id": 1094584, "type": "COREF"}, {"id": 177478, "from_id": 1094585, "to_id": 1094586, "type": "USED-FOR"}, {"id": 177479, "from_id": 1094587, "to_id": 1094580, "type": "COREF"}]}
{"id": "CVPR_2007_11_abs", "text": "This paper proposes a framework in which Lagrangian Particle Dynamics is used for the segmentation of high density crowd flows and detection of flow instabilities. For this purpose, a flow field generated by a moving crowd is treated as an aperiodic dynamical system. A grid of particles is overlaid on the flow field, and is advected using a numerical integration scheme. The evolution of particles through the flow is tracked using a Flow Map, whose spatial gradients are subsequently used to setup a Cauchy Green Deformation tensor for quantifying the amount by which the neighboring particles have diverged over the length of the integration. The maximum eigenvalue of the tensor is used to construct a Finite Time Lyapunov Exponent (FTLE) field, which reveals the Lagrangian Coherent Structures (LCS) present in the underlying flow. The LCS divide flow into regions of qualitatively different dynamics and are used to locate boundaries of the flow segments in a normalized cuts framework. Any change in the number of flow segments over time is regarded as an instability, which is detected by establishing correspondences between flow segments over time. The experiments are conducted on a challenging set of videos taken from Google Video and a National Geographic documentary.", "Comments": [], "entities": [{"id": 1094639, "label": "ENT", "start_offset": 41, "end_offset": 69}, {"id": 1094640, "label": "ENT", "start_offset": 86, "end_offset": 126}, {"id": 1094641, "label": "ENT", "start_offset": 131, "end_offset": 162}, {"id": 1094642, "label": "ENT", "start_offset": 184, "end_offset": 194}, {"id": 1094643, "label": "ENT", "start_offset": 210, "end_offset": 222}, {"id": 1094644, "label": "ENT", "start_offset": 240, "end_offset": 266}, {"id": 1094645, "label": "ENT", "start_offset": 270, "end_offset": 287}, {"id": 1094646, "label": "ENT", "start_offset": 307, "end_offset": 317}, {"id": 1094647, "label": "ENT", "start_offset": 343, "end_offset": 371}, {"id": 1094648, "label": "ENT", "start_offset": 377, "end_offset": 399}, {"id": 1094649, "label": "ENT", "start_offset": 436, "end_offset": 444}, {"id": 1094650, "label": "ENT", "start_offset": 452, "end_offset": 469}, {"id": 1094651, "label": "ENT", "start_offset": 503, "end_offset": 534}, {"id": 1094652, "label": "ENT", "start_offset": 651, "end_offset": 669}, {"id": 1094653, "label": "ENT", "start_offset": 677, "end_offset": 683}, {"id": 1094654, "label": "ENT", "start_offset": 707, "end_offset": 749}, {"id": 1094655, "label": "ENT", "start_offset": 769, "end_offset": 805}, {"id": 1094656, "label": "ENT", "start_offset": 842, "end_offset": 845}, {"id": 1094657, "label": "ENT", "start_offset": 930, "end_offset": 961}, {"id": 1094658, "label": "ENT", "start_offset": 967, "end_offset": 992}, {"id": 1094659, "label": "ENT", "start_offset": 1232, "end_offset": 1244}, {"id": 1094660, "label": "ENT", "start_offset": 1251, "end_offset": 1282}], "relations": [{"id": 177525, "from_id": 1094639, "to_id": 1094640, "type": "USED-FOR"}, {"id": 177526, "from_id": 1094639, "to_id": 1094641, "type": "USED-FOR"}, {"id": 177527, "from_id": 1094643, "to_id": 1094642, "type": "USED-FOR"}, {"id": 177528, "from_id": 1094644, "to_id": 1094642, "type": "USED-FOR"}, {"id": 177529, "from_id": 1094642, "to_id": 1094646, "type": "COREF"}, {"id": 177530, "from_id": 1094653, "to_id": 1094651, "type": "COREF"}, {"id": 177531, "from_id": 1094652, "to_id": 1094653, "type": "FEATURE-OF"}, {"id": 177532, "from_id": 1094652, "to_id": 1094654, "type": "USED-FOR"}, {"id": 177533, "from_id": 1094654, "to_id": 1094655, "type": "USED-FOR"}, {"id": 177534, "from_id": 1094656, "to_id": 1094655, "type": "COREF"}, {"id": 177535, "from_id": 1094656, "to_id": 1094657, "type": "USED-FOR"}, {"id": 177536, "from_id": 1094658, "to_id": 1094657, "type": "USED-FOR"}, {"id": 177537, "from_id": 1094659, "to_id": 1094660, "type": "CONJUNCTION"}, {"id": 177538, "from_id": 1094640, "to_id": 1094641, "type": "CONJUNCTION"}, {"id": 177539, "from_id": 1094645, "to_id": 1094646, "type": "USED-FOR"}, {"id": 177540, "from_id": 1094647, "to_id": 1094645, "type": "USED-FOR"}, {"id": 177541, "from_id": 1094649, "to_id": 1094648, "type": "USED-FOR"}, {"id": 177542, "from_id": 1094650, "to_id": 1094651, "type": "USED-FOR"}]}
{"id": "E93-1025", "text": "  We give an analysis of  ellipsis resolution  in terms of a straightforward  discourse copying algorithm  that correctly predicts a wide range of phenomena. The treatment does not suffer from problems inherent in  identity-of-relations analyses . Furthermore, in contrast to the approach of Dalrymple et al. [1991], the treatment directly encodes the intuitive distinction between  full NPs  and the  referential elements  that corefer with them through what we term  role linking . The correct  predictions  for several problematic examples of  ellipsis  naturally result. Finally, the analysis extends directly to other  discourse copying phenomena . ", "Comments": [], "entities": [{"id": 1094754, "label": "ENT", "start_offset": 13, "end_offset": 45}, {"id": 1094755, "label": "ENT", "start_offset": 78, "end_offset": 105}, {"id": 1094756, "label": "ENT", "start_offset": 162, "end_offset": 171}, {"id": 1094757, "label": "ENT", "start_offset": 215, "end_offset": 245}, {"id": 1094758, "label": "ENT", "start_offset": 321, "end_offset": 330}, {"id": 1094759, "label": "ENT", "start_offset": 383, "end_offset": 391}, {"id": 1094760, "label": "ENT", "start_offset": 402, "end_offset": 422}, {"id": 1094761, "label": "ENT", "start_offset": 469, "end_offset": 481}, {"id": 1094762, "label": "ENT", "start_offset": 547, "end_offset": 555}, {"id": 1094763, "label": "ENT", "start_offset": 588, "end_offset": 596}, {"id": 1094764, "label": "ENT", "start_offset": 624, "end_offset": 651}], "relations": [{"id": 177611, "from_id": 1094759, "to_id": 1094760, "type": "CONJUNCTION"}, {"id": 177612, "from_id": 1094758, "to_id": 1094756, "type": "COREF"}, {"id": 177613, "from_id": 1094763, "to_id": 1094764, "type": "USED-FOR"}, {"id": 177614, "from_id": 1094763, "to_id": 1094754, "type": "COREF"}, {"id": 177615, "from_id": 1094756, "to_id": 1094754, "type": "COREF"}]}
{"id": "ICCV_2015_392_abs", "text": "In this paper, we propose a new approach to generate oriented object proposals (OOPs) to reduce the detection error caused by various orientations of the object. To this end, we propose to efficiently locate object regions according to pixelwise object probability, rather than measuring the objectness from a set of sampled windows. We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes (i.e., sizes and orientations) can be produced by locating the local maximum likelihoods. The new approach has three main advantages. First, it helps the object detector handle objects of different orientations. Second, as the shapes of the proposals may vary to fit the objects, the resulting proposals are tighter than the sampling windows with fixed sizes. Third, it avoids massive window sampling, and thereby reducing the number of proposals while maintaining a high recall. Experiments on the PASCAL VOC 2007 dataset show that the proposed OOP outperforms the state-of-the-art fast methods. Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios. Generating OOPs is very fast and takes only 0.5s per image.", "Comments": [], "entities": [{"id": 1094784, "label": "ENT", "start_offset": 32, "end_offset": 40}, {"id": 1094785, "label": "ENT", "start_offset": 53, "end_offset": 85}, {"id": 1094786, "label": "ENT", "start_offset": 100, "end_offset": 115}, {"id": 1094787, "label": "ENT", "start_offset": 134, "end_offset": 160}, {"id": 1094788, "label": "ENT", "start_offset": 208, "end_offset": 222}, {"id": 1094789, "label": "ENT", "start_offset": 236, "end_offset": 264}, {"id": 1094790, "label": "ENT", "start_offset": 292, "end_offset": 302}, {"id": 1094791, "label": "ENT", "start_offset": 351, "end_offset": 378}, {"id": 1094792, "label": "ENT", "start_offset": 384, "end_offset": 415}, {"id": 1094793, "label": "ENT", "start_offset": 426, "end_offset": 442}, {"id": 1094794, "label": "ENT", "start_offset": 456, "end_offset": 462}, {"id": 1094795, "label": "ENT", "start_offset": 470, "end_offset": 475}, {"id": 1094796, "label": "ENT", "start_offset": 480, "end_offset": 492}, {"id": 1094797, "label": "ENT", "start_offset": 526, "end_offset": 551}, {"id": 1094798, "label": "ENT", "start_offset": 561, "end_offset": 569}, {"id": 1094799, "label": "ENT", "start_offset": 604, "end_offset": 606}, {"id": 1094800, "label": "ENT", "start_offset": 617, "end_offset": 632}, {"id": 1094801, "label": "ENT", "start_offset": 661, "end_offset": 673}, {"id": 1094802, "label": "ENT", "start_offset": 690, "end_offset": 713}, {"id": 1094803, "label": "ENT", "start_offset": 788, "end_offset": 804}, {"id": 1094804, "label": "ENT", "start_offset": 830, "end_offset": 832}, {"id": 1094805, "label": "ENT", "start_offset": 840, "end_offset": 863}, {"id": 1094806, "label": "ENT", "start_offset": 890, "end_offset": 909}, {"id": 1094807, "label": "ENT", "start_offset": 935, "end_offset": 941}, {"id": 1094808, "label": "ENT", "start_offset": 962, "end_offset": 985}, {"id": 1094809, "label": "ENT", "start_offset": 1009, "end_offset": 1012}, {"id": 1094810, "label": "ENT", "start_offset": 1029, "end_offset": 1058}, {"id": 1094811, "label": "ENT", "start_offset": 1094, "end_offset": 1121}, {"id": 1094812, "label": "ENT", "start_offset": 1130, "end_offset": 1160}, {"id": 1094813, "label": "ENT", "start_offset": 1214, "end_offset": 1241}, {"id": 1094814, "label": "ENT", "start_offset": 1252, "end_offset": 1277}, {"id": 1094815, "label": "ENT", "start_offset": 1281, "end_offset": 1298}, {"id": 1094816, "label": "ENT", "start_offset": 1311, "end_offset": 1315}], "relations": [{"id": 177626, "from_id": 1094786, "to_id": 1094785, "type": "EVALUATE-FOR"}, {"id": 177627, "from_id": 1094795, "to_id": 1094796, "type": "CONJUNCTION"}, {"id": 177628, "from_id": 1094792, "to_id": 1094791, "type": "USED-FOR"}, {"id": 177629, "from_id": 1094794, "to_id": 1094793, "type": "FEATURE-OF"}, {"id": 177630, "from_id": 1094809, "to_id": 1094810, "type": "COMPARE"}, {"id": 177631, "from_id": 1094811, "to_id": 1094812, "type": "USED-FOR"}, {"id": 177632, "from_id": 1094812, "to_id": 1094813, "type": "COMPARE"}, {"id": 177633, "from_id": 1094789, "to_id": 1094788, "type": "USED-FOR"}, {"id": 177634, "from_id": 1094789, "to_id": 1094790, "type": "COMPARE"}, {"id": 177635, "from_id": 1094798, "to_id": 1094792, "type": "COREF"}, {"id": 177636, "from_id": 1094804, "to_id": 1094798, "type": "COREF"}, {"id": 177637, "from_id": 1094799, "to_id": 1094798, "type": "COREF"}, {"id": 177638, "from_id": 1094807, "to_id": 1094804, "type": "EVALUATE-FOR"}, {"id": 177639, "from_id": 1094784, "to_id": 1094785, "type": "USED-FOR"}, {"id": 177640, "from_id": 1094792, "to_id": 1094784, "type": "COREF"}, {"id": 177641, "from_id": 1094800, "to_id": 1094801, "type": "USED-FOR"}, {"id": 177642, "from_id": 1094804, "to_id": 1094806, "type": "USED-FOR"}, {"id": 177643, "from_id": 1094808, "to_id": 1094809, "type": "EVALUATE-FOR"}, {"id": 177644, "from_id": 1094816, "to_id": 1094809, "type": "COREF"}, {"id": 177645, "from_id": 1094795, "to_id": 1094794, "type": "HYPONYM-OF"}, {"id": 177646, "from_id": 1094796, "to_id": 1094794, "type": "HYPONYM-OF"}, {"id": 177647, "from_id": 1094797, "to_id": 1094793, "type": "USED-FOR"}, {"id": 177648, "from_id": 1094814, "to_id": 1094815, "type": "CONJUNCTION"}, {"id": 177649, "from_id": 1094814, "to_id": 1094813, "type": "EVALUATE-FOR"}, {"id": 177650, "from_id": 1094815, "to_id": 1094813, "type": "EVALUATE-FOR"}, {"id": 177651, "from_id": 1094814, "to_id": 1094812, "type": "EVALUATE-FOR"}, {"id": 177652, "from_id": 1094815, "to_id": 1094812, "type": "EVALUATE-FOR"}]}
{"id": "P05-1032", "text": " In this paper we describe a novel  data structure  for  phrase-based statistical machine translation  which allows for the  retrieval  of arbitrarily long  phrases  while simultaneously using less  memory  than is required by current  decoder  implementations. We detail the  computational complexity  and  average retrieval times  for looking up  phrase translations  in our  suffix array-based data structure  . We show how  sampling  can be used to reduce the  retrieval time  by orders of magnitude with no loss in  translation quality  . ", "Comments": [], "entities": [{"id": 1094817, "label": "ENT", "start_offset": 36, "end_offset": 50}, {"id": 1094818, "label": "ENT", "start_offset": 57, "end_offset": 101}, {"id": 1094819, "label": "ENT", "start_offset": 125, "end_offset": 164}, {"id": 1094820, "label": "ENT", "start_offset": 199, "end_offset": 205}, {"id": 1094821, "label": "ENT", "start_offset": 236, "end_offset": 243}, {"id": 1094822, "label": "ENT", "start_offset": 277, "end_offset": 301}, {"id": 1094823, "label": "ENT", "start_offset": 308, "end_offset": 331}, {"id": 1094824, "label": "ENT", "start_offset": 349, "end_offset": 368}, {"id": 1094825, "label": "ENT", "start_offset": 378, "end_offset": 411}, {"id": 1094826, "label": "ENT", "start_offset": 428, "end_offset": 436}, {"id": 1094827, "label": "ENT", "start_offset": 465, "end_offset": 479}, {"id": 1094828, "label": "ENT", "start_offset": 521, "end_offset": 540}], "relations": [{"id": 177653, "from_id": 1094824, "to_id": 1094825, "type": "PART-OF"}, {"id": 177654, "from_id": 1094817, "to_id": 1094818, "type": "USED-FOR"}, {"id": 177655, "from_id": 1094817, "to_id": 1094819, "type": "USED-FOR"}, {"id": 177656, "from_id": 1094822, "to_id": 1094823, "type": "CONJUNCTION"}, {"id": 177657, "from_id": 1094827, "to_id": 1094826, "type": "EVALUATE-FOR"}, {"id": 177658, "from_id": 1094828, "to_id": 1094826, "type": "EVALUATE-FOR"}]}
{"id": "ICCV_2005_47_abs", "text": "Face images of non-frontal views under poor illumination with low resolution reduce dramatically face recognition accuracy. This is evident most compellingly by the very low recognition rate of all existing face recognition systems when applied to live CCTV camera input. In this paper, we present a Bayesian framework to perform multi-modal (such as variations in viewpoint and illumination) face image super-resolution for recognition in tensor space. Given a single modal low-resolution face image, we benefit from the multiple factor interactions of training tensor, and super-resolve its high-resolution reconstructions across different modalities for face recognition. Instead of performing pixel-domain super-resolution and recognition independently as two separate sequential processes, we integrate the tasks of super-resolution and recognition by directly computing a maximum likelihood identity parameter vector in high-resolution tensor space for recognition. We show results from multi-modal super-resolution and face recognition experiments across different imaging modalities, using low-resolution images as testing inputs and demonstrate improved recognition rates over standard tensorface and eigenface representations.", "Comments": [], "entities": [{"id": 1094933, "label": "ENT", "start_offset": 0, "end_offset": 32}, {"id": 1094934, "label": "ENT", "start_offset": 97, "end_offset": 122}, {"id": 1094935, "label": "ENT", "start_offset": 174, "end_offset": 190}, {"id": 1094936, "label": "ENT", "start_offset": 207, "end_offset": 231}, {"id": 1094937, "label": "ENT", "start_offset": 248, "end_offset": 270}, {"id": 1094938, "label": "ENT", "start_offset": 300, "end_offset": 318}, {"id": 1094939, "label": "ENT", "start_offset": 365, "end_offset": 374}, {"id": 1094940, "label": "ENT", "start_offset": 379, "end_offset": 391}, {"id": 1094941, "label": "ENT", "start_offset": 393, "end_offset": 420}, {"id": 1094942, "label": "ENT", "start_offset": 425, "end_offset": 436}, {"id": 1094943, "label": "ENT", "start_offset": 440, "end_offset": 452}, {"id": 1094944, "label": "ENT", "start_offset": 462, "end_offset": 500}, {"id": 1094945, "label": "ENT", "start_offset": 522, "end_offset": 569}, {"id": 1094946, "label": "ENT", "start_offset": 593, "end_offset": 624}, {"id": 1094947, "label": "ENT", "start_offset": 642, "end_offset": 652}, {"id": 1094948, "label": "ENT", "start_offset": 657, "end_offset": 673}, {"id": 1094949, "label": "ENT", "start_offset": 697, "end_offset": 742}, {"id": 1094950, "label": "ENT", "start_offset": 821, "end_offset": 837}, {"id": 1094951, "label": "ENT", "start_offset": 842, "end_offset": 853}, {"id": 1094952, "label": "ENT", "start_offset": 878, "end_offset": 922}, {"id": 1094953, "label": "ENT", "start_offset": 926, "end_offset": 954}, {"id": 1094954, "label": "ENT", "start_offset": 959, "end_offset": 970}, {"id": 1094955, "label": "ENT", "start_offset": 993, "end_offset": 1042}, {"id": 1094956, "label": "ENT", "start_offset": 1072, "end_offset": 1090}, {"id": 1094957, "label": "ENT", "start_offset": 1098, "end_offset": 1119}, {"id": 1094958, "label": "ENT", "start_offset": 1163, "end_offset": 1180}, {"id": 1094959, "label": "ENT", "start_offset": 1195, "end_offset": 1235}], "relations": [{"id": 177741, "from_id": 1094935, "to_id": 1094936, "type": "EVALUATE-FOR"}, {"id": 177742, "from_id": 1094937, "to_id": 1094936, "type": "USED-FOR"}, {"id": 177743, "from_id": 1094938, "to_id": 1094941, "type": "USED-FOR"}, {"id": 177744, "from_id": 1094941, "to_id": 1094942, "type": "USED-FOR"}, {"id": 177745, "from_id": 1094947, "to_id": 1094946, "type": "FEATURE-OF"}, {"id": 177746, "from_id": 1094946, "to_id": 1094948, "type": "USED-FOR"}, {"id": 177747, "from_id": 1094953, "to_id": 1094952, "type": "FEATURE-OF"}, {"id": 177748, "from_id": 1094952, "to_id": 1094954, "type": "USED-FOR"}, {"id": 177749, "from_id": 1094950, "to_id": 1094951, "type": "CONJUNCTION"}, {"id": 177750, "from_id": 1094957, "to_id": 1094955, "type": "USED-FOR"}, {"id": 177751, "from_id": 1094958, "to_id": 1094955, "type": "EVALUATE-FOR"}, {"id": 177752, "from_id": 1094958, "to_id": 1094959, "type": "EVALUATE-FOR"}, {"id": 177753, "from_id": 1094944, "to_id": 1094946, "type": "USED-FOR"}, {"id": 177754, "from_id": 1094945, "to_id": 1094946, "type": "USED-FOR"}, {"id": 177755, "from_id": 1094939, "to_id": 1094940, "type": "CONJUNCTION"}, {"id": 177756, "from_id": 1094943, "to_id": 1094942, "type": "FEATURE-OF"}, {"id": 177757, "from_id": 1094950, "to_id": 1094949, "type": "HYPONYM-OF"}, {"id": 177758, "from_id": 1094951, "to_id": 1094949, "type": "HYPONYM-OF"}, {"id": 177759, "from_id": 1094952, "to_id": 1094950, "type": "USED-FOR"}, {"id": 177760, "from_id": 1094952, "to_id": 1094951, "type": "USED-FOR"}, {"id": 177761, "from_id": 1094954, "to_id": 1094951, "type": "COREF"}, {"id": 177762, "from_id": 1094951, "to_id": 1094948, "type": "COREF"}, {"id": 177763, "from_id": 1094948, "to_id": 1094942, "type": "COREF"}, {"id": 177764, "from_id": 1094950, "to_id": 1094941, "type": "COREF"}]}
{"id": "J87-3001", "text": " This paper shows how  dictionary word sense definitions  can be analysed by applying a hierarchy of  phrasal patterns . An experimental system embodying this mechanism has been implemented for processing  definitions  from the  Longman Dictionary of Contemporary English . A property of this  dictionary , exploited by the system, is that it uses a  restricted vocabulary  in its  word sense definitions . The structures generated by the experimental system are intended to be used for the  classification  of new  word senses  in terms of the  senses  of  words  in the  restricted vocabulary . Examples illustrating the output generated are presented, and some qualitative performance results and problems that were encountered are discussed. The analysis process applies successively more specific  phrasal analysis rules  as determined by a hierarchy of  patterns  in which less specific  patterns  dominate more specific ones. This ensures that reasonable incomplete analyses of the  definitions  are produced when more complete analyses are not possible, resulting in a relatively robust  analysis mechanism . Thus the work reported addresses two  robustness problems  faced by current experimental  natural language processing systems : coping with an incomplete  lexicon  and with incomplete  knowledge  of  phrasal constructions .  ", "Comments": [], "entities": [{"id": 1095050, "label": "ENT", "start_offset": 23, "end_offset": 56}, {"id": 1095051, "label": "ENT", "start_offset": 88, "end_offset": 118}, {"id": 1095052, "label": "ENT", "start_offset": 137, "end_offset": 143}, {"id": 1095053, "label": "ENT", "start_offset": 159, "end_offset": 168}, {"id": 1095054, "label": "ENT", "start_offset": 229, "end_offset": 271}, {"id": 1095055, "label": "ENT", "start_offset": 294, "end_offset": 304}, {"id": 1095056, "label": "ENT", "start_offset": 324, "end_offset": 330}, {"id": 1095057, "label": "ENT", "start_offset": 340, "end_offset": 342}, {"id": 1095058, "label": "ENT", "start_offset": 351, "end_offset": 372}, {"id": 1095059, "label": "ENT", "start_offset": 382, "end_offset": 404}, {"id": 1095060, "label": "ENT", "start_offset": 492, "end_offset": 527}, {"id": 1095061, "label": "ENT", "start_offset": 573, "end_offset": 594}, {"id": 1095062, "label": "ENT", "start_offset": 803, "end_offset": 825}, {"id": 1095063, "label": "ENT", "start_offset": 1155, "end_offset": 1174}, {"id": 1095064, "label": "ENT", "start_offset": 1207, "end_offset": 1242}, {"id": 1095065, "label": "ENT", "start_offset": 1260, "end_offset": 1279}, {"id": 1095066, "label": "ENT", "start_offset": 1290, "end_offset": 1338}], "relations": [{"id": 177820, "from_id": 1095058, "to_id": 1095059, "type": "USED-FOR"}, {"id": 177821, "from_id": 1095063, "to_id": 1095064, "type": "FEATURE-OF"}, {"id": 177822, "from_id": 1095055, "to_id": 1095054, "type": "COREF"}, {"id": 177823, "from_id": 1095056, "to_id": 1095052, "type": "COREF"}, {"id": 177824, "from_id": 1095055, "to_id": 1095057, "type": "COREF"}, {"id": 177825, "from_id": 1095058, "to_id": 1095057, "type": "USED-FOR"}, {"id": 177826, "from_id": 1095061, "to_id": 1095058, "type": "COREF"}, {"id": 177827, "from_id": 1095051, "to_id": 1095050, "type": "USED-FOR"}, {"id": 177828, "from_id": 1095053, "to_id": 1095051, "type": "COREF"}, {"id": 177829, "from_id": 1095053, "to_id": 1095052, "type": "PART-OF"}, {"id": 177830, "from_id": 1095061, "to_id": 1095060, "type": "USED-FOR"}, {"id": 177831, "from_id": 1095065, "to_id": 1095063, "type": "HYPONYM-OF"}, {"id": 177832, "from_id": 1095066, "to_id": 1095063, "type": "HYPONYM-OF"}]}
{"id": "I05-5009", "text": " This paper presents an  evaluation method  employing a  latent variable model  for  paraphrases  with their  contexts . We assume that the  context  of a  sentence  is indicated by a  latent variable  of the  model  as a  topic  and that the  likelihood  of each  variable  can be inferred. A  paraphrase  is evaluated for whether its  sentences  are used in the same  context . Experimental results showed that the proposed method achieves almost 60%  accuracy  and that there is not a large performance difference between the two  models . The results also revealed an upper bound of  accuracy  of 77% with the  method  when using only  topic information . ", "Comments": [], "entities": [{"id": 1095114, "label": "ENT", "start_offset": 25, "end_offset": 42}, {"id": 1095115, "label": "ENT", "start_offset": 57, "end_offset": 78}, {"id": 1095116, "label": "ENT", "start_offset": 85, "end_offset": 96}, {"id": 1095117, "label": "ENT", "start_offset": 185, "end_offset": 200}, {"id": 1095118, "label": "ENT", "start_offset": 210, "end_offset": 215}, {"id": 1095119, "label": "ENT", "start_offset": 295, "end_offset": 305}, {"id": 1095120, "label": "ENT", "start_offset": 426, "end_offset": 432}, {"id": 1095121, "label": "ENT", "start_offset": 588, "end_offset": 596}, {"id": 1095122, "label": "ENT", "start_offset": 615, "end_offset": 621}, {"id": 1095123, "label": "ENT", "start_offset": 640, "end_offset": 657}], "relations": [{"id": 177864, "from_id": 1095115, "to_id": 1095114, "type": "USED-FOR"}, {"id": 177865, "from_id": 1095118, "to_id": 1095115, "type": "COREF"}, {"id": 177866, "from_id": 1095114, "to_id": 1095116, "type": "EVALUATE-FOR"}, {"id": 177867, "from_id": 1095120, "to_id": 1095114, "type": "COREF"}, {"id": 177868, "from_id": 1095122, "to_id": 1095120, "type": "COREF"}, {"id": 177869, "from_id": 1095123, "to_id": 1095122, "type": "USED-FOR"}, {"id": 177870, "from_id": 1095121, "to_id": 1095122, "type": "EVALUATE-FOR"}]}
{"id": "A88-1001", "text": "   This paper describes a domain independent strategy for the  multimedia articulation of answers  elicited by a  natural language interface  to  database query applications  .  Multimedia answers  include  videodisc images  and heuristically-produced complete  sentences  in  text  or  text-to-speech form  .  Deictic reference  and  feedback  about the  discourse  are enabled. The  interface  thus presents the application as cooperative and conversational. ", "Comments": [], "entities": [{"id": 1095163, "label": "ENT", "start_offset": 26, "end_offset": 53}, {"id": 1095164, "label": "ENT", "start_offset": 63, "end_offset": 97}, {"id": 1095165, "label": "ENT", "start_offset": 114, "end_offset": 140}, {"id": 1095166, "label": "ENT", "start_offset": 146, "end_offset": 173}, {"id": 1095167, "label": "ENT", "start_offset": 178, "end_offset": 196}, {"id": 1095168, "label": "ENT", "start_offset": 207, "end_offset": 223}, {"id": 1095169, "label": "ENT", "start_offset": 287, "end_offset": 306}, {"id": 1095170, "label": "ENT", "start_offset": 311, "end_offset": 328}, {"id": 1095171, "label": "ENT", "start_offset": 335, "end_offset": 343}, {"id": 1095172, "label": "ENT", "start_offset": 356, "end_offset": 365}, {"id": 1095173, "label": "ENT", "start_offset": 385, "end_offset": 394}, {"id": 1095174, "label": "ENT", "start_offset": 414, "end_offset": 425}], "relations": [{"id": 177903, "from_id": 1095171, "to_id": 1095172, "type": "FEATURE-OF"}, {"id": 177904, "from_id": 1095168, "to_id": 1095167, "type": "PART-OF"}, {"id": 177905, "from_id": 1095170, "to_id": 1095172, "type": "FEATURE-OF"}, {"id": 177906, "from_id": 1095173, "to_id": 1095165, "type": "COREF"}, {"id": 177907, "from_id": 1095163, "to_id": 1095164, "type": "USED-FOR"}, {"id": 177908, "from_id": 1095165, "to_id": 1095166, "type": "USED-FOR"}, {"id": 177909, "from_id": 1095174, "to_id": 1095166, "type": "COREF"}, {"id": 177910, "from_id": 1095170, "to_id": 1095171, "type": "CONJUNCTION"}, {"id": 177911, "from_id": 1095164, "to_id": 1095165, "type": "USED-FOR"}]}
{"id": "CVPR_2014_11_abs", "text": "In this paper, we cast the problem of point cloud matching as a shape matching problem by transforming each of the given point clouds into a shape representation called the Schr\u00f6dinger distance transform (SDT) representation. This is achieved by solving a static Schr\u00f6dinger equation instead of the corresponding static Hamilton-Jacobi equation in this setting. The SDT representation is an analytic expression and following the theoretical physics literature, can be normalized to have unit L2 norm-making it a square-root density, which is identified with a point on a unit Hilbert sphere, whose intrinsic geometry is fully known. The Fisher-Rao metric, a natural metric for the space of densities leads to analytic expressions for the geodesic distance between points on this sphere. In this paper, we use the well known Riemannian framework never before used for point cloud matching, and present a novel matching algorithm. We pose point set matching under rigid and non-rigid transformations in this framework and solve for the transformations using standard nonlinear optimization techniques. Finally, to evaluate the performance of our algorithm-dubbed SDTM-we present several synthetic and real data examples along with extensive comparisons to state-of-the-art techniques. The experiments show that our algorithm outperforms state-of-the-art point set registration algorithms on many quantitative metrics.", "Comments": [], "entities": [{"id": 1095175, "label": "ENT", "start_offset": 38, "end_offset": 58}, {"id": 1095176, "label": "ENT", "start_offset": 64, "end_offset": 86}, {"id": 1095177, "label": "ENT", "start_offset": 121, "end_offset": 133}, {"id": 1095178, "label": "ENT", "start_offset": 141, "end_offset": 161}, {"id": 1095179, "label": "ENT", "start_offset": 173, "end_offset": 224}, {"id": 1095180, "label": "ENT", "start_offset": 256, "end_offset": 283}, {"id": 1095181, "label": "ENT", "start_offset": 313, "end_offset": 344}, {"id": 1095182, "label": "ENT", "start_offset": 366, "end_offset": 384}, {"id": 1095183, "label": "ENT", "start_offset": 391, "end_offset": 410}, {"id": 1095184, "label": "ENT", "start_offset": 429, "end_offset": 459}, {"id": 1095185, "label": "ENT", "start_offset": 487, "end_offset": 499}, {"id": 1095186, "label": "ENT", "start_offset": 507, "end_offset": 509}, {"id": 1095187, "label": "ENT", "start_offset": 512, "end_offset": 531}, {"id": 1095188, "label": "ENT", "start_offset": 571, "end_offset": 590}, {"id": 1095189, "label": "ENT", "start_offset": 598, "end_offset": 616}, {"id": 1095190, "label": "ENT", "start_offset": 637, "end_offset": 654}, {"id": 1095191, "label": "ENT", "start_offset": 658, "end_offset": 672}, {"id": 1095192, "label": "ENT", "start_offset": 681, "end_offset": 699}, {"id": 1095193, "label": "ENT", "start_offset": 709, "end_offset": 729}, {"id": 1095194, "label": "ENT", "start_offset": 738, "end_offset": 755}, {"id": 1095195, "label": "ENT", "start_offset": 779, "end_offset": 785}, {"id": 1095196, "label": "ENT", "start_offset": 824, "end_offset": 844}, {"id": 1095197, "label": "ENT", "start_offset": 867, "end_offset": 887}, {"id": 1095198, "label": "ENT", "start_offset": 909, "end_offset": 927}, {"id": 1095199, "label": "ENT", "start_offset": 937, "end_offset": 955}, {"id": 1095200, "label": "ENT", "start_offset": 962, "end_offset": 997}, {"id": 1095201, "label": "ENT", "start_offset": 1006, "end_offset": 1015}, {"id": 1095202, "label": "ENT", "start_offset": 1034, "end_offset": 1049}, {"id": 1095203, "label": "ENT", "start_offset": 1065, "end_offset": 1098}, {"id": 1095204, "label": "ENT", "start_offset": 1144, "end_offset": 1153}, {"id": 1095205, "label": "ENT", "start_offset": 1154, "end_offset": 1165}, {"id": 1095206, "label": "ENT", "start_offset": 1185, "end_offset": 1217}, {"id": 1095207, "label": "ENT", "start_offset": 1254, "end_offset": 1281}, {"id": 1095208, "label": "ENT", "start_offset": 1313, "end_offset": 1322}, {"id": 1095209, "label": "ENT", "start_offset": 1352, "end_offset": 1385}, {"id": 1095210, "label": "ENT", "start_offset": 1394, "end_offset": 1414}], "relations": [{"id": 177912, "from_id": 1095176, "to_id": 1095175, "type": "USED-FOR"}, {"id": 177913, "from_id": 1095179, "to_id": 1095178, "type": "HYPONYM-OF"}, {"id": 177914, "from_id": 1095178, "to_id": 1095177, "type": "USED-FOR"}, {"id": 177915, "from_id": 1095182, "to_id": 1095179, "type": "COREF"}, {"id": 177916, "from_id": 1095182, "to_id": 1095183, "type": "HYPONYM-OF"}, {"id": 177917, "from_id": 1095193, "to_id": 1095194, "type": "USED-FOR"}, {"id": 177918, "from_id": 1095188, "to_id": 1095195, "type": "COREF"}, {"id": 177919, "from_id": 1095175, "to_id": 1095197, "type": "COREF"}, {"id": 177920, "from_id": 1095196, "to_id": 1095197, "type": "USED-FOR"}, {"id": 177921, "from_id": 1095196, "to_id": 1095201, "type": "COREF"}, {"id": 177922, "from_id": 1095200, "to_id": 1095202, "type": "COREF"}, {"id": 177923, "from_id": 1095203, "to_id": 1095202, "type": "USED-FOR"}, {"id": 177924, "from_id": 1095200, "to_id": 1095199, "type": "USED-FOR"}, {"id": 177925, "from_id": 1095201, "to_id": 1095199, "type": "USED-FOR"}, {"id": 177926, "from_id": 1095205, "to_id": 1095204, "type": "COREF"}, {"id": 177927, "from_id": 1095204, "to_id": 1095207, "type": "COMPARE"}, {"id": 177928, "from_id": 1095210, "to_id": 1095209, "type": "EVALUATE-FOR"}, {"id": 177929, "from_id": 1095182, "to_id": 1095186, "type": "COREF"}, {"id": 177930, "from_id": 1095187, "to_id": 1095186, "type": "USED-FOR"}, {"id": 177931, "from_id": 1095185, "to_id": 1095182, "type": "PART-OF"}, {"id": 177932, "from_id": 1095190, "to_id": 1095191, "type": "COREF"}, {"id": 177933, "from_id": 1095191, "to_id": 1095192, "type": "USED-FOR"}, {"id": 177934, "from_id": 1095208, "to_id": 1095209, "type": "COMPARE"}, {"id": 177935, "from_id": 1095208, "to_id": 1095204, "type": "COREF"}, {"id": 177936, "from_id": 1095210, "to_id": 1095208, "type": "EVALUATE-FOR"}, {"id": 177937, "from_id": 1095189, "to_id": 1095188, "type": "FEATURE-OF"}]}
{"id": "E99-1023", "text": " Dividing  sentences  in  chunks of words  is a useful preprocessing step for  parsing ,  information extraction  and  information retrieval . (Ramshaw and Marcus, 1995) have introduced a \"convenient\"  data representation  for  chunking  by converting it to a  tagging task . In this paper we will examine seven different  data representations  for the problem of recognizing  noun phrase chunks . We will show that the  data representation choice  has a minor influence on  chunking performance . However, equipped with the most suitable data representation , our  memory-based learning chunker  was able to improve the best published  chunking results  for a  standard data set . ", "Comments": [], "entities": [{"id": 1095305, "label": "ENT", "start_offset": 1, "end_offset": 41}, {"id": 1095306, "label": "ENT", "start_offset": 79, "end_offset": 86}, {"id": 1095307, "label": "ENT", "start_offset": 90, "end_offset": 112}, {"id": 1095308, "label": "ENT", "start_offset": 119, "end_offset": 140}, {"id": 1095309, "label": "ENT", "start_offset": 202, "end_offset": 221}, {"id": 1095310, "label": "ENT", "start_offset": 228, "end_offset": 236}, {"id": 1095311, "label": "ENT", "start_offset": 252, "end_offset": 254}, {"id": 1095312, "label": "ENT", "start_offset": 261, "end_offset": 273}, {"id": 1095313, "label": "ENT", "start_offset": 323, "end_offset": 343}, {"id": 1095314, "label": "ENT", "start_offset": 364, "end_offset": 395}, {"id": 1095315, "label": "ENT", "start_offset": 421, "end_offset": 440}, {"id": 1095316, "label": "ENT", "start_offset": 475, "end_offset": 483}, {"id": 1095317, "label": "ENT", "start_offset": 539, "end_offset": 558}, {"id": 1095318, "label": "ENT", "start_offset": 566, "end_offset": 595}, {"id": 1095319, "label": "ENT", "start_offset": 637, "end_offset": 645}, {"id": 1095320, "label": "ENT", "start_offset": 671, "end_offset": 679}], "relations": [{"id": 178006, "from_id": 1095309, "to_id": 1095310, "type": "USED-FOR"}, {"id": 178007, "from_id": 1095306, "to_id": 1095307, "type": "CONJUNCTION"}, {"id": 178008, "from_id": 1095307, "to_id": 1095308, "type": "CONJUNCTION"}, {"id": 178009, "from_id": 1095317, "to_id": 1095318, "type": "USED-FOR"}, {"id": 178010, "from_id": 1095320, "to_id": 1095318, "type": "EVALUATE-FOR"}, {"id": 178011, "from_id": 1095305, "to_id": 1095306, "type": "USED-FOR"}, {"id": 178012, "from_id": 1095305, "to_id": 1095307, "type": "USED-FOR"}, {"id": 178013, "from_id": 1095305, "to_id": 1095308, "type": "USED-FOR"}, {"id": 178014, "from_id": 1095310, "to_id": 1095305, "type": "COREF"}, {"id": 178015, "from_id": 1095311, "to_id": 1095310, "type": "COREF"}, {"id": 178016, "from_id": 1095313, "to_id": 1095314, "type": "USED-FOR"}, {"id": 178017, "from_id": 1095310, "to_id": 1095316, "type": "COREF"}, {"id": 178018, "from_id": 1095316, "to_id": 1095319, "type": "COREF"}]}
{"id": "N03-2003", "text": " Sources of  training data  suitable for  language modeling  of  conversational speech  are limited. In this paper, we show how  training data  can be supplemented with  text  from the  web  filtered to match the  style  and/or  topic  of the target  recognition task  , but also that it is possible to get bigger performance gains from the  data  by using  class-dependent interpolation  of  N-grams  . ", "Comments": [], "entities": [{"id": 1095434, "label": "ENT", "start_offset": 42, "end_offset": 59}, {"id": 1095435, "label": "ENT", "start_offset": 65, "end_offset": 86}, {"id": 1095436, "label": "ENT", "start_offset": 251, "end_offset": 267}, {"id": 1095437, "label": "ENT", "start_offset": 358, "end_offset": 400}], "relations": [{"id": 178114, "from_id": 1095435, "to_id": 1095434, "type": "USED-FOR"}, {"id": 178115, "from_id": 1095437, "to_id": 1095436, "type": "USED-FOR"}]}
{"id": "CVPR_2010_30_abs", "text": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions. Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation, the proposed method requires fewer evaluations of the classifier functions, thereby speeding up the search. Furthermore, we show how the recently developed efficient subwindow search (ESS) procedure [11] can be integrated into the last stage of our method. This allows us to use our method to act not only as a faster procedure for cascade evaluation, but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions, in particular kernel-ized support vector machines. Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50% by our method compared to standard cascade evaluation.", "Comments": [], "entities": [{"id": 1095470, "label": "ENT", "start_offset": 15, "end_offset": 21}, {"id": 1095471, "label": "ENT", "start_offset": 40, "end_offset": 79}, {"id": 1095472, "label": "ENT", "start_offset": 99, "end_offset": 127}, {"id": 1095473, "label": "ENT", "start_offset": 135, "end_offset": 161}, {"id": 1095474, "label": "ENT", "start_offset": 179, "end_offset": 199}, {"id": 1095475, "label": "ENT", "start_offset": 242, "end_offset": 260}, {"id": 1095476, "label": "ENT", "start_offset": 275, "end_offset": 281}, {"id": 1095477, "label": "ENT", "start_offset": 316, "end_offset": 336}, {"id": 1095478, "label": "ENT", "start_offset": 362, "end_offset": 368}, {"id": 1095479, "label": "ENT", "start_offset": 428, "end_offset": 460}, {"id": 1095480, "label": "ENT", "start_offset": 511, "end_offset": 517}, {"id": 1095481, "label": "ENT", "start_offset": 545, "end_offset": 551}, {"id": 1095482, "label": "ENT", "start_offset": 594, "end_offset": 612}, {"id": 1095483, "label": "ENT", "start_offset": 654, "end_offset": 687}, {"id": 1095484, "label": "ENT", "start_offset": 693, "end_offset": 720}, {"id": 1095485, "label": "ENT", "start_offset": 736, "end_offset": 771}, {"id": 1095486, "label": "ENT", "start_offset": 792, "end_offset": 815}, {"id": 1095487, "label": "ENT", "start_offset": 861, "end_offset": 867}, {"id": 1095488, "label": "ENT", "start_offset": 889, "end_offset": 907}], "relations": [{"id": 178143, "from_id": 1095470, "to_id": 1095471, "type": "USED-FOR"}, {"id": 178144, "from_id": 1095473, "to_id": 1095472, "type": "FEATURE-OF"}, {"id": 178145, "from_id": 1095472, "to_id": 1095470, "type": "USED-FOR"}, {"id": 178146, "from_id": 1095471, "to_id": 1095475, "type": "COREF"}, {"id": 178147, "from_id": 1095476, "to_id": 1095470, "type": "COREF"}, {"id": 178148, "from_id": 1095474, "to_id": 1095475, "type": "USED-FOR"}, {"id": 178149, "from_id": 1095474, "to_id": 1095476, "type": "COMPARE"}, {"id": 178150, "from_id": 1095476, "to_id": 1095478, "type": "USED-FOR"}, {"id": 178151, "from_id": 1095480, "to_id": 1095476, "type": "COREF"}, {"id": 178152, "from_id": 1095479, "to_id": 1095480, "type": "PART-OF"}, {"id": 178153, "from_id": 1095481, "to_id": 1095480, "type": "COREF"}, {"id": 178154, "from_id": 1095481, "to_id": 1095482, "type": "USED-FOR"}, {"id": 178155, "from_id": 1095481, "to_id": 1095483, "type": "USED-FOR"}, {"id": 178156, "from_id": 1095487, "to_id": 1095481, "type": "COREF"}, {"id": 178157, "from_id": 1095486, "to_id": 1095487, "type": "EVALUATE-FOR"}, {"id": 178158, "from_id": 1095486, "to_id": 1095488, "type": "EVALUATE-FOR"}, {"id": 178159, "from_id": 1095488, "to_id": 1095487, "type": "COMPARE"}, {"id": 178160, "from_id": 1095484, "to_id": 1095483, "type": "USED-FOR"}, {"id": 178161, "from_id": 1095485, "to_id": 1095484, "type": "HYPONYM-OF"}]}
{"id": "ICCV_2011_47_abs", "text": "We present a method for detecting 3D objects using multi-modalities. While it is generic, we demonstrate it on the combination of an image and a dense depth map which give complementary object information. It works in real-time, under heavy clutter, does not require a time consuming training stage, and can handle untextured objects. It is based on an efficient representation of templates that capture the different modalities, and we show in many experiments on commodity hardware that our approach significantly outperforms state-of-the-art methods on single modalities.", "Comments": [], "entities": [{"id": 1095529, "label": "ENT", "start_offset": 13, "end_offset": 19}, {"id": 1095530, "label": "ENT", "start_offset": 24, "end_offset": 44}, {"id": 1095531, "label": "ENT", "start_offset": 51, "end_offset": 67}, {"id": 1095532, "label": "ENT", "start_offset": 75, "end_offset": 77}, {"id": 1095533, "label": "ENT", "start_offset": 105, "end_offset": 107}, {"id": 1095534, "label": "ENT", "start_offset": 133, "end_offset": 138}, {"id": 1095535, "label": "ENT", "start_offset": 145, "end_offset": 160}, {"id": 1095536, "label": "ENT", "start_offset": 172, "end_offset": 204}, {"id": 1095537, "label": "ENT", "start_offset": 206, "end_offset": 208}, {"id": 1095538, "label": "ENT", "start_offset": 269, "end_offset": 298}, {"id": 1095539, "label": "ENT", "start_offset": 315, "end_offset": 333}, {"id": 1095540, "label": "ENT", "start_offset": 335, "end_offset": 337}, {"id": 1095541, "label": "ENT", "start_offset": 381, "end_offset": 390}, {"id": 1095542, "label": "ENT", "start_offset": 418, "end_offset": 428}, {"id": 1095543, "label": "ENT", "start_offset": 465, "end_offset": 483}, {"id": 1095544, "label": "ENT", "start_offset": 493, "end_offset": 501}, {"id": 1095545, "label": "ENT", "start_offset": 528, "end_offset": 552}, {"id": 1095546, "label": "ENT", "start_offset": 556, "end_offset": 573}], "relations": [{"id": 178194, "from_id": 1095529, "to_id": 1095530, "type": "USED-FOR"}, {"id": 178195, "from_id": 1095531, "to_id": 1095529, "type": "USED-FOR"}, {"id": 178196, "from_id": 1095532, "to_id": 1095529, "type": "COREF"}, {"id": 178197, "from_id": 1095532, "to_id": 1095533, "type": "USED-FOR"}, {"id": 178198, "from_id": 1095534, "to_id": 1095533, "type": "USED-FOR"}, {"id": 178199, "from_id": 1095535, "to_id": 1095533, "type": "USED-FOR"}, {"id": 178200, "from_id": 1095536, "to_id": 1095535, "type": "FEATURE-OF"}, {"id": 178201, "from_id": 1095534, "to_id": 1095535, "type": "CONJUNCTION"}, {"id": 178202, "from_id": 1095537, "to_id": 1095533, "type": "COREF"}, {"id": 178203, "from_id": 1095537, "to_id": 1095540, "type": "COREF"}, {"id": 178204, "from_id": 1095541, "to_id": 1095542, "type": "USED-FOR"}, {"id": 178205, "from_id": 1095544, "to_id": 1095540, "type": "COREF"}, {"id": 178206, "from_id": 1095544, "to_id": 1095545, "type": "COMPARE"}, {"id": 178207, "from_id": 1095544, "to_id": 1095546, "type": "USED-FOR"}, {"id": 178208, "from_id": 1095545, "to_id": 1095546, "type": "USED-FOR"}]}
{"id": "CVPR_2011_300_abs", "text": "We present an algorithm for calibrated camera relative pose estimation from lines. Given three lines with two of the lines parallel and orthogonal to the third we can compute the relative rotation between two images. We can also compute the relative translation from two intersection points. We also present a framework in which such lines can be detected. We evaluate the performance of the algorithm using synthetic and real data. The intended use of the algorithm is with robust hypothesize-and-test frameworks such as RANSAC. Our approach is suitable for urban and indoor environments where most lines are either parallel or orthogonal to each other.", "Comments": [], "entities": [{"id": 1095585, "label": "ENT", "start_offset": 14, "end_offset": 23}, {"id": 1095586, "label": "ENT", "start_offset": 28, "end_offset": 70}, {"id": 1095587, "label": "ENT", "start_offset": 179, "end_offset": 196}, {"id": 1095588, "label": "ENT", "start_offset": 241, "end_offset": 261}, {"id": 1095589, "label": "ENT", "start_offset": 310, "end_offset": 319}, {"id": 1095590, "label": "ENT", "start_offset": 392, "end_offset": 401}, {"id": 1095591, "label": "ENT", "start_offset": 408, "end_offset": 431}, {"id": 1095592, "label": "ENT", "start_offset": 457, "end_offset": 466}, {"id": 1095593, "label": "ENT", "start_offset": 482, "end_offset": 513}, {"id": 1095594, "label": "ENT", "start_offset": 522, "end_offset": 528}, {"id": 1095595, "label": "ENT", "start_offset": 534, "end_offset": 542}, {"id": 1095596, "label": "ENT", "start_offset": 559, "end_offset": 588}], "relations": [{"id": 178241, "from_id": 1095585, "to_id": 1095586, "type": "USED-FOR"}, {"id": 178242, "from_id": 1095590, "to_id": 1095589, "type": "COREF"}, {"id": 178243, "from_id": 1095589, "to_id": 1095585, "type": "COREF"}, {"id": 178244, "from_id": 1095591, "to_id": 1095590, "type": "USED-FOR"}, {"id": 178245, "from_id": 1095592, "to_id": 1095590, "type": "COREF"}, {"id": 178246, "from_id": 1095594, "to_id": 1095593, "type": "HYPONYM-OF"}, {"id": 178247, "from_id": 1095595, "to_id": 1095592, "type": "COREF"}, {"id": 178248, "from_id": 1095595, "to_id": 1095596, "type": "USED-FOR"}, {"id": 178249, "from_id": 1095592, "to_id": 1095593, "type": "CONJUNCTION"}]}
{"id": "CVPR_2014_18_abs", "text": "We address the problem of populating object category detection datasets with dense, per-object 3D reconstructions , bootstrapped from class labels, ground truth figure-ground segmentations and a small set of keypoint annotations. Our proposed algorithm first estimates camera viewpoint using rigid structure-from-motion, then reconstructs object shapes by optimizing over visual hull proposals guided by loose within-class shape similarity assumptions. The visual hull sampling process attempts to intersect an object's projection cone with the cones of minimal subsets of other similar objects among those pictured from certain vantage points. We show that our method is able to produce convincing per-object 3D reconstructions on one of the most challenging existing object-category detection datasets, PASCAL VOC. Our results may re-stimulate once popular geometry-oriented model-based recognition approaches.", "Comments": [], "entities": [{"id": 1095676, "label": "ENT", "start_offset": 37, "end_offset": 71}, {"id": 1095677, "label": "ENT", "start_offset": 84, "end_offset": 113}, {"id": 1095678, "label": "ENT", "start_offset": 148, "end_offset": 188}, {"id": 1095679, "label": "ENT", "start_offset": 208, "end_offset": 228}, {"id": 1095680, "label": "ENT", "start_offset": 243, "end_offset": 252}, {"id": 1095681, "label": "ENT", "start_offset": 269, "end_offset": 285}, {"id": 1095682, "label": "ENT", "start_offset": 292, "end_offset": 319}, {"id": 1095683, "label": "ENT", "start_offset": 339, "end_offset": 352}, {"id": 1095684, "label": "ENT", "start_offset": 372, "end_offset": 393}, {"id": 1095685, "label": "ENT", "start_offset": 404, "end_offset": 451}, {"id": 1095686, "label": "ENT", "start_offset": 457, "end_offset": 485}, {"id": 1095687, "label": "ENT", "start_offset": 520, "end_offset": 535}, {"id": 1095688, "label": "ENT", "start_offset": 662, "end_offset": 668}, {"id": 1095689, "label": "ENT", "start_offset": 699, "end_offset": 728}, {"id": 1095690, "label": "ENT", "start_offset": 769, "end_offset": 803}, {"id": 1095691, "label": "ENT", "start_offset": 805, "end_offset": 815}, {"id": 1095692, "label": "ENT", "start_offset": 859, "end_offset": 911}], "relations": [{"id": 178311, "from_id": 1095680, "to_id": 1095681, "type": "USED-FOR"}, {"id": 178312, "from_id": 1095682, "to_id": 1095680, "type": "USED-FOR"}, {"id": 178313, "from_id": 1095685, "to_id": 1095684, "type": "USED-FOR"}, {"id": 178314, "from_id": 1095684, "to_id": 1095683, "type": "USED-FOR"}, {"id": 178315, "from_id": 1095680, "to_id": 1095683, "type": "USED-FOR"}, {"id": 178316, "from_id": 1095688, "to_id": 1095689, "type": "USED-FOR"}, {"id": 178317, "from_id": 1095690, "to_id": 1095688, "type": "USED-FOR"}, {"id": 178318, "from_id": 1095691, "to_id": 1095690, "type": "HYPONYM-OF"}, {"id": 178319, "from_id": 1095688, "to_id": 1095680, "type": "COREF"}, {"id": 178320, "from_id": 1095677, "to_id": 1095689, "type": "COREF"}, {"id": 178321, "from_id": 1095676, "to_id": 1095677, "type": "USED-FOR"}, {"id": 178322, "from_id": 1095678, "to_id": 1095677, "type": "USED-FOR"}, {"id": 178323, "from_id": 1095679, "to_id": 1095677, "type": "USED-FOR"}, {"id": 178324, "from_id": 1095678, "to_id": 1095679, "type": "CONJUNCTION"}, {"id": 178325, "from_id": 1095690, "to_id": 1095676, "type": "COREF"}, {"id": 178326, "from_id": 1095686, "to_id": 1095684, "type": "COREF"}]}
{"id": "C04-1036", "text": " We suggest a new goal and  evaluation criterion  for  word similarity measures . The new criterion \u2013  meaning-entailing substitutability  \u2013 fits the needs of  semantic-oriented NLP applications  and can be evaluated directly (independent of an application) at a good level of  human agreement . Motivated by this  semantic criterion  we analyze the empirical quality of  distributional word feature vectors  and its impact on  word similarity results , proposing an objective measure for evaluating  feature vector quality . Finally, a novel  feature weighting and selection function  is presented, which yields superior  feature vectors  and better  word similarity performance .", "Comments": [], "entities": [{"id": 1095731, "label": "ENT", "start_offset": 28, "end_offset": 48}, {"id": 1095732, "label": "ENT", "start_offset": 55, "end_offset": 79}, {"id": 1095733, "label": "ENT", "start_offset": 90, "end_offset": 99}, {"id": 1095734, "label": "ENT", "start_offset": 103, "end_offset": 137}, {"id": 1095735, "label": "ENT", "start_offset": 160, "end_offset": 194}, {"id": 1095736, "label": "ENT", "start_offset": 278, "end_offset": 293}, {"id": 1095737, "label": "ENT", "start_offset": 315, "end_offset": 333}, {"id": 1095738, "label": "ENT", "start_offset": 372, "end_offset": 407}, {"id": 1095739, "label": "ENT", "start_offset": 428, "end_offset": 443}, {"id": 1095740, "label": "ENT", "start_offset": 477, "end_offset": 484}, {"id": 1095741, "label": "ENT", "start_offset": 501, "end_offset": 523}, {"id": 1095742, "label": "ENT", "start_offset": 544, "end_offset": 584}, {"id": 1095743, "label": "ENT", "start_offset": 623, "end_offset": 638}, {"id": 1095744, "label": "ENT", "start_offset": 652, "end_offset": 667}], "relations": [{"id": 178350, "from_id": 1095734, "to_id": 1095735, "type": "USED-FOR"}, {"id": 178351, "from_id": 1095737, "to_id": 1095738, "type": "EVALUATE-FOR"}, {"id": 178352, "from_id": 1095731, "to_id": 1095732, "type": "USED-FOR"}, {"id": 178353, "from_id": 1095733, "to_id": 1095731, "type": "COREF"}, {"id": 178354, "from_id": 1095734, "to_id": 1095733, "type": "COREF"}, {"id": 178355, "from_id": 1095737, "to_id": 1095733, "type": "COREF"}, {"id": 178356, "from_id": 1095736, "to_id": 1095734, "type": "EVALUATE-FOR"}, {"id": 178357, "from_id": 1095738, "to_id": 1095739, "type": "USED-FOR"}, {"id": 178358, "from_id": 1095740, "to_id": 1095741, "type": "EVALUATE-FOR"}, {"id": 178359, "from_id": 1095742, "to_id": 1095743, "type": "USED-FOR"}, {"id": 178360, "from_id": 1095742, "to_id": 1095744, "type": "USED-FOR"}, {"id": 178361, "from_id": 1095743, "to_id": 1095744, "type": "CONJUNCTION"}]}
{"id": "INTERSPEECH_2001_21_abs", "text": "SmartKom is a multimodal dialog system that combines speech, gesture, and mimics input and output. Spontaneous speech understanding is combined with the video-based recognition of natural gestures. One of the major scientific goals of SmartKom is to design new computational methods for the seamless integration and mutual disambiguation of multimodal input and output on a semantic and pragmatic level. SmartKom is based on the situated delegation-oriented dialog paradigm, in which the user delegates a task to a virtual communication assistant, visualized as a lifelike character on a graphical display. We describe the SmartKom architecture, the use of an XML-based markup language for multimodal content, and some of the distinguishing features of the first fully operational SmartKom demonstrator.", "Comments": [], "entities": [{"id": 1095745, "label": "ENT", "start_offset": 0, "end_offset": 8}, {"id": 1095746, "label": "ENT", "start_offset": 14, "end_offset": 38}, {"id": 1095747, "label": "ENT", "start_offset": 53, "end_offset": 59}, {"id": 1095748, "label": "ENT", "start_offset": 61, "end_offset": 68}, {"id": 1095749, "label": "ENT", "start_offset": 99, "end_offset": 131}, {"id": 1095750, "label": "ENT", "start_offset": 153, "end_offset": 196}, {"id": 1095751, "label": "ENT", "start_offset": 235, "end_offset": 243}, {"id": 1095752, "label": "ENT", "start_offset": 261, "end_offset": 282}, {"id": 1095753, "label": "ENT", "start_offset": 300, "end_offset": 368}, {"id": 1095754, "label": "ENT", "start_offset": 374, "end_offset": 402}, {"id": 1095755, "label": "ENT", "start_offset": 404, "end_offset": 412}, {"id": 1095756, "label": "ENT", "start_offset": 429, "end_offset": 473}, {"id": 1095757, "label": "ENT", "start_offset": 515, "end_offset": 546}, {"id": 1095758, "label": "ENT", "start_offset": 588, "end_offset": 605}, {"id": 1095759, "label": "ENT", "start_offset": 623, "end_offset": 644}, {"id": 1095760, "label": "ENT", "start_offset": 660, "end_offset": 685}, {"id": 1095761, "label": "ENT", "start_offset": 690, "end_offset": 708}, {"id": 1095762, "label": "ENT", "start_offset": 781, "end_offset": 802}], "relations": [{"id": 178362, "from_id": 1095745, "to_id": 1095746, "type": "HYPONYM-OF"}, {"id": 178363, "from_id": 1095749, "to_id": 1095750, "type": "CONJUNCTION"}, {"id": 178364, "from_id": 1095751, "to_id": 1095745, "type": "COREF"}, {"id": 178365, "from_id": 1095751, "to_id": 1095752, "type": "USED-FOR"}, {"id": 178366, "from_id": 1095747, "to_id": 1095748, "type": "CONJUNCTION"}, {"id": 178367, "from_id": 1095747, "to_id": 1095746, "type": "USED-FOR"}, {"id": 178368, "from_id": 1095748, "to_id": 1095746, "type": "USED-FOR"}, {"id": 178369, "from_id": 1095756, "to_id": 1095755, "type": "USED-FOR"}, {"id": 178370, "from_id": 1095751, "to_id": 1095755, "type": "COREF"}, {"id": 178371, "from_id": 1095755, "to_id": 1095759, "type": "COREF"}, {"id": 178372, "from_id": 1095760, "to_id": 1095761, "type": "USED-FOR"}, {"id": 178373, "from_id": 1095759, "to_id": 1095762, "type": "COREF"}, {"id": 178374, "from_id": 1095752, "to_id": 1095753, "type": "USED-FOR"}, {"id": 178375, "from_id": 1095754, "to_id": 1095753, "type": "FEATURE-OF"}]}
{"id": "CVPR_1994_10_abs", "text": "MINPRAN, a new robust operator, nds good ts in data sets where more than 50% of the points are outliers. Unlike other techniques that handle large outlier percentages, MINPRAN does not rely on a known error bound for the good data. Instead it assumes that the bad data are randomly (uniformly) distributed within the dynamic range of the sensor. Based on this, MINPRAN uses random sampling to search for the t and the number of inliers to the t that are least likely to have occurred randomly. It runs in time O(N 2 + SN log N), where S is the number of random samples and N is the number of data points. We demonstrate analytically that MINPRAN distinguishes good ts from ts to random data, and that MINPRAN nds accurate ts and nearly the correct number of inliers, regardless of the percentage of true inliers. MINPRAN's properties are connrmed experimentally on synthetic data and compare favorably to least median of squares. Related work applies MINPRAN to complex range and intensity data 23].", "Comments": [], "entities": [{"id": 1095888, "label": "ENT", "start_offset": 0, "end_offset": 7}, {"id": 1095889, "label": "ENT", "start_offset": 15, "end_offset": 30}, {"id": 1095890, "label": "ENT", "start_offset": 118, "end_offset": 128}, {"id": 1095891, "label": "ENT", "start_offset": 141, "end_offset": 166}, {"id": 1095892, "label": "ENT", "start_offset": 168, "end_offset": 175}, {"id": 1095893, "label": "ENT", "start_offset": 201, "end_offset": 212}, {"id": 1095894, "label": "ENT", "start_offset": 240, "end_offset": 242}, {"id": 1095895, "label": "ENT", "start_offset": 317, "end_offset": 344}, {"id": 1095896, "label": "ENT", "start_offset": 361, "end_offset": 368}, {"id": 1095897, "label": "ENT", "start_offset": 374, "end_offset": 389}, {"id": 1095898, "label": "ENT", "start_offset": 494, "end_offset": 496}, {"id": 1095899, "label": "ENT", "start_offset": 638, "end_offset": 645}, {"id": 1095900, "label": "ENT", "start_offset": 701, "end_offset": 708}, {"id": 1095901, "label": "ENT", "start_offset": 785, "end_offset": 811}, {"id": 1095902, "label": "ENT", "start_offset": 813, "end_offset": 820}, {"id": 1095903, "label": "ENT", "start_offset": 865, "end_offset": 879}, {"id": 1095904, "label": "ENT", "start_offset": 905, "end_offset": 928}, {"id": 1095905, "label": "ENT", "start_offset": 951, "end_offset": 958}, {"id": 1095906, "label": "ENT", "start_offset": 962, "end_offset": 975}, {"id": 1095907, "label": "ENT", "start_offset": 980, "end_offset": 994}], "relations": [{"id": 178464, "from_id": 1095888, "to_id": 1095889, "type": "HYPONYM-OF"}, {"id": 178465, "from_id": 1095890, "to_id": 1095891, "type": "USED-FOR"}, {"id": 178466, "from_id": 1095892, "to_id": 1095888, "type": "COREF"}, {"id": 178467, "from_id": 1095890, "to_id": 1095892, "type": "COMPARE"}, {"id": 178468, "from_id": 1095894, "to_id": 1095892, "type": "COREF"}, {"id": 178469, "from_id": 1095896, "to_id": 1095894, "type": "COREF"}, {"id": 178470, "from_id": 1095897, "to_id": 1095896, "type": "USED-FOR"}, {"id": 178471, "from_id": 1095898, "to_id": 1095896, "type": "COREF"}, {"id": 178472, "from_id": 1095899, "to_id": 1095898, "type": "COREF"}, {"id": 178473, "from_id": 1095900, "to_id": 1095899, "type": "COREF"}, {"id": 178474, "from_id": 1095902, "to_id": 1095899, "type": "COREF"}, {"id": 178475, "from_id": 1095905, "to_id": 1095902, "type": "COREF"}, {"id": 178476, "from_id": 1095903, "to_id": 1095902, "type": "EVALUATE-FOR"}, {"id": 178477, "from_id": 1095904, "to_id": 1095902, "type": "COMPARE"}, {"id": 178478, "from_id": 1095905, "to_id": 1095907, "type": "USED-FOR"}, {"id": 178479, "from_id": 1095905, "to_id": 1095906, "type": "USED-FOR"}]}
