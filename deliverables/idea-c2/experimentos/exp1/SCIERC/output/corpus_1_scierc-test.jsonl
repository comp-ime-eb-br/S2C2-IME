{"id": "N03-2025", "text": " A novel  bootstrapping approach  to  Named Entity (NE) tagging  using  concept-based seeds  and  successive learners  is presented. This approach only requires a few  common noun  or  pronoun   seeds  that correspond to the  concept  for the targeted  NE  , e.g. he/she/man/woman for  PERSON NE  . The  bootstrapping procedure  is implemented as training two  successive learners  . First,  decision list  is used to learn the  parsing-based NE rules  . Then, a  Hidden Markov Model  is trained on a  corpus  automatically tagged by the first  learner  . The resulting  NE system  approaches  supervised NE  performance for some  NE types  . ", "Comments": [], "entities": [{"id": 1089071, "label": "ENT", "start_offset": 10, "end_offset": 32}, {"id": 1089072, "label": "ENT", "start_offset": 38, "end_offset": 63}, {"id": 1089073, "label": "ENT", "start_offset": 72, "end_offset": 91}, {"id": 1089074, "label": "ENT", "start_offset": 98, "end_offset": 117}, {"id": 1089075, "label": "ENT", "start_offset": 138, "end_offset": 146}, {"id": 1089076, "label": "ENT", "start_offset": 253, "end_offset": 255}, {"id": 1089077, "label": "ENT", "start_offset": 286, "end_offset": 295}, {"id": 1089078, "label": "ENT", "start_offset": 304, "end_offset": 327}, {"id": 1089079, "label": "ENT", "start_offset": 361, "end_offset": 380}, {"id": 1089080, "label": "ENT", "start_offset": 392, "end_offset": 405}, {"id": 1089081, "label": "ENT", "start_offset": 429, "end_offset": 451}, {"id": 1089082, "label": "ENT", "start_offset": 464, "end_offset": 483}, {"id": 1089083, "label": "ENT", "start_offset": 545, "end_offset": 552}, {"id": 1089084, "label": "ENT", "start_offset": 571, "end_offset": 580}, {"id": 1089085, "label": "ENT", "start_offset": 594, "end_offset": 607}], "relations": [{"id": 173084, "from_id": 1089071, "to_id": 1089072, "type": "USED-FOR"}, {"id": 173085, "from_id": 1089080, "to_id": 1089081, "type": "USED-FOR"}, {"id": 173086, "from_id": 1089073, "to_id": 1089071, "type": "USED-FOR"}, {"id": 173087, "from_id": 1089074, "to_id": 1089071, "type": "USED-FOR"}, {"id": 173088, "from_id": 1089073, "to_id": 1089074, "type": "CONJUNCTION"}, {"id": 173089, "from_id": 1089075, "to_id": 1089071, "type": "COREF"}, {"id": 173090, "from_id": 1089077, "to_id": 1089076, "type": "HYPONYM-OF"}, {"id": 173091, "from_id": 1089078, "to_id": 1089075, "type": "COREF"}, {"id": 173092, "from_id": 1089079, "to_id": 1089078, "type": "USED-FOR"}, {"id": 173093, "from_id": 1089084, "to_id": 1089085, "type": "USED-FOR"}, {"id": 173094, "from_id": 1089083, "to_id": 1089079, "type": "HYPONYM-OF"}, {"id": 173095, "from_id": 1089079, "to_id": 1089074, "type": "COREF"}]}
{"id": "ICASSP_2011_587_abs", "text": "In this paper, we propose a novel algorithm to detect/compensate on-line interference effects when integrating Global Navigation Satellite System (GNSS) and Inertial Navigation System (INS). The GNSS/INS coupling is usually performed by an Extended Kalman Filter (EKF) which yields an accurate and robust localization. However , interference cause the GNSS measurement noise to increase unexpectedly, hence degrade the positioning accuracy. In this context , our contribution is twofold. We first study the impact of the GNSS noise inflation on the covariance of the EKF outputs so as to compute a least square estimate of the potential variance jumps. Then, this estimation is used in a Bayesian test which decides whether interference are corrupting the GNSS signal or not. It allows us to estimate their times of occurrence as well. In this way, the impaired measurements can be discarded while their impact on the navigation solution can be compensated. The results show the performance of the proposed approach on simulated data.", "Comments": [], "entities": [{"id": 1089086, "label": "ENT", "start_offset": 34, "end_offset": 43}, {"id": 1089087, "label": "ENT", "start_offset": 65, "end_offset": 93}, {"id": 1089088, "label": "ENT", "start_offset": 111, "end_offset": 152}, {"id": 1089089, "label": "ENT", "start_offset": 157, "end_offset": 189}, {"id": 1089090, "label": "ENT", "start_offset": 195, "end_offset": 212}, {"id": 1089091, "label": "ENT", "start_offset": 240, "end_offset": 268}, {"id": 1089092, "label": "ENT", "start_offset": 285, "end_offset": 317}, {"id": 1089093, "label": "ENT", "start_offset": 329, "end_offset": 341}, {"id": 1089094, "label": "ENT", "start_offset": 352, "end_offset": 374}, {"id": 1089095, "label": "ENT", "start_offset": 419, "end_offset": 439}, {"id": 1089096, "label": "ENT", "start_offset": 549, "end_offset": 559}, {"id": 1089097, "label": "ENT", "start_offset": 567, "end_offset": 578}, {"id": 1089098, "label": "ENT", "start_offset": 598, "end_offset": 619}, {"id": 1089099, "label": "ENT", "start_offset": 637, "end_offset": 651}, {"id": 1089100, "label": "ENT", "start_offset": 664, "end_offset": 674}, {"id": 1089101, "label": "ENT", "start_offset": 688, "end_offset": 701}, {"id": 1089102, "label": "ENT", "start_offset": 756, "end_offset": 767}, {"id": 1089103, "label": "ENT", "start_offset": 918, "end_offset": 937}, {"id": 1089104, "label": "ENT", "start_offset": 1007, "end_offset": 1015}, {"id": 1089105, "label": "ENT", "start_offset": 1019, "end_offset": 1033}], "relations": [{"id": 173096, "from_id": 1089086, "to_id": 1089087, "type": "USED-FOR"}, {"id": 173097, "from_id": 1089088, "to_id": 1089089, "type": "CONJUNCTION"}, {"id": 173098, "from_id": 1089091, "to_id": 1089090, "type": "USED-FOR"}, {"id": 173099, "from_id": 1089091, "to_id": 1089092, "type": "USED-FOR"}, {"id": 173100, "from_id": 1089097, "to_id": 1089096, "type": "FEATURE-OF"}, {"id": 173101, "from_id": 1089098, "to_id": 1089099, "type": "USED-FOR"}, {"id": 173102, "from_id": 1089100, "to_id": 1089098, "type": "COREF"}, {"id": 173103, "from_id": 1089100, "to_id": 1089101, "type": "USED-FOR"}, {"id": 173104, "from_id": 1089105, "to_id": 1089104, "type": "EVALUATE-FOR"}, {"id": 173105, "from_id": 1089088, "to_id": 1089090, "type": "HYPONYM-OF"}, {"id": 173106, "from_id": 1089089, "to_id": 1089090, "type": "HYPONYM-OF"}, {"id": 173107, "from_id": 1089104, "to_id": 1089101, "type": "COREF"}, {"id": 173108, "from_id": 1089101, "to_id": 1089086, "type": "COREF"}]}
{"id": "P06-2012", "text": " This paper presents an  unsupervised learning approach  to disambiguate various relations between  named entities  by use of various  lexical and syntactic features  from the  contexts  . It works by calculating  eigenvectors  of an  adjacency graph  's  Laplacian  to recover a  submanifold  of data from a  high dimensionality space  and then performing  cluster number estimation  on the  eigenvectors  . Experiment results on  ACE corpora  show that this  spectral clustering based approach  outperforms the other  clustering methods  . ", "Comments": [], "entities": [{"id": 1089106, "label": "ENT", "start_offset": 25, "end_offset": 55}, {"id": 1089107, "label": "ENT", "start_offset": 81, "end_offset": 114}, {"id": 1089108, "label": "ENT", "start_offset": 135, "end_offset": 165}, {"id": 1089109, "label": "ENT", "start_offset": 189, "end_offset": 191}, {"id": 1089110, "label": "ENT", "start_offset": 214, "end_offset": 226}, {"id": 1089111, "label": "ENT", "start_offset": 235, "end_offset": 265}, {"id": 1089112, "label": "ENT", "start_offset": 281, "end_offset": 292}, {"id": 1089113, "label": "ENT", "start_offset": 310, "end_offset": 335}, {"id": 1089114, "label": "ENT", "start_offset": 358, "end_offset": 383}, {"id": 1089115, "label": "ENT", "start_offset": 393, "end_offset": 405}, {"id": 1089116, "label": "ENT", "start_offset": 432, "end_offset": 443}, {"id": 1089117, "label": "ENT", "start_offset": 461, "end_offset": 495}, {"id": 1089118, "label": "ENT", "start_offset": 520, "end_offset": 538}], "relations": [{"id": 173109, "from_id": 1089108, "to_id": 1089106, "type": "USED-FOR"}, {"id": 173110, "from_id": 1089117, "to_id": 1089118, "type": "COMPARE"}, {"id": 173111, "from_id": 1089106, "to_id": 1089109, "type": "COREF"}, {"id": 173112, "from_id": 1089111, "to_id": 1089110, "type": "FEATURE-OF"}, {"id": 173113, "from_id": 1089110, "to_id": 1089109, "type": "USED-FOR"}, {"id": 173114, "from_id": 1089109, "to_id": 1089112, "type": "USED-FOR"}, {"id": 173115, "from_id": 1089110, "to_id": 1089115, "type": "COREF"}, {"id": 173116, "from_id": 1089114, "to_id": 1089115, "type": "USED-FOR"}, {"id": 173117, "from_id": 1089116, "to_id": 1089117, "type": "EVALUATE-FOR"}, {"id": 173118, "from_id": 1089116, "to_id": 1089118, "type": "EVALUATE-FOR"}, {"id": 173119, "from_id": 1089106, "to_id": 1089107, "type": "USED-FOR"}, {"id": 173120, "from_id": 1089113, "to_id": 1089112, "type": "USED-FOR"}, {"id": 173121, "from_id": 1089114, "to_id": 1089109, "type": "USED-FOR"}]}
{"id": "C90-3072", "text": "    Spelling-checkers  have become an integral part of most  text processing software  . From different reasons among which the speed of processing prevails they are usually based on  dictionaries of word forms  instead of  words  . This approach is sufficient for languages with little  inflection  such as  English  , but fails for  highly inflective languages  such as  Czech  ,  Russian  ,  Slovak  or other  Slavonic languages  . We have developed a special method for describing  inflection  for the purpose of building  spelling-checkers  for such languages. The speed of the resulting program lies somewhere in the middle of the scale of existing  spelling-checkers  for  English  and the main  dictionary  fits into the standard  360K floppy  , whereas the number of recognized  word forms  exceeds 6 million (for  Czech  ). Further, a special method has been developed for easy  word classification  . ", "Comments": [], "entities": [{"id": 1089119, "label": "ENT", "start_offset": 4, "end_offset": 21}, {"id": 1089120, "label": "ENT", "start_offset": 61, "end_offset": 85}, {"id": 1089121, "label": "ENT", "start_offset": 157, "end_offset": 161}, {"id": 1089122, "label": "ENT", "start_offset": 184, "end_offset": 210}, {"id": 1089123, "label": "ENT", "start_offset": 238, "end_offset": 246}, {"id": 1089124, "label": "ENT", "start_offset": 265, "end_offset": 274}, {"id": 1089125, "label": "ENT", "start_offset": 288, "end_offset": 298}, {"id": 1089126, "label": "ENT", "start_offset": 309, "end_offset": 316}, {"id": 1089127, "label": "ENT", "start_offset": 335, "end_offset": 362}, {"id": 1089128, "label": "ENT", "start_offset": 373, "end_offset": 378}, {"id": 1089129, "label": "ENT", "start_offset": 383, "end_offset": 390}, {"id": 1089130, "label": "ENT", "start_offset": 395, "end_offset": 401}, {"id": 1089131, "label": "ENT", "start_offset": 413, "end_offset": 431}, {"id": 1089132, "label": "ENT", "start_offset": 463, "end_offset": 469}, {"id": 1089133, "label": "ENT", "start_offset": 486, "end_offset": 496}, {"id": 1089134, "label": "ENT", "start_offset": 527, "end_offset": 544}, {"id": 1089135, "label": "ENT", "start_offset": 555, "end_offset": 564}, {"id": 1089136, "label": "ENT", "start_offset": 593, "end_offset": 600}, {"id": 1089137, "label": "ENT", "start_offset": 656, "end_offset": 673}, {"id": 1089138, "label": "ENT", "start_offset": 680, "end_offset": 687}, {"id": 1089139, "label": "ENT", "start_offset": 824, "end_offset": 829}, {"id": 1089140, "label": "ENT", "start_offset": 853, "end_offset": 859}, {"id": 1089141, "label": "ENT", "start_offset": 889, "end_offset": 908}], "relations": [{"id": 173122, "from_id": 1089119, "to_id": 1089120, "type": "PART-OF"}, {"id": 173123, "from_id": 1089138, "to_id": 1089137, "type": "USED-FOR"}, {"id": 173124, "from_id": 1089121, "to_id": 1089119, "type": "COREF"}, {"id": 173125, "from_id": 1089122, "to_id": 1089121, "type": "USED-FOR"}, {"id": 173126, "from_id": 1089123, "to_id": 1089122, "type": "COREF"}, {"id": 173127, "from_id": 1089126, "to_id": 1089124, "type": "HYPONYM-OF"}, {"id": 173128, "from_id": 1089128, "to_id": 1089127, "type": "HYPONYM-OF"}, {"id": 173129, "from_id": 1089129, "to_id": 1089127, "type": "HYPONYM-OF"}, {"id": 173130, "from_id": 1089130, "to_id": 1089127, "type": "HYPONYM-OF"}, {"id": 173131, "from_id": 1089131, "to_id": 1089127, "type": "HYPONYM-OF"}, {"id": 173132, "from_id": 1089134, "to_id": 1089121, "type": "COREF"}, {"id": 173133, "from_id": 1089132, "to_id": 1089133, "type": "USED-FOR"}, {"id": 173134, "from_id": 1089132, "to_id": 1089134, "type": "USED-FOR"}, {"id": 173135, "from_id": 1089135, "to_id": 1089127, "type": "COREF"}, {"id": 173136, "from_id": 1089134, "to_id": 1089135, "type": "USED-FOR"}, {"id": 173137, "from_id": 1089140, "to_id": 1089141, "type": "USED-FOR"}, {"id": 173138, "from_id": 1089136, "to_id": 1089132, "type": "COREF"}, {"id": 173139, "from_id": 1089124, "to_id": 1089123, "type": "USED-FOR"}, {"id": 173140, "from_id": 1089128, "to_id": 1089129, "type": "CONJUNCTION"}, {"id": 173141, "from_id": 1089129, "to_id": 1089130, "type": "CONJUNCTION"}, {"id": 173142, "from_id": 1089130, "to_id": 1089131, "type": "CONJUNCTION"}, {"id": 173143, "from_id": 1089125, "to_id": 1089124, "type": "FEATURE-OF"}]}
{"id": "C92-2115", "text": "   The  transfer phase  in  machine translation (MT) systems  has been considered to be more complicated than  analysis  and  generation  , since it is inherently a conglomeration of individual  lexical rules  . Currently some attempts are being made to use  case-based reasoning  in  machine translation  , that is, to make decisions on the basis of  translation examples  at appropriate pints in  MT  . This paper proposes a new type of  transfer system  , called a  Similarity-driven Transfer System (SimTran)  , for use in such  case-based MT (CBMT)  . ", "Comments": [], "entities": [{"id": 1089142, "label": "ENT", "start_offset": 8, "end_offset": 22}, {"id": 1089143, "label": "ENT", "start_offset": 28, "end_offset": 60}, {"id": 1089144, "label": "ENT", "start_offset": 111, "end_offset": 119}, {"id": 1089145, "label": "ENT", "start_offset": 126, "end_offset": 136}, {"id": 1089146, "label": "ENT", "start_offset": 146, "end_offset": 148}, {"id": 1089147, "label": "ENT", "start_offset": 195, "end_offset": 208}, {"id": 1089148, "label": "ENT", "start_offset": 259, "end_offset": 279}, {"id": 1089149, "label": "ENT", "start_offset": 285, "end_offset": 304}, {"id": 1089150, "label": "ENT", "start_offset": 399, "end_offset": 401}, {"id": 1089151, "label": "ENT", "start_offset": 440, "end_offset": 455}, {"id": 1089152, "label": "ENT", "start_offset": 469, "end_offset": 512}, {"id": 1089153, "label": "ENT", "start_offset": 533, "end_offset": 553}], "relations": [{"id": 173144, "from_id": 1089142, "to_id": 1089144, "type": "COMPARE"}, {"id": 173145, "from_id": 1089148, "to_id": 1089149, "type": "USED-FOR"}, {"id": 173146, "from_id": 1089152, "to_id": 1089153, "type": "USED-FOR"}, {"id": 173147, "from_id": 1089142, "to_id": 1089143, "type": "PART-OF"}, {"id": 173148, "from_id": 1089144, "to_id": 1089145, "type": "CONJUNCTION"}, {"id": 173149, "from_id": 1089142, "to_id": 1089145, "type": "COMPARE"}, {"id": 173150, "from_id": 1089149, "to_id": 1089143, "type": "COREF"}, {"id": 173151, "from_id": 1089150, "to_id": 1089149, "type": "COREF"}, {"id": 173152, "from_id": 1089152, "to_id": 1089151, "type": "HYPONYM-OF"}, {"id": 173153, "from_id": 1089146, "to_id": 1089142, "type": "COREF"}]}
{"id": "P05-1010", "text": " This paper defines a  generative probabilistic model  of  parse trees , which we call  PCFG-LA . This  model  is an extension of  PCFG  in which  non-terminal symbols  are augmented with  latent variables . Finegrained  CFG rules  are automatically induced from a  parsed corpus  by  training  a  PCFG-LA model  using an  EM-algorithm . Because exact  parsing  with a  PCFG-LA  is  NP-hard , several  approximations  are described and empirically compared. In experiments using the  Penn WSJ corpus , our automatically trained  model  gave a  performance  of 86.6% (F1,  sentences  < 40  words ), which is comparable to that of an  unlexicalized PCFG parser  created using extensive  manual feature selection . ", "Comments": [], "entities": [{"id": 1089154, "label": "ENT", "start_offset": 23, "end_offset": 70}, {"id": 1089155, "label": "ENT", "start_offset": 88, "end_offset": 95}, {"id": 1089156, "label": "ENT", "start_offset": 104, "end_offset": 109}, {"id": 1089157, "label": "ENT", "start_offset": 131, "end_offset": 135}, {"id": 1089158, "label": "ENT", "start_offset": 147, "end_offset": 167}, {"id": 1089159, "label": "ENT", "start_offset": 189, "end_offset": 205}, {"id": 1089160, "label": "ENT", "start_offset": 208, "end_offset": 230}, {"id": 1089161, "label": "ENT", "start_offset": 266, "end_offset": 279}, {"id": 1089162, "label": "ENT", "start_offset": 298, "end_offset": 311}, {"id": 1089163, "label": "ENT", "start_offset": 323, "end_offset": 335}, {"id": 1089164, "label": "ENT", "start_offset": 346, "end_offset": 360}, {"id": 1089165, "label": "ENT", "start_offset": 370, "end_offset": 377}, {"id": 1089166, "label": "ENT", "start_offset": 484, "end_offset": 499}, {"id": 1089167, "label": "ENT", "start_offset": 529, "end_offset": 534}, {"id": 1089168, "label": "ENT", "start_offset": 567, "end_offset": 569}, {"id": 1089169, "label": "ENT", "start_offset": 633, "end_offset": 658}, {"id": 1089170, "label": "ENT", "start_offset": 685, "end_offset": 709}], "relations": [{"id": 173154, "from_id": 1089170, "to_id": 1089169, "type": "USED-FOR"}, {"id": 173155, "from_id": 1089155, "to_id": 1089154, "type": "HYPONYM-OF"}, {"id": 173156, "from_id": 1089154, "to_id": 1089156, "type": "COREF"}, {"id": 173157, "from_id": 1089157, "to_id": 1089156, "type": "USED-FOR"}, {"id": 173158, "from_id": 1089159, "to_id": 1089158, "type": "USED-FOR"}, {"id": 173159, "from_id": 1089158, "to_id": 1089157, "type": "PART-OF"}, {"id": 173160, "from_id": 1089161, "to_id": 1089160, "type": "USED-FOR"}, {"id": 173161, "from_id": 1089163, "to_id": 1089162, "type": "USED-FOR"}, {"id": 173162, "from_id": 1089165, "to_id": 1089164, "type": "USED-FOR"}, {"id": 173163, "from_id": 1089167, "to_id": 1089169, "type": "COMPARE"}, {"id": 173164, "from_id": 1089168, "to_id": 1089167, "type": "EVALUATE-FOR"}, {"id": 173165, "from_id": 1089168, "to_id": 1089169, "type": "EVALUATE-FOR"}, {"id": 173166, "from_id": 1089166, "to_id": 1089167, "type": "EVALUATE-FOR"}, {"id": 173167, "from_id": 1089166, "to_id": 1089169, "type": "EVALUATE-FOR"}, {"id": 173168, "from_id": 1089155, "to_id": 1089162, "type": "COREF"}, {"id": 173169, "from_id": 1089162, "to_id": 1089165, "type": "COREF"}, {"id": 173170, "from_id": 1089165, "to_id": 1089167, "type": "COREF"}]}
{"id": "C08-1128", "text": "  Words  in  Chinese text  are not naturally separated by  delimiters , which poses a challenge to  standard machine translation (MT) systems . In  MT , the widely used approach is to apply a  Chinese word segmenter  trained from  manually annotated data , using a fixed  lexicon . Such  word segmentation  is not necessarily optimal for  translation . We propose a  Bayesian semi-supervised Chinese word segmentation model  which uses both  monolingual and bilingual information  to derive a  segmentation  suitable for  MT . Experiments show that our method improves a  state-of-the-art MT system  in a small and a  large data environment . ", "Comments": [], "entities": [{"id": 1089227, "label": "ENT", "start_offset": 13, "end_offset": 25}, {"id": 1089228, "label": "ENT", "start_offset": 109, "end_offset": 141}, {"id": 1089229, "label": "ENT", "start_offset": 148, "end_offset": 150}, {"id": 1089230, "label": "ENT", "start_offset": 193, "end_offset": 215}, {"id": 1089231, "label": "ENT", "start_offset": 231, "end_offset": 254}, {"id": 1089232, "label": "ENT", "start_offset": 288, "end_offset": 305}, {"id": 1089233, "label": "ENT", "start_offset": 339, "end_offset": 350}, {"id": 1089234, "label": "ENT", "start_offset": 367, "end_offset": 423}, {"id": 1089235, "label": "ENT", "start_offset": 442, "end_offset": 479}, {"id": 1089236, "label": "ENT", "start_offset": 494, "end_offset": 506}, {"id": 1089237, "label": "ENT", "start_offset": 522, "end_offset": 524}, {"id": 1089238, "label": "ENT", "start_offset": 553, "end_offset": 559}, {"id": 1089239, "label": "ENT", "start_offset": 589, "end_offset": 598}], "relations": [{"id": 173207, "from_id": 1089230, "to_id": 1089229, "type": "USED-FOR"}, {"id": 173208, "from_id": 1089235, "to_id": 1089234, "type": "USED-FOR"}, {"id": 173209, "from_id": 1089236, "to_id": 1089237, "type": "USED-FOR"}, {"id": 173210, "from_id": 1089229, "to_id": 1089228, "type": "COREF"}, {"id": 173211, "from_id": 1089231, "to_id": 1089230, "type": "USED-FOR"}, {"id": 173212, "from_id": 1089232, "to_id": 1089230, "type": "COREF"}, {"id": 173213, "from_id": 1089232, "to_id": 1089233, "type": "USED-FOR"}, {"id": 173214, "from_id": 1089233, "to_id": 1089229, "type": "COREF"}, {"id": 173215, "from_id": 1089234, "to_id": 1089236, "type": "USED-FOR"}, {"id": 173216, "from_id": 1089238, "to_id": 1089234, "type": "COREF"}, {"id": 173217, "from_id": 1089238, "to_id": 1089239, "type": "COMPARE"}, {"id": 173218, "from_id": 1089237, "to_id": 1089233, "type": "COREF"}]}
{"id": "H92-1010", "text": "   The paper provides an overview of the research conducted at  LIMSI  in the field of  speech processing  , but also in the related areas of  Human-Machine Communication  , including  Natural Language Processing  ,  Non Verbal and Multimodal Communication  . Also presented are the commercial applications of some of the research projects. When applicable, the discussion is placed in the framework of international collaborations. ", "Comments": [], "entities": [{"id": 1089268, "label": "ENT", "start_offset": 88, "end_offset": 105}, {"id": 1089269, "label": "ENT", "start_offset": 143, "end_offset": 170}, {"id": 1089270, "label": "ENT", "start_offset": 185, "end_offset": 212}, {"id": 1089271, "label": "ENT", "start_offset": 217, "end_offset": 256}], "relations": [{"id": 173234, "from_id": 1089268, "to_id": 1089269, "type": "CONJUNCTION"}, {"id": 173235, "from_id": 1089270, "to_id": 1089269, "type": "HYPONYM-OF"}, {"id": 173236, "from_id": 1089271, "to_id": 1089269, "type": "HYPONYM-OF"}, {"id": 173237, "from_id": 1089270, "to_id": 1089271, "type": "CONJUNCTION"}]}
{"id": "W02-1403", "text": "  Terminology structuring  has been the subject of much work in the context of  terms  extracted from  corpora : given a set of  terms , obtained from an existing resource or extracted from a  corpus , identifying  hierarchical (or other types of) relations  between these  terms . The present paper focusses on  terminology structuring  by  lexical methods , which match  terms  on the basis on their  content words , taking  morphological variants  into account. Experiments are done on a 'flat' list of  terms  obtained from an originally  hierarchically-structured terminology : the French version of the  US National Library of Medicine MeSH thesaurus . We compare the  lexically-induced relations  with the original  MeSH relations : after a quantitative evaluation of their congruence through  recall and precision metrics , we perform a qualitative, human analysis ofthe 'new'  relations  not present in the  MeSH . This analysis shows, on the one hand, the limits of the  lexical structuring method . On the other hand, it also reveals some specific structuring choices and  naming conventions  made by the  MeSH  designers, and emphasizes ontological commitments that cannot be left to  automatic structuring . ", "Comments": [], "entities": [{"id": 1089307, "label": "ENT", "start_offset": 2, "end_offset": 25}, {"id": 1089308, "label": "ENT", "start_offset": 193, "end_offset": 199}, {"id": 1089309, "label": "ENT", "start_offset": 215, "end_offset": 257}, {"id": 1089310, "label": "ENT", "start_offset": 313, "end_offset": 336}, {"id": 1089311, "label": "ENT", "start_offset": 342, "end_offset": 357}, {"id": 1089312, "label": "ENT", "start_offset": 427, "end_offset": 449}, {"id": 1089313, "label": "ENT", "start_offset": 543, "end_offset": 580}, {"id": 1089314, "label": "ENT", "start_offset": 610, "end_offset": 656}, {"id": 1089315, "label": "ENT", "start_offset": 675, "end_offset": 702}, {"id": 1089316, "label": "ENT", "start_offset": 723, "end_offset": 737}, {"id": 1089317, "label": "ENT", "start_offset": 801, "end_offset": 829}, {"id": 1089318, "label": "ENT", "start_offset": 917, "end_offset": 921}, {"id": 1089319, "label": "ENT", "start_offset": 981, "end_offset": 1007}, {"id": 1089320, "label": "ENT", "start_offset": 1117, "end_offset": 1121}, {"id": 1089321, "label": "ENT", "start_offset": 1197, "end_offset": 1218}], "relations": [{"id": 173277, "from_id": 1089314, "to_id": 1089313, "type": "HYPONYM-OF"}, {"id": 173278, "from_id": 1089311, "to_id": 1089310, "type": "USED-FOR"}, {"id": 173279, "from_id": 1089318, "to_id": 1089316, "type": "COREF"}, {"id": 173280, "from_id": 1089315, "to_id": 1089316, "type": "COMPARE"}, {"id": 173281, "from_id": 1089317, "to_id": 1089316, "type": "EVALUATE-FOR"}]}
{"id": "CVPR_2012_10_abs", "text": "Automated facial expression recognition has received increased attention over the past two decades. Existing works in the field usually do not encode either the temporal evolution or the intensity of the observed facial displays. They also fail to jointly model multidimensional (multi-class) continuous facial behaviour data; binary classifiers-one for each target basic-emotion class-are used instead. In this paper, intrinsic topology of multidimensional continuous facial affect data is first modeled by an ordinal man-ifold. This topology is then incorporated into the Hidden Conditional Ordinal Random Field (H-CORF) framework for dynamic ordinal regression by constraining H-CORF parameters to lie on the ordinal manifold. The resulting model attains simultaneous dynamic recognition and intensity estimation of facial expressions of multiple emotions. To the best of our knowledge, the proposed method is the first one to achieve this on both deliberate as well as spontaneous facial affect data.", "Comments": [], "entities": [{"id": 1089322, "label": "ENT", "start_offset": 0, "end_offset": 39}, {"id": 1089323, "label": "ENT", "start_offset": 100, "end_offset": 114}, {"id": 1089324, "label": "ENT", "start_offset": 161, "end_offset": 179}, {"id": 1089325, "label": "ENT", "start_offset": 187, "end_offset": 228}, {"id": 1089326, "label": "ENT", "start_offset": 230, "end_offset": 234}, {"id": 1089327, "label": "ENT", "start_offset": 262, "end_offset": 325}, {"id": 1089328, "label": "ENT", "start_offset": 327, "end_offset": 345}, {"id": 1089329, "label": "ENT", "start_offset": 419, "end_offset": 475}, {"id": 1089330, "label": "ENT", "start_offset": 511, "end_offset": 528}, {"id": 1089331, "label": "ENT", "start_offset": 535, "end_offset": 543}, {"id": 1089332, "label": "ENT", "start_offset": 574, "end_offset": 632}, {"id": 1089333, "label": "ENT", "start_offset": 637, "end_offset": 663}, {"id": 1089334, "label": "ENT", "start_offset": 680, "end_offset": 697}, {"id": 1089335, "label": "ENT", "start_offset": 712, "end_offset": 728}, {"id": 1089336, "label": "ENT", "start_offset": 744, "end_offset": 749}, {"id": 1089337, "label": "ENT", "start_offset": 758, "end_offset": 790}, {"id": 1089338, "label": "ENT", "start_offset": 795, "end_offset": 837}, {"id": 1089339, "label": "ENT", "start_offset": 890, "end_offset": 909}, {"id": 1089340, "label": "ENT", "start_offset": 973, "end_offset": 1003}], "relations": [{"id": 173282, "from_id": 1089325, "to_id": 1089324, "type": "CONJUNCTION"}, {"id": 173283, "from_id": 1089326, "to_id": 1089323, "type": "COREF"}, {"id": 173284, "from_id": 1089339, "to_id": 1089336, "type": "COREF"}, {"id": 173285, "from_id": 1089331, "to_id": 1089329, "type": "COREF"}, {"id": 173286, "from_id": 1089330, "to_id": 1089329, "type": "USED-FOR"}, {"id": 173287, "from_id": 1089331, "to_id": 1089332, "type": "PART-OF"}, {"id": 173288, "from_id": 1089332, "to_id": 1089333, "type": "USED-FOR"}, {"id": 173289, "from_id": 1089336, "to_id": 1089337, "type": "USED-FOR"}, {"id": 173290, "from_id": 1089336, "to_id": 1089338, "type": "USED-FOR"}, {"id": 173291, "from_id": 1089337, "to_id": 1089338, "type": "CONJUNCTION"}, {"id": 173292, "from_id": 1089340, "to_id": 1089339, "type": "EVALUATE-FOR"}]}
{"id": "P05-1039", "text": " In this paper, we present an  unlexicalized parser  for  German  which employs  smoothing  and  suffix analysis  to achieve a  labelled bracket F-score  of 76.2, higher than previously reported results on the  NEGRA corpus . In addition to the high  accuracy  of the model, the use of  smoothing  in an  unlexicalized parser  allows us to better examine the interplay between  smoothing  and  parsing  results. ", "Comments": [], "entities": [{"id": 1089375, "label": "ENT", "start_offset": 31, "end_offset": 51}, {"id": 1089376, "label": "ENT", "start_offset": 58, "end_offset": 64}, {"id": 1089377, "label": "ENT", "start_offset": 81, "end_offset": 90}, {"id": 1089378, "label": "ENT", "start_offset": 97, "end_offset": 112}, {"id": 1089379, "label": "ENT", "start_offset": 128, "end_offset": 152}, {"id": 1089380, "label": "ENT", "start_offset": 211, "end_offset": 223}, {"id": 1089381, "label": "ENT", "start_offset": 251, "end_offset": 259}, {"id": 1089382, "label": "ENT", "start_offset": 268, "end_offset": 273}, {"id": 1089383, "label": "ENT", "start_offset": 287, "end_offset": 296}, {"id": 1089384, "label": "ENT", "start_offset": 305, "end_offset": 325}, {"id": 1089385, "label": "ENT", "start_offset": 378, "end_offset": 387}, {"id": 1089386, "label": "ENT", "start_offset": 394, "end_offset": 401}], "relations": [{"id": 173317, "from_id": 1089375, "to_id": 1089376, "type": "USED-FOR"}, {"id": 173318, "from_id": 1089383, "to_id": 1089384, "type": "USED-FOR"}, {"id": 173319, "from_id": 1089377, "to_id": 1089375, "type": "USED-FOR"}, {"id": 173320, "from_id": 1089378, "to_id": 1089375, "type": "USED-FOR"}, {"id": 173321, "from_id": 1089379, "to_id": 1089375, "type": "EVALUATE-FOR"}, {"id": 173322, "from_id": 1089377, "to_id": 1089378, "type": "CONJUNCTION"}, {"id": 173323, "from_id": 1089381, "to_id": 1089382, "type": "EVALUATE-FOR"}, {"id": 173324, "from_id": 1089375, "to_id": 1089382, "type": "COREF"}, {"id": 173325, "from_id": 1089382, "to_id": 1089384, "type": "COREF"}, {"id": 173326, "from_id": 1089380, "to_id": 1089375, "type": "EVALUATE-FOR"}]}
{"id": "ICCV_2003_158_abs", "text": "This paper presents an algorithm for computing optical flow, shape, motion, lighting, and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination. The problem is formulated in a manner that subsumes structure from motion, multi-view stereo, and photo-metric stereo as special cases. The algorithm utilizes both spatial and temporal intensity variation as cues: the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces. The algorithm works by iteratively estimating affine camera parameters, illumination , shape, and albedo in an alternating fashion. Results are demonstrated on videos of hand-held objects moving in front of a fixed light and camera.", "Comments": [], "entities": [{"id": 1089387, "label": "ENT", "start_offset": 23, "end_offset": 32}, {"id": 1089388, "label": "ENT", "start_offset": 37, "end_offset": 96}, {"id": 1089389, "label": "ENT", "start_offset": 105, "end_offset": 119}, {"id": 1089390, "label": "ENT", "start_offset": 125, "end_offset": 157}, {"id": 1089391, "label": "ENT", "start_offset": 164, "end_offset": 184}, {"id": 1089392, "label": "ENT", "start_offset": 190, "end_offset": 197}, {"id": 1089393, "label": "ENT", "start_offset": 253, "end_offset": 259}, {"id": 1089394, "label": "ENT", "start_offset": 261, "end_offset": 278}, {"id": 1089395, "label": "ENT", "start_offset": 284, "end_offset": 303}, {"id": 1089396, "label": "ENT", "start_offset": 326, "end_offset": 335}, {"id": 1089397, "label": "ENT", "start_offset": 350, "end_offset": 390}, {"id": 1089398, "label": "ENT", "start_offset": 394, "end_offset": 398}, {"id": 1089399, "label": "ENT", "start_offset": 404, "end_offset": 410}, {"id": 1089400, "label": "ENT", "start_offset": 422, "end_offset": 426}, {"id": 1089401, "label": "ENT", "start_offset": 435, "end_offset": 441}, {"id": 1089402, "label": "ENT", "start_offset": 453, "end_offset": 472}, {"id": 1089403, "label": "ENT", "start_offset": 490, "end_offset": 494}, {"id": 1089404, "label": "ENT", "start_offset": 503, "end_offset": 566}, {"id": 1089405, "label": "ENT", "start_offset": 572, "end_offset": 581}, {"id": 1089406, "label": "ENT", "start_offset": 603, "end_offset": 672}, {"id": 1089407, "label": "ENT", "start_offset": 728, "end_offset": 755}], "relations": [{"id": 173327, "from_id": 1089390, "to_id": 1089389, "type": "FEATURE-OF"}, {"id": 173328, "from_id": 1089391, "to_id": 1089390, "type": "FEATURE-OF"}, {"id": 173329, "from_id": 1089387, "to_id": 1089388, "type": "USED-FOR"}, {"id": 173330, "from_id": 1089389, "to_id": 1089387, "type": "USED-FOR"}, {"id": 173331, "from_id": 1089388, "to_id": 1089392, "type": "COREF"}, {"id": 173332, "from_id": 1089393, "to_id": 1089394, "type": "CONJUNCTION"}, {"id": 173333, "from_id": 1089394, "to_id": 1089395, "type": "CONJUNCTION"}, {"id": 173334, "from_id": 1089401, "to_id": 1089402, "type": "USED-FOR"}, {"id": 173335, "from_id": 1089399, "to_id": 1089400, "type": "USED-FOR"}, {"id": 173336, "from_id": 1089397, "to_id": 1089398, "type": "COREF"}, {"id": 173337, "from_id": 1089399, "to_id": 1089398, "type": "HYPONYM-OF"}, {"id": 173338, "from_id": 1089401, "to_id": 1089398, "type": "HYPONYM-OF"}, {"id": 173339, "from_id": 1089399, "to_id": 1089401, "type": "CONJUNCTION"}, {"id": 173340, "from_id": 1089403, "to_id": 1089398, "type": "COREF"}, {"id": 173341, "from_id": 1089403, "to_id": 1089404, "type": "USED-FOR"}, {"id": 173342, "from_id": 1089397, "to_id": 1089396, "type": "USED-FOR"}, {"id": 173343, "from_id": 1089396, "to_id": 1089387, "type": "COREF"}, {"id": 173344, "from_id": 1089405, "to_id": 1089396, "type": "COREF"}, {"id": 173345, "from_id": 1089406, "to_id": 1089405, "type": "USED-FOR"}]}
{"id": "J86-4002", "text": "   The goal of this work is the enrichment of  human-machine interactions  in a  natural language environment  . Because a  speaker  and  listener  cannot be assured to have the same  beliefs  ,  contexts  ,  perceptions  ,  backgrounds  , or  goals  , at each point in a  conversation  , difficulties and mistakes arise when a  listener  interprets a  speaker's utterance  . These mistakes can lead to various kinds of misunderstandings between  speaker  and  listener  , including  reference failures  or failure to understand the  speaker's intention  . We call these misunderstandings  miscommunication  . Such mistakes can slow, and possibly break down,  communication  . Our goal is to recognize and isolate such  miscommunications  and circumvent them. This paper highlights a particular class of  miscommunication  ---  reference problems  --- by describing a case study and techniques for avoiding  failures of reference  . We want to illustrate a framework less restrictive than earlier ones by allowing a  speaker  leeway in forming an  utterance  about a task and in determining the conversational vehicle to deliver it. The paper also promotes a new view for  extensional reference  . ", "Comments": [], "entities": [{"id": 1089431, "label": "ENT", "start_offset": 47, "end_offset": 73}, {"id": 1089432, "label": "ENT", "start_offset": 81, "end_offset": 109}, {"id": 1089433, "label": "ENT", "start_offset": 484, "end_offset": 502}, {"id": 1089434, "label": "ENT", "start_offset": 534, "end_offset": 553}, {"id": 1089435, "label": "ENT", "start_offset": 590, "end_offset": 606}, {"id": 1089436, "label": "ENT", "start_offset": 720, "end_offset": 737}, {"id": 1089437, "label": "ENT", "start_offset": 754, "end_offset": 758}, {"id": 1089438, "label": "ENT", "start_offset": 805, "end_offset": 821}, {"id": 1089439, "label": "ENT", "start_offset": 828, "end_offset": 846}, {"id": 1089440, "label": "ENT", "start_offset": 883, "end_offset": 893}, {"id": 1089441, "label": "ENT", "start_offset": 908, "end_offset": 929}, {"id": 1089442, "label": "ENT", "start_offset": 1173, "end_offset": 1194}], "relations": [{"id": 173362, "from_id": 1089432, "to_id": 1089431, "type": "FEATURE-OF"}, {"id": 173363, "from_id": 1089437, "to_id": 1089436, "type": "COREF"}, {"id": 173364, "from_id": 1089436, "to_id": 1089435, "type": "COREF"}, {"id": 173365, "from_id": 1089438, "to_id": 1089436, "type": "COREF"}, {"id": 173366, "from_id": 1089439, "to_id": 1089438, "type": "HYPONYM-OF"}, {"id": 173367, "from_id": 1089440, "to_id": 1089441, "type": "USED-FOR"}]}
{"id": "INTERSPEECH_2013_28_abs", "text": "We attack an inexplicably under-explored language genre of spoken language\u2014lyrics in music\u2014via completely unsuper-vised induction of an SMT-style stochastic transduction grammar for hip hop lyrics, yielding a fully-automatically learned challenge-response system that produces rhyming lyrics given an input. Unlike previous efforts, we choose the domain of hip hop lyrics, which is particularly unstructured and noisy. A novel feature of our approach is that it is completely unsupervised and requires no a priori linguistic or phonetic knowledge. In spite of the level of difficulty of the challenge, the model nevertheless produces fluent output as judged by human evaluators, and performs significantly better than widely used phrase-based SMT models upon the same task.", "Comments": [], "entities": [{"id": 1089443, "label": "ENT", "start_offset": 26, "end_offset": 74}, {"id": 1089444, "label": "ENT", "start_offset": 75, "end_offset": 90}, {"id": 1089445, "label": "ENT", "start_offset": 106, "end_offset": 129}, {"id": 1089446, "label": "ENT", "start_offset": 136, "end_offset": 177}, {"id": 1089447, "label": "ENT", "start_offset": 182, "end_offset": 196}, {"id": 1089448, "label": "ENT", "start_offset": 209, "end_offset": 262}, {"id": 1089449, "label": "ENT", "start_offset": 277, "end_offset": 291}, {"id": 1089450, "label": "ENT", "start_offset": 357, "end_offset": 371}, {"id": 1089451, "label": "ENT", "start_offset": 442, "end_offset": 450}, {"id": 1089452, "label": "ENT", "start_offset": 507, "end_offset": 546}, {"id": 1089453, "label": "ENT", "start_offset": 606, "end_offset": 611}, {"id": 1089454, "label": "ENT", "start_offset": 661, "end_offset": 677}, {"id": 1089455, "label": "ENT", "start_offset": 730, "end_offset": 753}, {"id": 1089456, "label": "ENT", "start_offset": 768, "end_offset": 772}], "relations": [{"id": 173368, "from_id": 1089448, "to_id": 1089449, "type": "USED-FOR"}, {"id": 173369, "from_id": 1089444, "to_id": 1089443, "type": "HYPONYM-OF"}, {"id": 173370, "from_id": 1089445, "to_id": 1089443, "type": "USED-FOR"}, {"id": 173371, "from_id": 1089445, "to_id": 1089446, "type": "USED-FOR"}, {"id": 173372, "from_id": 1089447, "to_id": 1089446, "type": "FEATURE-OF"}, {"id": 173373, "from_id": 1089451, "to_id": 1089448, "type": "COREF"}, {"id": 173374, "from_id": 1089453, "to_id": 1089451, "type": "COREF"}, {"id": 173375, "from_id": 1089445, "to_id": 1089448, "type": "USED-FOR"}, {"id": 173376, "from_id": 1089453, "to_id": 1089455, "type": "COMPARE"}, {"id": 173377, "from_id": 1089456, "to_id": 1089455, "type": "EVALUATE-FOR"}, {"id": 173378, "from_id": 1089456, "to_id": 1089453, "type": "EVALUATE-FOR"}]}
{"id": "E93-1004", "text": " In this paper we introduce a  modal language LT for imposing  constraints  on  trees , and an extension  LT (LF)  for imposing  constraints  on  trees decorated with feature structures . The motivation for introducing these  languages  is to provide tools for formalising  grammatical frameworks  perspicuously, and the paper illustrates this by showing how the leading ideas of  GPSG  can be captured in  LT (LF) . In addition, the role of  modal languages  (and in particular, what we have called as  constraint formalisms  for linguistic theorising is discussed in some detail. ", "Comments": [], "entities": [{"id": 1089457, "label": "ENT", "start_offset": 31, "end_offset": 48}, {"id": 1089458, "label": "ENT", "start_offset": 63, "end_offset": 85}, {"id": 1089459, "label": "ENT", "start_offset": 95, "end_offset": 113}, {"id": 1089460, "label": "ENT", "start_offset": 129, "end_offset": 185}, {"id": 1089461, "label": "ENT", "start_offset": 226, "end_offset": 235}, {"id": 1089462, "label": "ENT", "start_offset": 274, "end_offset": 296}, {"id": 1089463, "label": "ENT", "start_offset": 381, "end_offset": 385}, {"id": 1089464, "label": "ENT", "start_offset": 407, "end_offset": 414}, {"id": 1089465, "label": "ENT", "start_offset": 443, "end_offset": 458}, {"id": 1089466, "label": "ENT", "start_offset": 504, "end_offset": 525}], "relations": [{"id": 173379, "from_id": 1089457, "to_id": 1089461, "type": "HYPONYM-OF"}, {"id": 173380, "from_id": 1089461, "to_id": 1089462, "type": "USED-FOR"}, {"id": 173381, "from_id": 1089465, "to_id": 1089461, "type": "COREF"}, {"id": 173382, "from_id": 1089463, "to_id": 1089464, "type": "USED-FOR"}, {"id": 173383, "from_id": 1089457, "to_id": 1089458, "type": "USED-FOR"}, {"id": 173384, "from_id": 1089459, "to_id": 1089460, "type": "USED-FOR"}, {"id": 173385, "from_id": 1089459, "to_id": 1089461, "type": "HYPONYM-OF"}, {"id": 173386, "from_id": 1089464, "to_id": 1089459, "type": "COREF"}]}
{"id": "C88-2162", "text": "   Computer programs so far have not fared well in  modeling language acquisition  . For one thing,  learning methodology  applicable in  general domains  does not readily lend itself in the  linguistic domain  . For another,  linguistic representation  used by  language processing systems  is not geared to  learning  . We introduced a new  linguistic representation  , the  Dynamic Hierarchical Phrasal Lexicon (DHPL)  [Zernik88], to facilitate  language acquisition  . From this, a  language learning model  was implemented in the program  RINA  , which enhances its own  lexical hierarchy  by processing examples in context. We identified two tasks: First, how  linguistic concepts  are acquired from  training examples  and organized in a  hierarchy  ; this task was discussed in previous papers [Zernik87]. Second, we show in this paper how a  lexical hierarchy  is used in predicting new  linguistic concepts  . Thus, a  program  does not stall even in the presence of a  lexical unknown  , and a  hypothesis  can be produced for covering that  lexical gap  . ", "Comments": [], "entities": [{"id": 1089499, "label": "ENT", "start_offset": 3, "end_offset": 20}, {"id": 1089500, "label": "ENT", "start_offset": 61, "end_offset": 81}, {"id": 1089501, "label": "ENT", "start_offset": 101, "end_offset": 121}, {"id": 1089502, "label": "ENT", "start_offset": 138, "end_offset": 153}, {"id": 1089503, "label": "ENT", "start_offset": 192, "end_offset": 209}, {"id": 1089504, "label": "ENT", "start_offset": 227, "end_offset": 252}, {"id": 1089505, "label": "ENT", "start_offset": 263, "end_offset": 290}, {"id": 1089506, "label": "ENT", "start_offset": 343, "end_offset": 368}, {"id": 1089507, "label": "ENT", "start_offset": 377, "end_offset": 420}, {"id": 1089508, "label": "ENT", "start_offset": 449, "end_offset": 469}, {"id": 1089509, "label": "ENT", "start_offset": 487, "end_offset": 510}, {"id": 1089510, "label": "ENT", "start_offset": 544, "end_offset": 548}, {"id": 1089511, "label": "ENT", "start_offset": 576, "end_offset": 593}, {"id": 1089512, "label": "ENT", "start_offset": 667, "end_offset": 686}, {"id": 1089513, "label": "ENT", "start_offset": 746, "end_offset": 755}, {"id": 1089514, "label": "ENT", "start_offset": 851, "end_offset": 868}, {"id": 1089515, "label": "ENT", "start_offset": 897, "end_offset": 916}, {"id": 1089516, "label": "ENT", "start_offset": 929, "end_offset": 936}], "relations": [{"id": 173409, "from_id": 1089502, "to_id": 1089503, "type": "COMPARE"}, {"id": 173410, "from_id": 1089504, "to_id": 1089505, "type": "USED-FOR"}, {"id": 173411, "from_id": 1089507, "to_id": 1089508, "type": "USED-FOR"}, {"id": 173412, "from_id": 1089514, "to_id": 1089515, "type": "USED-FOR"}, {"id": 173413, "from_id": 1089501, "to_id": 1089502, "type": "USED-FOR"}, {"id": 173414, "from_id": 1089509, "to_id": 1089510, "type": "PART-OF"}, {"id": 173415, "from_id": 1089512, "to_id": 1089513, "type": "PART-OF"}, {"id": 173416, "from_id": 1089516, "to_id": 1089499, "type": "COREF"}, {"id": 173417, "from_id": 1089507, "to_id": 1089506, "type": "HYPONYM-OF"}, {"id": 173418, "from_id": 1089506, "to_id": 1089508, "type": "USED-FOR"}, {"id": 173419, "from_id": 1089515, "to_id": 1089512, "type": "COREF"}, {"id": 173420, "from_id": 1089508, "to_id": 1089500, "type": "COREF"}]}
{"id": "H94-1102", "text": " The major objective of this program is to develop and demonstrate robust, high performance  continuous speech recognition (CSR) techniques  focussed on application in  Spoken Language Systems (SLS)  which will enhance the effectiveness of  military and civilian computer-based systems . A key complementary objective is to define and develop applications of robust  speech recognition and understanding systems , and to help catalyze the transition of  spoken language technology  into  military and civilian systems , with particular focus on application of robust  CSR  to  mobile military command and control . The research effort focusses on developing advanced  acoustic modelling , rapid search, and  recognition-time adaptation techniques  for robust  large-vocabulary CSR , and on applying these techniques to the new  ARPA large-vocabulary CSR corpora  and to military application tasks. ", "Comments": [], "entities": [{"id": 1089517, "label": "ENT", "start_offset": 93, "end_offset": 139}, {"id": 1089518, "label": "ENT", "start_offset": 169, "end_offset": 198}, {"id": 1089519, "label": "ENT", "start_offset": 241, "end_offset": 285}, {"id": 1089520, "label": "ENT", "start_offset": 367, "end_offset": 411}, {"id": 1089521, "label": "ENT", "start_offset": 454, "end_offset": 480}, {"id": 1089522, "label": "ENT", "start_offset": 488, "end_offset": 517}, {"id": 1089523, "label": "ENT", "start_offset": 568, "end_offset": 571}, {"id": 1089524, "label": "ENT", "start_offset": 577, "end_offset": 612}, {"id": 1089525, "label": "ENT", "start_offset": 668, "end_offset": 686}, {"id": 1089526, "label": "ENT", "start_offset": 689, "end_offset": 701}, {"id": 1089527, "label": "ENT", "start_offset": 708, "end_offset": 746}, {"id": 1089528, "label": "ENT", "start_offset": 760, "end_offset": 780}, {"id": 1089529, "label": "ENT", "start_offset": 805, "end_offset": 815}, {"id": 1089530, "label": "ENT", "start_offset": 828, "end_offset": 861}, {"id": 1089531, "label": "ENT", "start_offset": 870, "end_offset": 896}], "relations": [{"id": 173421, "from_id": 1089517, "to_id": 1089518, "type": "USED-FOR"}, {"id": 173422, "from_id": 1089521, "to_id": 1089522, "type": "USED-FOR"}, {"id": 173423, "from_id": 1089523, "to_id": 1089524, "type": "USED-FOR"}, {"id": 173424, "from_id": 1089528, "to_id": 1089530, "type": "USED-FOR"}, {"id": 173425, "from_id": 1089518, "to_id": 1089519, "type": "USED-FOR"}, {"id": 173426, "from_id": 1089522, "to_id": 1089519, "type": "COREF"}, {"id": 173427, "from_id": 1089521, "to_id": 1089518, "type": "COREF"}, {"id": 173428, "from_id": 1089523, "to_id": 1089517, "type": "COREF"}, {"id": 173429, "from_id": 1089527, "to_id": 1089528, "type": "USED-FOR"}, {"id": 173430, "from_id": 1089525, "to_id": 1089528, "type": "USED-FOR"}, {"id": 173431, "from_id": 1089526, "to_id": 1089528, "type": "USED-FOR"}, {"id": 173432, "from_id": 1089525, "to_id": 1089526, "type": "CONJUNCTION"}, {"id": 173433, "from_id": 1089526, "to_id": 1089527, "type": "CONJUNCTION"}, {"id": 173434, "from_id": 1089525, "to_id": 1089529, "type": "HYPONYM-OF"}, {"id": 173435, "from_id": 1089526, "to_id": 1089529, "type": "HYPONYM-OF"}, {"id": 173436, "from_id": 1089527, "to_id": 1089529, "type": "HYPONYM-OF"}, {"id": 173437, "from_id": 1089530, "to_id": 1089529, "type": "EVALUATE-FOR"}, {"id": 173438, "from_id": 1089529, "to_id": 1089531, "type": "USED-FOR"}, {"id": 173439, "from_id": 1089525, "to_id": 1089531, "type": "USED-FOR"}, {"id": 173440, "from_id": 1089526, "to_id": 1089531, "type": "USED-FOR"}, {"id": 173441, "from_id": 1089527, "to_id": 1089531, "type": "USED-FOR"}]}
{"id": "N06-2038", "text": "   There are several approaches that model  information extraction  as a  token classification task  , using various  tagging strategies  to combine multiple  tokens  . We describe the  tagging strategies  that can be found in the literature and evaluate their relative performances. We also introduce a new strategy, called  Begin/After tagging  or  BIA  , and show that it is competitive to the best other strategies. ", "Comments": [], "entities": [{"id": 1089569, "label": "ENT", "start_offset": 21, "end_offset": 31}, {"id": 1089570, "label": "ENT", "start_offset": 44, "end_offset": 66}, {"id": 1089571, "label": "ENT", "start_offset": 74, "end_offset": 99}, {"id": 1089572, "label": "ENT", "start_offset": 118, "end_offset": 136}, {"id": 1089573, "label": "ENT", "start_offset": 186, "end_offset": 204}, {"id": 1089574, "label": "ENT", "start_offset": 308, "end_offset": 316}, {"id": 1089575, "label": "ENT", "start_offset": 326, "end_offset": 345}, {"id": 1089576, "label": "ENT", "start_offset": 351, "end_offset": 354}, {"id": 1089577, "label": "ENT", "start_offset": 372, "end_offset": 374}, {"id": 1089578, "label": "ENT", "start_offset": 408, "end_offset": 418}], "relations": [{"id": 173470, "from_id": 1089572, "to_id": 1089571, "type": "USED-FOR"}, {"id": 173471, "from_id": 1089570, "to_id": 1089571, "type": "HYPONYM-OF"}, {"id": 173472, "from_id": 1089569, "to_id": 1089570, "type": "USED-FOR"}, {"id": 173473, "from_id": 1089576, "to_id": 1089575, "type": "COREF"}, {"id": 173474, "from_id": 1089575, "to_id": 1089574, "type": "COREF"}, {"id": 173475, "from_id": 1089574, "to_id": 1089577, "type": "COREF"}, {"id": 173476, "from_id": 1089577, "to_id": 1089578, "type": "COMPARE"}, {"id": 173477, "from_id": 1089572, "to_id": 1089569, "type": "COREF"}, {"id": 173478, "from_id": 1089573, "to_id": 1089572, "type": "COREF"}]}
{"id": "W08-2122", "text": " We propose a solution to the challenge of the  CoNLL 2008 shared task  that uses a  generative history-based latent variable model  to predict the most likely  derivation  of a  synchronous dependency parser  for both  syntactic and semantic dependencies . The submitted  model  yields 79.1%  macro-average F1 performance , for the joint task, 86.9%  syntactic dependencies LAS  and 71.0%  semantic dependencies F1 . A larger  model  trained after the deadline achieves 80.5%  macro-average F1 , 87.6%  syntactic dependencies LAS , and 73.1%  semantic dependencies F1 . ", "Comments": [], "entities": [{"id": 1089754, "label": "ENT", "start_offset": 48, "end_offset": 70}, {"id": 1089755, "label": "ENT", "start_offset": 85, "end_offset": 131}, {"id": 1089756, "label": "ENT", "start_offset": 179, "end_offset": 208}, {"id": 1089757, "label": "ENT", "start_offset": 220, "end_offset": 255}, {"id": 1089758, "label": "ENT", "start_offset": 273, "end_offset": 278}, {"id": 1089759, "label": "ENT", "start_offset": 294, "end_offset": 322}, {"id": 1089760, "label": "ENT", "start_offset": 339, "end_offset": 343}, {"id": 1089761, "label": "ENT", "start_offset": 352, "end_offset": 378}, {"id": 1089762, "label": "ENT", "start_offset": 391, "end_offset": 415}, {"id": 1089763, "label": "ENT", "start_offset": 428, "end_offset": 433}, {"id": 1089764, "label": "ENT", "start_offset": 478, "end_offset": 494}, {"id": 1089765, "label": "ENT", "start_offset": 504, "end_offset": 530}, {"id": 1089766, "label": "ENT", "start_offset": 544, "end_offset": 568}], "relations": [{"id": 173614, "from_id": 1089755, "to_id": 1089754, "type": "USED-FOR"}, {"id": 173615, "from_id": 1089758, "to_id": 1089755, "type": "COREF"}, {"id": 173616, "from_id": 1089759, "to_id": 1089758, "type": "EVALUATE-FOR"}, {"id": 173617, "from_id": 1089756, "to_id": 1089757, "type": "USED-FOR"}, {"id": 173618, "from_id": 1089755, "to_id": 1089756, "type": "USED-FOR"}, {"id": 173619, "from_id": 1089760, "to_id": 1089754, "type": "COREF"}, {"id": 173620, "from_id": 1089759, "to_id": 1089760, "type": "EVALUATE-FOR"}, {"id": 173621, "from_id": 1089761, "to_id": 1089760, "type": "EVALUATE-FOR"}, {"id": 173622, "from_id": 1089762, "to_id": 1089760, "type": "EVALUATE-FOR"}, {"id": 173623, "from_id": 1089761, "to_id": 1089762, "type": "CONJUNCTION"}, {"id": 173624, "from_id": 1089764, "to_id": 1089763, "type": "EVALUATE-FOR"}, {"id": 173625, "from_id": 1089765, "to_id": 1089763, "type": "EVALUATE-FOR"}, {"id": 173626, "from_id": 1089766, "to_id": 1089763, "type": "EVALUATE-FOR"}, {"id": 173627, "from_id": 1089765, "to_id": 1089766, "type": "CONJUNCTION"}, {"id": 173628, "from_id": 1089764, "to_id": 1089765, "type": "CONJUNCTION"}]}
{"id": "AAAI_2008_254_abs", "text": "The construction of causal graphs from non-experimental data rests on a set of constraints that the graph structure imposes on all probability distributions compatible with the graph. These constraints are of two types: conditional inde-pendencies and algebraic constraints, first noted by Verma. While conditional independencies are well studied and frequently used in causal induction algorithms, Verma constraints are still poorly understood, and rarely applied. In this paper we examine a special subset of Verma constraints which are easy to understand, easy to identify and easy to apply ; they arise from \" dormant independencies, \" namely, conditional independencies that hold in interventional distributions. We give a complete algorithm for determining if a dormant independence between two sets of variables is entailed by the causal graph, such that this independence is identifiable , in other words if it resides in an interventional distribution that can be predicted without resorting to interventions. We further show the usefulness of dormant independencies in model testing and induction by giving an algorithm that uses constraints entailed by dormant independencies to prune extraneous edges from a given causal graph.", "Comments": [], "entities": [{"id": 1089796, "label": "ENT", "start_offset": 4, "end_offset": 33}, {"id": 1089797, "label": "ENT", "start_offset": 39, "end_offset": 60}, {"id": 1089798, "label": "ENT", "start_offset": 79, "end_offset": 90}, {"id": 1089799, "label": "ENT", "start_offset": 100, "end_offset": 115}, {"id": 1089800, "label": "ENT", "start_offset": 131, "end_offset": 156}, {"id": 1089801, "label": "ENT", "start_offset": 177, "end_offset": 182}, {"id": 1089802, "label": "ENT", "start_offset": 190, "end_offset": 201}, {"id": 1089803, "label": "ENT", "start_offset": 220, "end_offset": 247}, {"id": 1089804, "label": "ENT", "start_offset": 252, "end_offset": 273}, {"id": 1089805, "label": "ENT", "start_offset": 303, "end_offset": 329}, {"id": 1089806, "label": "ENT", "start_offset": 370, "end_offset": 397}, {"id": 1089807, "label": "ENT", "start_offset": 399, "end_offset": 416}, {"id": 1089808, "label": "ENT", "start_offset": 511, "end_offset": 528}, {"id": 1089809, "label": "ENT", "start_offset": 596, "end_offset": 600}, {"id": 1089810, "label": "ENT", "start_offset": 614, "end_offset": 636}, {"id": 1089811, "label": "ENT", "start_offset": 648, "end_offset": 674}, {"id": 1089812, "label": "ENT", "start_offset": 688, "end_offset": 716}, {"id": 1089813, "label": "ENT", "start_offset": 737, "end_offset": 746}, {"id": 1089814, "label": "ENT", "start_offset": 768, "end_offset": 788}, {"id": 1089815, "label": "ENT", "start_offset": 809, "end_offset": 818}, {"id": 1089816, "label": "ENT", "start_offset": 838, "end_offset": 850}, {"id": 1089817, "label": "ENT", "start_offset": 867, "end_offset": 879}, {"id": 1089818, "label": "ENT", "start_offset": 916, "end_offset": 918}, {"id": 1089819, "label": "ENT", "start_offset": 933, "end_offset": 960}, {"id": 1089820, "label": "ENT", "start_offset": 1004, "end_offset": 1017}, {"id": 1089821, "label": "ENT", "start_offset": 1053, "end_offset": 1075}, {"id": 1089822, "label": "ENT", "start_offset": 1079, "end_offset": 1092}, {"id": 1089823, "label": "ENT", "start_offset": 1097, "end_offset": 1106}, {"id": 1089824, "label": "ENT", "start_offset": 1120, "end_offset": 1129}, {"id": 1089825, "label": "ENT", "start_offset": 1140, "end_offset": 1151}, {"id": 1089826, "label": "ENT", "start_offset": 1164, "end_offset": 1186}, {"id": 1089827, "label": "ENT", "start_offset": 1196, "end_offset": 1212}, {"id": 1089828, "label": "ENT", "start_offset": 1226, "end_offset": 1238}], "relations": [{"id": 173655, "from_id": 1089803, "to_id": 1089802, "type": "HYPONYM-OF"}, {"id": 173656, "from_id": 1089804, "to_id": 1089802, "type": "HYPONYM-OF"}, {"id": 173657, "from_id": 1089800, "to_id": 1089801, "type": "FEATURE-OF"}, {"id": 173658, "from_id": 1089797, "to_id": 1089796, "type": "USED-FOR"}, {"id": 173659, "from_id": 1089807, "to_id": 1089805, "type": "COMPARE"}, {"id": 173660, "from_id": 1089805, "to_id": 1089806, "type": "USED-FOR"}, {"id": 173661, "from_id": 1089810, "to_id": 1089811, "type": "CONJUNCTION"}, {"id": 173662, "from_id": 1089811, "to_id": 1089812, "type": "FEATURE-OF"}, {"id": 173663, "from_id": 1089813, "to_id": 1089814, "type": "USED-FOR"}, {"id": 173664, "from_id": 1089817, "to_id": 1089814, "type": "COREF"}, {"id": 173665, "from_id": 1089822, "to_id": 1089823, "type": "CONJUNCTION"}, {"id": 173666, "from_id": 1089809, "to_id": 1089808, "type": "COREF"}, {"id": 173667, "from_id": 1089818, "to_id": 1089817, "type": "COREF"}, {"id": 173668, "from_id": 1089819, "to_id": 1089818, "type": "FEATURE-OF"}, {"id": 173669, "from_id": 1089821, "to_id": 1089822, "type": "USED-FOR"}, {"id": 173670, "from_id": 1089825, "to_id": 1089824, "type": "USED-FOR"}, {"id": 173671, "from_id": 1089827, "to_id": 1089828, "type": "PART-OF"}, {"id": 173672, "from_id": 1089802, "to_id": 1089798, "type": "COREF"}, {"id": 173673, "from_id": 1089821, "to_id": 1089823, "type": "USED-FOR"}, {"id": 173674, "from_id": 1089824, "to_id": 1089827, "type": "USED-FOR"}]}
{"id": "NIPS_1998_18_abs", "text": "Visually-guided arm reaching movements are produced by distributed neural networks within parietal and frontal regions of the cerebral cortex. Experimental data indicate that (I) single neurons in these regions are broadly tuned to parameters of movement; (2) appropriate commands are elaborated by populations of neurons; (3) the coordinated action of neu-rons can be visualized using a neuronal population vector (NPV). However , the NPV provides only a rough estimate of movement parameters (direction, velocity) and may even fail to reflect the parameters of movement when arm posture is changed. We designed a model of the cortical motor command to investigate the relation between the desired direction of the movement, the actual direction of movement and the direction of the NPV in motor cortex. The model is a two-layer self-organizing neural network which combines broadly-tuned (muscular) proprioceptive and (cartesian) visual information to calculate (angular) motor commands for the initial part of the movement of a two-link arm. The network was trained by motor babbling in 5 positions. Simulations showed that (1) the network produced appropriate movement direction over a large part of the workspace; (2) small deviations of the actual trajectory from the desired trajectory existed at the extremities of the workspace; (3) these deviations were accompanied by large deviations of the NPV from both trajectories. These results suggest the NPV does not give a faithful image of cortical processing during arm reaching movements.", "Comments": [], "entities": [{"id": 1089840, "label": "ENT", "start_offset": 0, "end_offset": 38}, {"id": 1089841, "label": "ENT", "start_offset": 55, "end_offset": 82}, {"id": 1089842, "label": "ENT", "start_offset": 331, "end_offset": 361}, {"id": 1089843, "label": "ENT", "start_offset": 388, "end_offset": 420}, {"id": 1089844, "label": "ENT", "start_offset": 436, "end_offset": 439}, {"id": 1089845, "label": "ENT", "start_offset": 577, "end_offset": 588}, {"id": 1089846, "label": "ENT", "start_offset": 615, "end_offset": 620}, {"id": 1089847, "label": "ENT", "start_offset": 628, "end_offset": 650}, {"id": 1089848, "label": "ENT", "start_offset": 784, "end_offset": 787}, {"id": 1089849, "label": "ENT", "start_offset": 791, "end_offset": 803}, {"id": 1089850, "label": "ENT", "start_offset": 809, "end_offset": 814}, {"id": 1089851, "label": "ENT", "start_offset": 820, "end_offset": 860}, {"id": 1089852, "label": "ENT", "start_offset": 876, "end_offset": 915}, {"id": 1089853, "label": "ENT", "start_offset": 920, "end_offset": 950}, {"id": 1089854, "label": "ENT", "start_offset": 964, "end_offset": 988}, {"id": 1089855, "label": "ENT", "start_offset": 1031, "end_offset": 1043}, {"id": 1089856, "label": "ENT", "start_offset": 1049, "end_offset": 1056}, {"id": 1089857, "label": "ENT", "start_offset": 1135, "end_offset": 1142}, {"id": 1089858, "label": "ENT", "start_offset": 1403, "end_offset": 1406}, {"id": 1089859, "label": "ENT", "start_offset": 1457, "end_offset": 1460}, {"id": 1089860, "label": "ENT", "start_offset": 1486, "end_offset": 1514}, {"id": 1089861, "label": "ENT", "start_offset": 1522, "end_offset": 1544}], "relations": [{"id": 173684, "from_id": 1089841, "to_id": 1089840, "type": "USED-FOR"}, {"id": 173685, "from_id": 1089843, "to_id": 1089842, "type": "USED-FOR"}, {"id": 173686, "from_id": 1089844, "to_id": 1089843, "type": "COREF"}, {"id": 173687, "from_id": 1089846, "to_id": 1089847, "type": "USED-FOR"}, {"id": 173688, "from_id": 1089848, "to_id": 1089844, "type": "COREF"}, {"id": 173689, "from_id": 1089848, "to_id": 1089849, "type": "USED-FOR"}, {"id": 173690, "from_id": 1089850, "to_id": 1089846, "type": "COREF"}, {"id": 173691, "from_id": 1089851, "to_id": 1089850, "type": "COREF"}, {"id": 173692, "from_id": 1089852, "to_id": 1089851, "type": "USED-FOR"}, {"id": 173693, "from_id": 1089853, "to_id": 1089851, "type": "USED-FOR"}, {"id": 173694, "from_id": 1089851, "to_id": 1089854, "type": "USED-FOR"}, {"id": 173695, "from_id": 1089852, "to_id": 1089853, "type": "CONJUNCTION"}, {"id": 173696, "from_id": 1089856, "to_id": 1089851, "type": "COREF"}, {"id": 173697, "from_id": 1089857, "to_id": 1089856, "type": "COREF"}, {"id": 173698, "from_id": 1089858, "to_id": 1089848, "type": "COREF"}, {"id": 173699, "from_id": 1089859, "to_id": 1089858, "type": "COREF"}, {"id": 173700, "from_id": 1089861, "to_id": 1089860, "type": "FEATURE-OF"}]}
{"id": "CVPR_2006_10_abs", "text": "In this paper we discuss object detection when only a small number of training examples are given. Specifically, we show how to incorporate a simple prior on the distribution of natural images into support vector machines. SVMs are known to be robust to overfitting; however, a few training examples usually do not represent well the structure of the class. Thus the resulting detectors are not robust and highly depend on the choice of the training examples. We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin , but also that the corresponding positive half space will have a low probability to contain natural images (the background). Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples, and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples.", "Comments": [], "entities": [{"id": 1089862, "label": "ENT", "start_offset": 25, "end_offset": 41}, {"id": 1089863, "label": "ENT", "start_offset": 149, "end_offset": 192}, {"id": 1089864, "label": "ENT", "start_offset": 198, "end_offset": 221}, {"id": 1089865, "label": "ENT", "start_offset": 223, "end_offset": 227}, {"id": 1089866, "label": "ENT", "start_offset": 254, "end_offset": 265}, {"id": 1089867, "label": "ENT", "start_offset": 377, "end_offset": 386}, {"id": 1089868, "label": "ENT", "start_offset": 479, "end_offset": 502}, {"id": 1089869, "label": "ENT", "start_offset": 536, "end_offset": 546}, {"id": 1089870, "label": "ENT", "start_offset": 726, "end_offset": 740}, {"id": 1089871, "label": "ENT", "start_offset": 765, "end_offset": 773}, {"id": 1089872, "label": "ENT", "start_offset": 857, "end_offset": 878}], "relations": [{"id": 173701, "from_id": 1089865, "to_id": 1089864, "type": "COREF"}, {"id": 173702, "from_id": 1089865, "to_id": 1089866, "type": "USED-FOR"}, {"id": 173703, "from_id": 1089863, "to_id": 1089864, "type": "USED-FOR"}, {"id": 173704, "from_id": 1089870, "to_id": 1089871, "type": "EVALUATE-FOR"}, {"id": 173705, "from_id": 1089871, "to_id": 1089872, "type": "COMPARE"}, {"id": 173706, "from_id": 1089871, "to_id": 1089867, "type": "COREF"}]}
{"id": "C02-1071", "text": " This paper describes to what extent  deep processing  may benefit from  shallow techniques  and it presents a  NLP system  which integrates a  linguistic PoS tagger and chunker  as a preprocessing module of a  broad coverage unification based grammar of Spanish . Experiments show that the  efficiency  of the overall analysis improves significantly and that our system also provides  robustness  to the  linguistic processing  while maintaining both the  accuracy  and the  precision  of the  grammar . ", "Comments": [], "entities": [{"id": 1089873, "label": "ENT", "start_offset": 38, "end_offset": 53}, {"id": 1089874, "label": "ENT", "start_offset": 73, "end_offset": 91}, {"id": 1089875, "label": "ENT", "start_offset": 112, "end_offset": 122}, {"id": 1089876, "label": "ENT", "start_offset": 144, "end_offset": 177}, {"id": 1089877, "label": "ENT", "start_offset": 211, "end_offset": 262}, {"id": 1089878, "label": "ENT", "start_offset": 364, "end_offset": 370}, {"id": 1089879, "label": "ENT", "start_offset": 386, "end_offset": 396}, {"id": 1089880, "label": "ENT", "start_offset": 406, "end_offset": 427}, {"id": 1089881, "label": "ENT", "start_offset": 457, "end_offset": 465}, {"id": 1089882, "label": "ENT", "start_offset": 476, "end_offset": 485}], "relations": [{"id": 173707, "from_id": 1089874, "to_id": 1089873, "type": "USED-FOR"}, {"id": 173708, "from_id": 1089878, "to_id": 1089875, "type": "COREF"}, {"id": 173709, "from_id": 1089879, "to_id": 1089878, "type": "EVALUATE-FOR"}, {"id": 173710, "from_id": 1089878, "to_id": 1089880, "type": "USED-FOR"}, {"id": 173711, "from_id": 1089877, "to_id": 1089875, "type": "USED-FOR"}, {"id": 173712, "from_id": 1089876, "to_id": 1089877, "type": "PART-OF"}, {"id": 173713, "from_id": 1089881, "to_id": 1089878, "type": "EVALUATE-FOR"}, {"id": 173714, "from_id": 1089882, "to_id": 1089878, "type": "EVALUATE-FOR"}, {"id": 173715, "from_id": 1089881, "to_id": 1089882, "type": "CONJUNCTION"}]}
{"id": "W04-1307", "text": " This paper describes a  computational model  of  word segmentation  and presents simulation results on  realistic acquisition . In particular, we explore the capacity and limitations of  statistical learning mechanisms  that have recently gained prominence in  cognitive psychology  and  linguistics . ", "Comments": [], "entities": [{"id": 1089903, "label": "ENT", "start_offset": 25, "end_offset": 44}, {"id": 1089904, "label": "ENT", "start_offset": 50, "end_offset": 67}, {"id": 1089905, "label": "ENT", "start_offset": 105, "end_offset": 126}, {"id": 1089906, "label": "ENT", "start_offset": 188, "end_offset": 219}, {"id": 1089907, "label": "ENT", "start_offset": 262, "end_offset": 282}, {"id": 1089908, "label": "ENT", "start_offset": 289, "end_offset": 300}], "relations": [{"id": 173734, "from_id": 1089903, "to_id": 1089904, "type": "USED-FOR"}, {"id": 173735, "from_id": 1089907, "to_id": 1089906, "type": "USED-FOR"}, {"id": 173736, "from_id": 1089908, "to_id": 1089906, "type": "USED-FOR"}, {"id": 173737, "from_id": 1089907, "to_id": 1089908, "type": "CONJUNCTION"}, {"id": 173738, "from_id": 1089903, "to_id": 1089905, "type": "USED-FOR"}]}
{"id": "P80-1004", "text": "   Interpreting  metaphors  is an integral and inescapable process in  human understanding of natural language  . This paper discusses a  method of analyzing metaphors  based on the existence of a small number of  generalized metaphor mappings  . Each  generalized metaphor  contains a  recognition network  , a  basic mapping  , additional  transfer mappings  , and an  implicit intention component  . It is argued that the method reduces  metaphor interpretation  from a  reconstruction  to a  recognition task  . Implications towards automating certain aspects of  language learning  are also discussed. ", "Comments": [], "entities": [{"id": 1089935, "label": "ENT", "start_offset": 3, "end_offset": 26}, {"id": 1089936, "label": "ENT", "start_offset": 71, "end_offset": 110}, {"id": 1089937, "label": "ENT", "start_offset": 138, "end_offset": 144}, {"id": 1089938, "label": "ENT", "start_offset": 148, "end_offset": 167}, {"id": 1089939, "label": "ENT", "start_offset": 214, "end_offset": 243}, {"id": 1089940, "label": "ENT", "start_offset": 253, "end_offset": 273}, {"id": 1089941, "label": "ENT", "start_offset": 287, "end_offset": 306}, {"id": 1089942, "label": "ENT", "start_offset": 313, "end_offset": 326}, {"id": 1089943, "label": "ENT", "start_offset": 342, "end_offset": 359}, {"id": 1089944, "label": "ENT", "start_offset": 371, "end_offset": 399}, {"id": 1089945, "label": "ENT", "start_offset": 425, "end_offset": 431}, {"id": 1089946, "label": "ENT", "start_offset": 441, "end_offset": 464}, {"id": 1089947, "label": "ENT", "start_offset": 474, "end_offset": 488}, {"id": 1089948, "label": "ENT", "start_offset": 496, "end_offset": 512}, {"id": 1089949, "label": "ENT", "start_offset": 568, "end_offset": 585}], "relations": [{"id": 173754, "from_id": 1089941, "to_id": 1089940, "type": "PART-OF"}, {"id": 173755, "from_id": 1089935, "to_id": 1089936, "type": "HYPONYM-OF"}, {"id": 173756, "from_id": 1089937, "to_id": 1089938, "type": "USED-FOR"}, {"id": 173757, "from_id": 1089939, "to_id": 1089938, "type": "USED-FOR"}, {"id": 173758, "from_id": 1089943, "to_id": 1089944, "type": "CONJUNCTION"}, {"id": 173759, "from_id": 1089943, "to_id": 1089942, "type": "CONJUNCTION"}, {"id": 173760, "from_id": 1089941, "to_id": 1089942, "type": "CONJUNCTION"}, {"id": 173761, "from_id": 1089942, "to_id": 1089940, "type": "PART-OF"}, {"id": 173762, "from_id": 1089943, "to_id": 1089940, "type": "PART-OF"}, {"id": 173763, "from_id": 1089944, "to_id": 1089940, "type": "PART-OF"}, {"id": 173764, "from_id": 1089937, "to_id": 1089945, "type": "COREF"}, {"id": 173765, "from_id": 1089948, "to_id": 1089946, "type": "USED-FOR"}, {"id": 173766, "from_id": 1089945, "to_id": 1089946, "type": "USED-FOR"}, {"id": 173767, "from_id": 1089946, "to_id": 1089935, "type": "COREF"}]}
{"id": "NIPS_2001_11_abs", "text": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions, suitable for efficient implementation of kernels in image processing. At the core of the externally digital architecture is a high-density, low-power analog array performing binary-binary partial matrix-vector multiplication. Full digital resolution is maintained even with low-resolution analog-to-digital conversion, owing to random statistics in the analog summation of binary products. A random modulation scheme produces near-Bernoulli statistics even for highly correlated inputs. The approach is validated with real image data, and with experimental results from a CID/DRAM analog array prototype in 0.5 \u00a2 m CMOS.", "Comments": [], "entities": [{"id": 1090010, "label": "ENT", "start_offset": 2, "end_offset": 23}, {"id": 1090011, "label": "ENT", "start_offset": 41, "end_offset": 91}, {"id": 1090012, "label": "ENT", "start_offset": 158, "end_offset": 165}, {"id": 1090013, "label": "ENT", "start_offset": 169, "end_offset": 185}, {"id": 1090014, "label": "ENT", "start_offset": 206, "end_offset": 237}, {"id": 1090015, "label": "ENT", "start_offset": 243, "end_offset": 279}, {"id": 1090016, "label": "ENT", "start_offset": 291, "end_offset": 341}, {"id": 1090017, "label": "ENT", "start_offset": 343, "end_offset": 366}, {"id": 1090018, "label": "ENT", "start_offset": 391, "end_offset": 434}, {"id": 1090019, "label": "ENT", "start_offset": 445, "end_offset": 462}, {"id": 1090020, "label": "ENT", "start_offset": 470, "end_offset": 505}, {"id": 1090021, "label": "ENT", "start_offset": 509, "end_offset": 533}, {"id": 1090022, "label": "ENT", "start_offset": 543, "end_offset": 568}, {"id": 1090023, "label": "ENT", "start_offset": 578, "end_offset": 602}, {"id": 1090024, "label": "ENT", "start_offset": 608, "end_offset": 616}, {"id": 1090025, "label": "ENT", "start_offset": 635, "end_offset": 650}, {"id": 1090026, "label": "ENT", "start_offset": 689, "end_offset": 720}], "relations": [{"id": 173810, "from_id": 1090010, "to_id": 1090011, "type": "USED-FOR"}, {"id": 173811, "from_id": 1090010, "to_id": 1090012, "type": "USED-FOR"}, {"id": 173812, "from_id": 1090012, "to_id": 1090013, "type": "USED-FOR"}, {"id": 173813, "from_id": 1090015, "to_id": 1090014, "type": "PART-OF"}, {"id": 173814, "from_id": 1090016, "to_id": 1090015, "type": "USED-FOR"}, {"id": 173815, "from_id": 1090019, "to_id": 1090020, "type": "PART-OF"}, {"id": 173816, "from_id": 1090021, "to_id": 1090022, "type": "USED-FOR"}, {"id": 173817, "from_id": 1090023, "to_id": 1090021, "type": "USED-FOR"}, {"id": 173818, "from_id": 1090025, "to_id": 1090024, "type": "EVALUATE-FOR"}, {"id": 173819, "from_id": 1090010, "to_id": 1090024, "type": "COREF"}]}
{"id": "H92-1003", "text": "   This paper describes a recently collected  spoken language corpus  for the  ATIS (Air Travel Information System) domain  . This data collection effort has been co-ordinated by  MADCOW (Multi-site ATIS Data COllection Working group)  . We summarize the motivation for this effort, the goals, the implementation of a  multi-site data collection paradigm  , and the accomplishments of  MADCOW  in monitoring the  collection  and distribution of 12,000  utterances  of  spontaneous speech  from five sites for use in a  multi-site common evaluation of speech, natural language and spoken language  .", "Comments": [], "entities": [{"id": 1090046, "label": "ENT", "start_offset": 46, "end_offset": 68}, {"id": 1090047, "label": "ENT", "start_offset": 79, "end_offset": 122}, {"id": 1090048, "label": "ENT", "start_offset": 131, "end_offset": 146}, {"id": 1090049, "label": "ENT", "start_offset": 319, "end_offset": 354}, {"id": 1090050, "label": "ENT", "start_offset": 413, "end_offset": 423}, {"id": 1090051, "label": "ENT", "start_offset": 469, "end_offset": 487}, {"id": 1090052, "label": "ENT", "start_offset": 519, "end_offset": 595}], "relations": [{"id": 173833, "from_id": 1090046, "to_id": 1090047, "type": "USED-FOR"}, {"id": 173834, "from_id": 1090048, "to_id": 1090046, "type": "COREF"}, {"id": 173835, "from_id": 1090050, "to_id": 1090048, "type": "COREF"}, {"id": 173836, "from_id": 1090051, "to_id": 1090052, "type": "EVALUATE-FOR"}]}
{"id": "H92-1017", "text": "   This paper describes three relatively  domain-independent capabilities  recently added to the  Paramax spoken language understanding system  :  non-monotonic reasoning  ,  implicit reference resolution  , and  database query paraphrase  . In addition, we discuss the results of the  February 1992 ATIS benchmark tests  . We describe a variation on the  standard evaluation metric  which provides a more tightly controlled measure of progress. Finally, we briefly describe an experiment which we have done in extending the  n-best speech/language integration architecture  to improving  OCR   accuracy  . ", "Comments": [], "entities": [{"id": 1090053, "label": "ENT", "start_offset": 42, "end_offset": 73}, {"id": 1090054, "label": "ENT", "start_offset": 98, "end_offset": 142}, {"id": 1090055, "label": "ENT", "start_offset": 147, "end_offset": 170}, {"id": 1090056, "label": "ENT", "start_offset": 175, "end_offset": 204}, {"id": 1090057, "label": "ENT", "start_offset": 213, "end_offset": 238}, {"id": 1090058, "label": "ENT", "start_offset": 286, "end_offset": 320}, {"id": 1090059, "label": "ENT", "start_offset": 526, "end_offset": 573}, {"id": 1090060, "label": "ENT", "start_offset": 589, "end_offset": 603}], "relations": [{"id": 173837, "from_id": 1090053, "to_id": 1090054, "type": "PART-OF"}, {"id": 173838, "from_id": 1090055, "to_id": 1090053, "type": "HYPONYM-OF"}, {"id": 173839, "from_id": 1090056, "to_id": 1090053, "type": "HYPONYM-OF"}, {"id": 173840, "from_id": 1090057, "to_id": 1090053, "type": "HYPONYM-OF"}, {"id": 173841, "from_id": 1090060, "to_id": 1090059, "type": "EVALUATE-FOR"}]}
{"id": "ICCV_2003_150_abs", "text": "We present a single-image highlight removal method that incorporates illumination-based constraints into image in-painting. Unlike occluded image regions filled by traditional inpainting, highlight pixels contain some useful information for guiding the inpainting process. Constraints provided by observed pixel colors, highlight color analysis and illumination color uniformity are employed in our method to improve estimation of the underlying diffuse color. The inclusion of these illumination constraints allows for better recovery of shading and textures by inpainting. Experimental results are given to demonstrate the performance of our method.", "Comments": [], "entities": [{"id": 1090099, "label": "ENT", "start_offset": 13, "end_offset": 50}, {"id": 1090100, "label": "ENT", "start_offset": 69, "end_offset": 99}, {"id": 1090101, "label": "ENT", "start_offset": 105, "end_offset": 122}, {"id": 1090102, "label": "ENT", "start_offset": 131, "end_offset": 153}, {"id": 1090103, "label": "ENT", "start_offset": 176, "end_offset": 186}, {"id": 1090104, "label": "ENT", "start_offset": 188, "end_offset": 204}, {"id": 1090105, "label": "ENT", "start_offset": 253, "end_offset": 271}, {"id": 1090106, "label": "ENT", "start_offset": 273, "end_offset": 284}, {"id": 1090107, "label": "ENT", "start_offset": 306, "end_offset": 318}, {"id": 1090108, "label": "ENT", "start_offset": 320, "end_offset": 344}, {"id": 1090109, "label": "ENT", "start_offset": 349, "end_offset": 378}, {"id": 1090110, "label": "ENT", "start_offset": 399, "end_offset": 405}, {"id": 1090111, "label": "ENT", "start_offset": 417, "end_offset": 459}, {"id": 1090112, "label": "ENT", "start_offset": 484, "end_offset": 508}, {"id": 1090113, "label": "ENT", "start_offset": 527, "end_offset": 559}, {"id": 1090114, "label": "ENT", "start_offset": 563, "end_offset": 573}, {"id": 1090115, "label": "ENT", "start_offset": 644, "end_offset": 650}], "relations": [{"id": 173871, "from_id": 1090099, "to_id": 1090101, "type": "USED-FOR"}, {"id": 173872, "from_id": 1090105, "to_id": 1090101, "type": "COREF"}, {"id": 173873, "from_id": 1090108, "to_id": 1090109, "type": "CONJUNCTION"}, {"id": 173874, "from_id": 1090110, "to_id": 1090111, "type": "USED-FOR"}, {"id": 173875, "from_id": 1090107, "to_id": 1090108, "type": "CONJUNCTION"}, {"id": 173876, "from_id": 1090106, "to_id": 1090110, "type": "USED-FOR"}, {"id": 173877, "from_id": 1090112, "to_id": 1090106, "type": "COREF"}, {"id": 173878, "from_id": 1090114, "to_id": 1090105, "type": "COREF"}, {"id": 173879, "from_id": 1090110, "to_id": 1090099, "type": "COREF"}, {"id": 173880, "from_id": 1090100, "to_id": 1090101, "type": "PART-OF"}, {"id": 173881, "from_id": 1090115, "to_id": 1090110, "type": "COREF"}, {"id": 173882, "from_id": 1090114, "to_id": 1090113, "type": "USED-FOR"}, {"id": 173883, "from_id": 1090112, "to_id": 1090113, "type": "USED-FOR"}]}
{"id": "NIPS_1996_22_abs", "text": "We study the number of hidden layers required by a multilayer neu-ral network with threshold units to compute a function f from n d to {O, I}. In dimension d = 2, Gibson characterized the functions computable with just one hidden layer, under the assumption that there is no \"multiple intersection point\" and that f is only defined on a compact set. We consider the restriction of f to the neighborhood of a multiple intersection point or of infinity, and give necessary and sufficient conditions for it to be locally computable with one hidden layer. We show that adding these conditions to Gib-son's assumptions is not sufficient to ensure global computability with one hidden layer, by exhibiting a new non-local configuration, the \"critical cycle\", which implies that f is not computable with one hidden layer.", "Comments": [], "entities": [{"id": 1090116, "label": "ENT", "start_offset": 13, "end_offset": 36}, {"id": 1090117, "label": "ENT", "start_offset": 51, "end_offset": 77}, {"id": 1090118, "label": "ENT", "start_offset": 83, "end_offset": 98}, {"id": 1090119, "label": "ENT", "start_offset": 223, "end_offset": 235}, {"id": 1090120, "label": "ENT", "start_offset": 538, "end_offset": 550}, {"id": 1090121, "label": "ENT", "start_offset": 642, "end_offset": 662}, {"id": 1090122, "label": "ENT", "start_offset": 672, "end_offset": 684}, {"id": 1090123, "label": "ENT", "start_offset": 706, "end_offset": 729}, {"id": 1090124, "label": "ENT", "start_offset": 735, "end_offset": 751}, {"id": 1090125, "label": "ENT", "start_offset": 801, "end_offset": 813}], "relations": [{"id": 173884, "from_id": 1090116, "to_id": 1090117, "type": "USED-FOR"}, {"id": 173885, "from_id": 1090118, "to_id": 1090116, "type": "USED-FOR"}, {"id": 173886, "from_id": 1090124, "to_id": 1090123, "type": "HYPONYM-OF"}]}
{"id": "P08-2034", "text": "  Lyric-based song sentiment classification  seeks to assign songs appropriate  sentiment labels  such as light-hearted heavy-hearted. Four problems render  vector space model (VSM)-based text classification approach  ineffective: 1) Many  words  within  song lyrics  actually contribute little to  sentiment ; 2)  Nouns  and  verbs  used to express  sentiment  are ambiguous; 3)  Negations  and  modifiers  around the  sentiment keywords  make particular contributions to  sentiment ; 4)  Song lyric  is usually very short. To address these problems, the  sentiment vector space model (s-VSM)  is proposed to represent  song lyric document . The preliminary experiments prove that the  s-VSM model  outperforms the  VSM model  in the  lyric-based song sentiment classification task .  ", "Comments": [], "entities": [{"id": 1090126, "label": "ENT", "start_offset": 2, "end_offset": 43}, {"id": 1090127, "label": "ENT", "start_offset": 157, "end_offset": 216}, {"id": 1090128, "label": "ENT", "start_offset": 255, "end_offset": 266}, {"id": 1090129, "label": "ENT", "start_offset": 299, "end_offset": 308}, {"id": 1090130, "label": "ENT", "start_offset": 381, "end_offset": 390}, {"id": 1090131, "label": "ENT", "start_offset": 397, "end_offset": 406}, {"id": 1090132, "label": "ENT", "start_offset": 420, "end_offset": 438}, {"id": 1090133, "label": "ENT", "start_offset": 474, "end_offset": 483}, {"id": 1090134, "label": "ENT", "start_offset": 490, "end_offset": 500}, {"id": 1090135, "label": "ENT", "start_offset": 557, "end_offset": 593}, {"id": 1090136, "label": "ENT", "start_offset": 621, "end_offset": 640}, {"id": 1090137, "label": "ENT", "start_offset": 687, "end_offset": 698}, {"id": 1090138, "label": "ENT", "start_offset": 717, "end_offset": 726}, {"id": 1090139, "label": "ENT", "start_offset": 736, "end_offset": 782}], "relations": [{"id": 173887, "from_id": 1090135, "to_id": 1090136, "type": "USED-FOR"}, {"id": 173888, "from_id": 1090137, "to_id": 1090138, "type": "COMPARE"}, {"id": 173889, "from_id": 1090130, "to_id": 1090131, "type": "CONJUNCTION"}, {"id": 173890, "from_id": 1090131, "to_id": 1090133, "type": "USED-FOR"}, {"id": 173891, "from_id": 1090130, "to_id": 1090133, "type": "USED-FOR"}, {"id": 173892, "from_id": 1090128, "to_id": 1090134, "type": "COREF"}, {"id": 173893, "from_id": 1090135, "to_id": 1090137, "type": "COREF"}, {"id": 173894, "from_id": 1090139, "to_id": 1090137, "type": "EVALUATE-FOR"}, {"id": 173895, "from_id": 1090139, "to_id": 1090138, "type": "EVALUATE-FOR"}]}
{"id": "INTERSPEECH_2007_31_abs", "text": "The paper assesses the capability of an HMM-based TTS system to produce German speech. The results are discussed in qualitative terms, and compared over three different choices of context features. In addition, the system is adapted to a small set of football announcements, in an exploratory attempt to synthe-sise expressive speech. We conclude that the HMMs are able to produce highly intelligible neutral German speech, with a stable quality, and that the expressivity is partially captured in spite of the small size of the football dataset.", "Comments": [], "entities": [{"id": 1090201, "label": "ENT", "start_offset": 40, "end_offset": 60}, {"id": 1090202, "label": "ENT", "start_offset": 72, "end_offset": 85}, {"id": 1090203, "label": "ENT", "start_offset": 180, "end_offset": 196}, {"id": 1090204, "label": "ENT", "start_offset": 215, "end_offset": 221}, {"id": 1090205, "label": "ENT", "start_offset": 251, "end_offset": 273}, {"id": 1090206, "label": "ENT", "start_offset": 316, "end_offset": 333}, {"id": 1090207, "label": "ENT", "start_offset": 356, "end_offset": 360}, {"id": 1090208, "label": "ENT", "start_offset": 388, "end_offset": 422}, {"id": 1090209, "label": "ENT", "start_offset": 529, "end_offset": 545}], "relations": [{"id": 173936, "from_id": 1090201, "to_id": 1090202, "type": "USED-FOR"}, {"id": 173937, "from_id": 1090201, "to_id": 1090204, "type": "COREF"}, {"id": 173938, "from_id": 1090204, "to_id": 1090205, "type": "USED-FOR"}, {"id": 173939, "from_id": 1090204, "to_id": 1090206, "type": "USED-FOR"}, {"id": 173940, "from_id": 1090207, "to_id": 1090208, "type": "USED-FOR"}]}
{"id": "CVPR_2012_18_abs", "text": "We propose a novel technique called bispectral photo-metric stereo that makes effective use of fluorescence for shape reconstruction. Fluorescence is a common phenomenon occurring in many objects from natural gems and corals, to fluorescent dyes used in clothing. One of the important characteristics of fluorescence is its wavelength-shifting behavior: fluorescent materials absorb light at a certain wavelength and then reemit it at longer wavelengths. Due to the complexity of its emission process, fluo-rescence tends to be excluded from most algorithms in computer vision and image processing. In this paper, we show that there is a strong similarity between fluorescence and ideal diffuse reflection and that fluorescence can provide distinct clues on how to estimate an object's shape. Moreover , fluorescence's wavelength-shifting property enables us to estimate the shape of an object by applying photomet-ric stereo to emission-only images without suffering from specular reflection. This is the significant advantage of the fluorescence-based method over previous methods based on reflection.", "Comments": [], "entities": [{"id": 1090210, "label": "ENT", "start_offset": 19, "end_offset": 28}, {"id": 1090211, "label": "ENT", "start_offset": 36, "end_offset": 66}, {"id": 1090212, "label": "ENT", "start_offset": 95, "end_offset": 107}, {"id": 1090213, "label": "ENT", "start_offset": 112, "end_offset": 132}, {"id": 1090214, "label": "ENT", "start_offset": 134, "end_offset": 146}, {"id": 1090215, "label": "ENT", "start_offset": 201, "end_offset": 213}, {"id": 1090216, "label": "ENT", "start_offset": 229, "end_offset": 245}, {"id": 1090217, "label": "ENT", "start_offset": 304, "end_offset": 316}, {"id": 1090218, "label": "ENT", "start_offset": 354, "end_offset": 375}, {"id": 1090219, "label": "ENT", "start_offset": 466, "end_offset": 476}, {"id": 1090220, "label": "ENT", "start_offset": 484, "end_offset": 500}, {"id": 1090221, "label": "ENT", "start_offset": 502, "end_offset": 515}, {"id": 1090222, "label": "ENT", "start_offset": 547, "end_offset": 557}, {"id": 1090223, "label": "ENT", "start_offset": 561, "end_offset": 576}, {"id": 1090224, "label": "ENT", "start_offset": 581, "end_offset": 597}, {"id": 1090225, "label": "ENT", "start_offset": 645, "end_offset": 655}, {"id": 1090226, "label": "ENT", "start_offset": 664, "end_offset": 676}, {"id": 1090227, "label": "ENT", "start_offset": 687, "end_offset": 705}, {"id": 1090228, "label": "ENT", "start_offset": 715, "end_offset": 727}, {"id": 1090229, "label": "ENT", "start_offset": 804, "end_offset": 847}, {"id": 1090230, "label": "ENT", "start_offset": 875, "end_offset": 880}, {"id": 1090231, "label": "ENT", "start_offset": 906, "end_offset": 925}, {"id": 1090232, "label": "ENT", "start_offset": 929, "end_offset": 949}, {"id": 1090233, "label": "ENT", "start_offset": 973, "end_offset": 992}, {"id": 1090234, "label": "ENT", "start_offset": 1035, "end_offset": 1060}, {"id": 1090235, "label": "ENT", "start_offset": 1075, "end_offset": 1082}, {"id": 1090236, "label": "ENT", "start_offset": 1092, "end_offset": 1102}], "relations": [{"id": 173941, "from_id": 1090211, "to_id": 1090210, "type": "COREF"}, {"id": 173942, "from_id": 1090212, "to_id": 1090211, "type": "USED-FOR"}, {"id": 173943, "from_id": 1090211, "to_id": 1090213, "type": "USED-FOR"}, {"id": 173944, "from_id": 1090219, "to_id": 1090220, "type": "EVALUATE-FOR"}, {"id": 173945, "from_id": 1090223, "to_id": 1090224, "type": "CONJUNCTION"}, {"id": 173946, "from_id": 1090222, "to_id": 1090223, "type": "USED-FOR"}, {"id": 173947, "from_id": 1090222, "to_id": 1090224, "type": "USED-FOR"}, {"id": 173948, "from_id": 1090231, "to_id": 1090211, "type": "COREF"}, {"id": 173949, "from_id": 1090232, "to_id": 1090231, "type": "USED-FOR"}, {"id": 173950, "from_id": 1090235, "to_id": 1090234, "type": "COMPARE"}, {"id": 173951, "from_id": 1090229, "to_id": 1090230, "type": "USED-FOR"}, {"id": 173952, "from_id": 1090231, "to_id": 1090230, "type": "USED-FOR"}]}
{"id": "P06-2001", "text": " In this paper, we describe the research using  machine learning techniques  to build a  comma checker  to be integrated in a  grammar checker  for  Basque  . After several experiments, and trained with a little  corpus  of 100,000  words  , the system guesses correctly not placing  commas  with a  precision  of 96% and a  recall  of 98%. It also gets a  precision  of 70% and a  recall  of 49% in the task of placing  commas  . Finally, we have shown that these results can be improved using a bigger and a more homogeneous  corpus  to train, that is, a bigger  corpus  written by one unique  author  . ", "Comments": [], "entities": [{"id": 1090275, "label": "ENT", "start_offset": 48, "end_offset": 75}, {"id": 1090276, "label": "ENT", "start_offset": 89, "end_offset": 102}, {"id": 1090277, "label": "ENT", "start_offset": 127, "end_offset": 142}, {"id": 1090278, "label": "ENT", "start_offset": 149, "end_offset": 155}, {"id": 1090279, "label": "ENT", "start_offset": 246, "end_offset": 252}, {"id": 1090280, "label": "ENT", "start_offset": 300, "end_offset": 309}, {"id": 1090281, "label": "ENT", "start_offset": 325, "end_offset": 331}, {"id": 1090282, "label": "ENT", "start_offset": 341, "end_offset": 343}, {"id": 1090283, "label": "ENT", "start_offset": 357, "end_offset": 366}, {"id": 1090284, "label": "ENT", "start_offset": 382, "end_offset": 388}, {"id": 1090285, "label": "ENT", "start_offset": 412, "end_offset": 427}], "relations": [{"id": 173980, "from_id": 1090275, "to_id": 1090276, "type": "USED-FOR"}, {"id": 173981, "from_id": 1090277, "to_id": 1090278, "type": "USED-FOR"}, {"id": 173982, "from_id": 1090276, "to_id": 1090277, "type": "PART-OF"}, {"id": 173983, "from_id": 1090276, "to_id": 1090279, "type": "COREF"}, {"id": 173984, "from_id": 1090280, "to_id": 1090279, "type": "EVALUATE-FOR"}, {"id": 173985, "from_id": 1090281, "to_id": 1090279, "type": "EVALUATE-FOR"}, {"id": 173986, "from_id": 1090282, "to_id": 1090279, "type": "COREF"}, {"id": 173987, "from_id": 1090283, "to_id": 1090282, "type": "EVALUATE-FOR"}, {"id": 173988, "from_id": 1090284, "to_id": 1090282, "type": "EVALUATE-FOR"}, {"id": 173989, "from_id": 1090282, "to_id": 1090285, "type": "USED-FOR"}]}
{"id": "P85-1019", "text": " We have implemented a  restricted domain parser  called  Plume . Building on previous work at Carnegie-Mellon University e.g. [4, 5, 8],  Plume's approach to parsing  is based on  semantic caseframe instantiation . This has the advantages of  efficiency  on  grammatical input , and  robustness  in the face of  ungrammatical input . While  Plume  is well adapted to simple  declarative and imperative utterances , it handles  passives ,  relative clauses  and  interrogatives  in an ad hoc manner leading to patchy  syntactic coverage . This paper outlines  Plume  as it currently exists and describes our detailed design for extending  Plume  to handle  passives ,  relative clauses , and  interrogatives  in a general manner. ", "Comments": [], "entities": [{"id": 1090415, "label": "ENT", "start_offset": 24, "end_offset": 48}, {"id": 1090416, "label": "ENT", "start_offset": 58, "end_offset": 63}, {"id": 1090417, "label": "ENT", "start_offset": 139, "end_offset": 155}, {"id": 1090418, "label": "ENT", "start_offset": 159, "end_offset": 166}, {"id": 1090419, "label": "ENT", "start_offset": 181, "end_offset": 213}, {"id": 1090420, "label": "ENT", "start_offset": 260, "end_offset": 277}, {"id": 1090421, "label": "ENT", "start_offset": 285, "end_offset": 295}, {"id": 1090422, "label": "ENT", "start_offset": 313, "end_offset": 332}, {"id": 1090423, "label": "ENT", "start_offset": 342, "end_offset": 347}, {"id": 1090424, "label": "ENT", "start_offset": 376, "end_offset": 413}, {"id": 1090425, "label": "ENT", "start_offset": 416, "end_offset": 418}, {"id": 1090426, "label": "ENT", "start_offset": 428, "end_offset": 436}, {"id": 1090427, "label": "ENT", "start_offset": 440, "end_offset": 456}, {"id": 1090428, "label": "ENT", "start_offset": 463, "end_offset": 477}, {"id": 1090429, "label": "ENT", "start_offset": 510, "end_offset": 536}, {"id": 1090430, "label": "ENT", "start_offset": 560, "end_offset": 565}, {"id": 1090431, "label": "ENT", "start_offset": 570, "end_offset": 572}, {"id": 1090432, "label": "ENT", "start_offset": 639, "end_offset": 644}, {"id": 1090433, "label": "ENT", "start_offset": 657, "end_offset": 665}, {"id": 1090434, "label": "ENT", "start_offset": 669, "end_offset": 685}, {"id": 1090435, "label": "ENT", "start_offset": 693, "end_offset": 707}], "relations": [{"id": 174088, "from_id": 1090416, "to_id": 1090415, "type": "HYPONYM-OF"}, {"id": 174089, "from_id": 1090416, "to_id": 1090417, "type": "COREF"}, {"id": 174090, "from_id": 1090417, "to_id": 1090418, "type": "USED-FOR"}, {"id": 174091, "from_id": 1090419, "to_id": 1090417, "type": "USED-FOR"}, {"id": 174092, "from_id": 1090417, "to_id": 1090423, "type": "COREF"}, {"id": 174093, "from_id": 1090423, "to_id": 1090424, "type": "USED-FOR"}, {"id": 174094, "from_id": 1090423, "to_id": 1090425, "type": "COREF"}, {"id": 174095, "from_id": 1090425, "to_id": 1090426, "type": "USED-FOR"}, {"id": 174096, "from_id": 1090425, "to_id": 1090427, "type": "USED-FOR"}, {"id": 174097, "from_id": 1090425, "to_id": 1090428, "type": "USED-FOR"}, {"id": 174098, "from_id": 1090426, "to_id": 1090427, "type": "CONJUNCTION"}, {"id": 174099, "from_id": 1090427, "to_id": 1090428, "type": "CONJUNCTION"}, {"id": 174100, "from_id": 1090423, "to_id": 1090430, "type": "COREF"}, {"id": 174101, "from_id": 1090430, "to_id": 1090431, "type": "COREF"}, {"id": 174102, "from_id": 1090431, "to_id": 1090432, "type": "COREF"}, {"id": 174103, "from_id": 1090432, "to_id": 1090433, "type": "USED-FOR"}, {"id": 174104, "from_id": 1090432, "to_id": 1090434, "type": "USED-FOR"}, {"id": 174105, "from_id": 1090432, "to_id": 1090435, "type": "USED-FOR"}, {"id": 174106, "from_id": 1090433, "to_id": 1090434, "type": "CONJUNCTION"}, {"id": 174107, "from_id": 1090434, "to_id": 1090435, "type": "CONJUNCTION"}, {"id": 174108, "from_id": 1090422, "to_id": 1090421, "type": "FEATURE-OF"}]}
{"id": "E99-1014", "text": " This paper proposes an approach to  full parsing  suitable for  Information Extraction  from  texts . Sequences of cascades of  rules  deterministically analyze the  text , building  unambiguous structures . Initially basic  chunks  are analyzed; then  argumental relations  are recognized; finally  modifier attachment  is performed and the  global parse tree  is built. The approach was proven to work for three  languages  and different  domains . It was implemented in the  IE module  of  FACILE, a EU project for multilingual text classification and IE . ", "Comments": [], "entities": [{"id": 1090505, "label": "ENT", "start_offset": 24, "end_offset": 32}, {"id": 1090506, "label": "ENT", "start_offset": 37, "end_offset": 49}, {"id": 1090507, "label": "ENT", "start_offset": 65, "end_offset": 87}, {"id": 1090508, "label": "ENT", "start_offset": 129, "end_offset": 134}, {"id": 1090509, "label": "ENT", "start_offset": 184, "end_offset": 206}, {"id": 1090510, "label": "ENT", "start_offset": 254, "end_offset": 274}, {"id": 1090511, "label": "ENT", "start_offset": 301, "end_offset": 320}, {"id": 1090512, "label": "ENT", "start_offset": 344, "end_offset": 361}, {"id": 1090513, "label": "ENT", "start_offset": 377, "end_offset": 385}, {"id": 1090514, "label": "ENT", "start_offset": 452, "end_offset": 454}, {"id": 1090515, "label": "ENT", "start_offset": 479, "end_offset": 488}, {"id": 1090516, "label": "ENT", "start_offset": 494, "end_offset": 558}], "relations": [{"id": 174172, "from_id": 1090506, "to_id": 1090507, "type": "USED-FOR"}, {"id": 174173, "from_id": 1090515, "to_id": 1090516, "type": "PART-OF"}, {"id": 174174, "from_id": 1090505, "to_id": 1090506, "type": "USED-FOR"}, {"id": 174175, "from_id": 1090514, "to_id": 1090513, "type": "COREF"}, {"id": 174176, "from_id": 1090514, "to_id": 1090515, "type": "USED-FOR"}, {"id": 174177, "from_id": 1090513, "to_id": 1090505, "type": "COREF"}]}
{"id": "INTERSPEECH_2007_28_abs", "text": "This paper presents a new two-pass algorithm for Extra Large (more than 1M words) Vocabulary COntinuous Speech recognition based on the Information Retrieval (ELVIRCOS). The principle of this approach is to decompose a recognition process into two passes where the first pass builds the words subset for the second pass recognition by using information retrieval procedure. Word graph composition for continuous speech is presented. With this approach a high performances for large vocabulary speech recognition can be obtained.", "Comments": [], "entities": [{"id": 1090517, "label": "ENT", "start_offset": 26, "end_offset": 44}, {"id": 1090518, "label": "ENT", "start_offset": 49, "end_offset": 122}, {"id": 1090519, "label": "ENT", "start_offset": 136, "end_offset": 168}, {"id": 1090520, "label": "ENT", "start_offset": 192, "end_offset": 200}, {"id": 1090521, "label": "ENT", "start_offset": 219, "end_offset": 238}, {"id": 1090522, "label": "ENT", "start_offset": 248, "end_offset": 254}, {"id": 1090523, "label": "ENT", "start_offset": 265, "end_offset": 275}, {"id": 1090524, "label": "ENT", "start_offset": 287, "end_offset": 299}, {"id": 1090525, "label": "ENT", "start_offset": 308, "end_offset": 331}, {"id": 1090526, "label": "ENT", "start_offset": 341, "end_offset": 372}, {"id": 1090527, "label": "ENT", "start_offset": 374, "end_offset": 396}, {"id": 1090528, "label": "ENT", "start_offset": 401, "end_offset": 418}, {"id": 1090529, "label": "ENT", "start_offset": 443, "end_offset": 451}, {"id": 1090530, "label": "ENT", "start_offset": 476, "end_offset": 511}], "relations": [{"id": 174178, "from_id": 1090517, "to_id": 1090518, "type": "USED-FOR"}, {"id": 174179, "from_id": 1090519, "to_id": 1090517, "type": "USED-FOR"}, {"id": 174180, "from_id": 1090520, "to_id": 1090517, "type": "COREF"}, {"id": 174181, "from_id": 1090523, "to_id": 1090522, "type": "HYPONYM-OF"}, {"id": 174182, "from_id": 1090522, "to_id": 1090521, "type": "COREF"}, {"id": 174183, "from_id": 1090525, "to_id": 1090522, "type": "HYPONYM-OF"}, {"id": 174184, "from_id": 1090526, "to_id": 1090525, "type": "USED-FOR"}, {"id": 174185, "from_id": 1090527, "to_id": 1090528, "type": "USED-FOR"}, {"id": 174186, "from_id": 1090529, "to_id": 1090530, "type": "USED-FOR"}, {"id": 174187, "from_id": 1090530, "to_id": 1090518, "type": "COREF"}]}
{"id": "CVPR_2012_11_abs", "text": "We propose a unified variational formulation for joint motion estimation and segmentation with explicit occlusion handling. This is done by a multi-label representation of the flow field, where each label corresponds to a parametric representation of the motion. We use a convex formulation of the multi-label Potts model with label costs and show that the asymmetric map-uniqueness criterion can be integrated into our formulation by means of convex constraints. Explicit occlusion handling eliminates errors otherwise created by the regularization. As occlusions can occur only at object boundaries, a large number of objects may be required. By using a fast primal-dual algorithm we are able to handle several hundred motion segments. Results are shown on several classical motion segmentation and optical flow examples.", "Comments": [], "entities": [{"id": 1090567, "label": "ENT", "start_offset": 13, "end_offset": 44}, {"id": 1090568, "label": "ENT", "start_offset": 49, "end_offset": 89}, {"id": 1090569, "label": "ENT", "start_offset": 95, "end_offset": 122}, {"id": 1090570, "label": "ENT", "start_offset": 142, "end_offset": 186}, {"id": 1090571, "label": "ENT", "start_offset": 222, "end_offset": 261}, {"id": 1090572, "label": "ENT", "start_offset": 272, "end_offset": 290}, {"id": 1090573, "label": "ENT", "start_offset": 298, "end_offset": 321}, {"id": 1090574, "label": "ENT", "start_offset": 357, "end_offset": 392}, {"id": 1090575, "label": "ENT", "start_offset": 420, "end_offset": 431}, {"id": 1090576, "label": "ENT", "start_offset": 444, "end_offset": 462}, {"id": 1090577, "label": "ENT", "start_offset": 464, "end_offset": 491}, {"id": 1090578, "label": "ENT", "start_offset": 535, "end_offset": 549}, {"id": 1090579, "label": "ENT", "start_offset": 554, "end_offset": 564}, {"id": 1090580, "label": "ENT", "start_offset": 583, "end_offset": 600}, {"id": 1090581, "label": "ENT", "start_offset": 661, "end_offset": 682}, {"id": 1090582, "label": "ENT", "start_offset": 721, "end_offset": 736}, {"id": 1090583, "label": "ENT", "start_offset": 767, "end_offset": 796}, {"id": 1090584, "label": "ENT", "start_offset": 801, "end_offset": 813}], "relations": [{"id": 174210, "from_id": 1090567, "to_id": 1090568, "type": "USED-FOR"}, {"id": 174211, "from_id": 1090569, "to_id": 1090567, "type": "USED-FOR"}, {"id": 174212, "from_id": 1090572, "to_id": 1090575, "type": "COREF"}, {"id": 174213, "from_id": 1090574, "to_id": 1090575, "type": "PART-OF"}, {"id": 174214, "from_id": 1090572, "to_id": 1090573, "type": "USED-FOR"}, {"id": 174215, "from_id": 1090576, "to_id": 1090575, "type": "USED-FOR"}, {"id": 174216, "from_id": 1090569, "to_id": 1090577, "type": "COREF"}, {"id": 174217, "from_id": 1090581, "to_id": 1090582, "type": "USED-FOR"}]}
{"id": "P06-2059", "text": " This paper proposes a novel method of building  polarity-tagged corpus  from  HTML documents  . The characteristics of this method is that it is fully automatic and can be applied to arbitrary  HTML documents  . The idea behind our method is to utilize certain  layout structures  and  linguistic pattern  . By using them, we can automatically extract such  sentences  that express opinion. In our experiment, the method could construct a  corpus  consisting of 126,610  sentences  . ", "Comments": [], "entities": [{"id": 1090675, "label": "ENT", "start_offset": 29, "end_offset": 35}, {"id": 1090676, "label": "ENT", "start_offset": 39, "end_offset": 71}, {"id": 1090677, "label": "ENT", "start_offset": 79, "end_offset": 93}, {"id": 1090678, "label": "ENT", "start_offset": 125, "end_offset": 131}, {"id": 1090679, "label": "ENT", "start_offset": 140, "end_offset": 142}, {"id": 1090680, "label": "ENT", "start_offset": 195, "end_offset": 209}, {"id": 1090681, "label": "ENT", "start_offset": 233, "end_offset": 239}, {"id": 1090682, "label": "ENT", "start_offset": 263, "end_offset": 280}, {"id": 1090683, "label": "ENT", "start_offset": 287, "end_offset": 305}, {"id": 1090684, "label": "ENT", "start_offset": 318, "end_offset": 322}, {"id": 1090685, "label": "ENT", "start_offset": 415, "end_offset": 421}], "relations": [{"id": 174281, "from_id": 1090675, "to_id": 1090676, "type": "USED-FOR"}, {"id": 174282, "from_id": 1090677, "to_id": 1090675, "type": "USED-FOR"}, {"id": 174283, "from_id": 1090675, "to_id": 1090678, "type": "COREF"}, {"id": 174284, "from_id": 1090678, "to_id": 1090679, "type": "COREF"}, {"id": 174285, "from_id": 1090679, "to_id": 1090680, "type": "USED-FOR"}, {"id": 174286, "from_id": 1090677, "to_id": 1090680, "type": "COREF"}, {"id": 174287, "from_id": 1090678, "to_id": 1090681, "type": "COREF"}, {"id": 174288, "from_id": 1090682, "to_id": 1090681, "type": "USED-FOR"}, {"id": 174289, "from_id": 1090683, "to_id": 1090681, "type": "USED-FOR"}, {"id": 174290, "from_id": 1090682, "to_id": 1090683, "type": "CONJUNCTION"}, {"id": 174291, "from_id": 1090682, "to_id": 1090684, "type": "HYPONYM-OF"}, {"id": 174292, "from_id": 1090683, "to_id": 1090684, "type": "HYPONYM-OF"}, {"id": 174293, "from_id": 1090681, "to_id": 1090685, "type": "COREF"}]}
{"id": "INTERSPEECH_2008_20_abs", "text": "In the study of expressive speech communication, it is commonly accepted that the emotion perceived by the listener is a good approximation of the intended emotion conveyed by the speaker. This paper analyzes the validity of this assumption by comparing the mismatches between the assessments made by na\u00a8\u0131ve listeners and by the speakers that generated the data. The analysis is based on the hypothesis that people are better decoders of their own emotions. Therefore, self-assessments will be closer to the intended emotions. Using the IEMOCAP database, discrete (categorical) and continuous (attribute) emotional assessments evaluated by the actors and na\u00a8\u0131ve listeners are compared. The results indicate that there is a mismatch between the expression and perception of emotion. The speakers in the database assigned their own emotions to more specific emotional categories, which led to more extreme values in the activation-valence space.", "Comments": [], "entities": [{"id": 1090774, "label": "ENT", "start_offset": 16, "end_offset": 47}, {"id": 1090775, "label": "ENT", "start_offset": 537, "end_offset": 553}, {"id": 1090776, "label": "ENT", "start_offset": 555, "end_offset": 626}, {"id": 1090777, "label": "ENT", "start_offset": 744, "end_offset": 780}, {"id": 1090778, "label": "ENT", "start_offset": 802, "end_offset": 810}, {"id": 1090779, "label": "ENT", "start_offset": 918, "end_offset": 942}], "relations": [{"id": 174358, "from_id": 1090775, "to_id": 1090776, "type": "USED-FOR"}, {"id": 174359, "from_id": 1090778, "to_id": 1090775, "type": "COREF"}]}
{"id": "N03-1017", "text": " We propose a new  phrase-based translation model  and  decoding algorithm  that enables us to evaluate and compare several, previously proposed  phrase-based translation models  . Within our framework, we carry out a large number of experiments to understand better and explain why  phrase-based models  outperform  word-based models  . Our empirical results, which hold for all examined  language pairs  , suggest that the highest levels of performance can be obtained through relatively simple means:  heuristic learning  of  phrase translations  from  word-based alignments  and  lexical weighting  of  phrase translations  . Surprisingly, learning  phrases  longer than three  words  and learning  phrases  from  high-accuracy word-level alignment models  does not have a strong impact on performance. Learning only  syntactically motivated phrases  degrades the performance of our systems. ", "Comments": [], "entities": [{"id": 1090780, "label": "ENT", "start_offset": 19, "end_offset": 49}, {"id": 1090781, "label": "ENT", "start_offset": 56, "end_offset": 74}, {"id": 1090782, "label": "ENT", "start_offset": 146, "end_offset": 177}, {"id": 1090783, "label": "ENT", "start_offset": 192, "end_offset": 201}, {"id": 1090784, "label": "ENT", "start_offset": 284, "end_offset": 303}, {"id": 1090785, "label": "ENT", "start_offset": 317, "end_offset": 334}, {"id": 1090786, "label": "ENT", "start_offset": 497, "end_offset": 502}, {"id": 1090787, "label": "ENT", "start_offset": 505, "end_offset": 548}, {"id": 1090788, "label": "ENT", "start_offset": 556, "end_offset": 577}, {"id": 1090789, "label": "ENT", "start_offset": 584, "end_offset": 626}, {"id": 1090790, "label": "ENT", "start_offset": 718, "end_offset": 759}, {"id": 1090791, "label": "ENT", "start_offset": 887, "end_offset": 894}], "relations": [{"id": 174360, "from_id": 1090784, "to_id": 1090785, "type": "COMPARE"}, {"id": 174361, "from_id": 1090780, "to_id": 1090781, "type": "CONJUNCTION"}, {"id": 174362, "from_id": 1090784, "to_id": 1090782, "type": "COREF"}, {"id": 174363, "from_id": 1090791, "to_id": 1090780, "type": "COREF"}, {"id": 174364, "from_id": 1090783, "to_id": 1090780, "type": "COREF"}, {"id": 174365, "from_id": 1090788, "to_id": 1090787, "type": "USED-FOR"}, {"id": 174366, "from_id": 1090787, "to_id": 1090786, "type": "HYPONYM-OF"}, {"id": 174367, "from_id": 1090789, "to_id": 1090786, "type": "HYPONYM-OF"}]}
{"id": "J05-4003", "text": "  We present a novel method for  discovering parallel sentences  in  comparable, non-parallel corpora  . We train a  maximum entropy classifier  that, given a pair of  sentences  , can reliably determine whether or not they are  translations  of each other. Using this approach, we extract  parallel data  from large  Chinese, Arabic, and English non-parallel newspaper corpora  . We evaluate the  quality of the extracted data  by showing that it improves the performance of a state-of-the-art  statistical machine translation system  . We also show that a good-quality  MT system  can be built from scratch by starting with a very small  parallel corpus  (100,000  words  ) and exploiting a large  non-parallel corpus  . Thus, our method can be applied with great benefit to  language pairs  for which only scarce  resources  are available. ", "Comments": [], "entities": [{"id": 1090860, "label": "ENT", "start_offset": 21, "end_offset": 27}, {"id": 1090861, "label": "ENT", "start_offset": 33, "end_offset": 63}, {"id": 1090862, "label": "ENT", "start_offset": 69, "end_offset": 101}, {"id": 1090863, "label": "ENT", "start_offset": 117, "end_offset": 143}, {"id": 1090864, "label": "ENT", "start_offset": 269, "end_offset": 277}, {"id": 1090865, "label": "ENT", "start_offset": 291, "end_offset": 304}, {"id": 1090866, "label": "ENT", "start_offset": 318, "end_offset": 377}, {"id": 1090867, "label": "ENT", "start_offset": 445, "end_offset": 447}, {"id": 1090868, "label": "ENT", "start_offset": 496, "end_offset": 534}, {"id": 1090869, "label": "ENT", "start_offset": 572, "end_offset": 581}, {"id": 1090870, "label": "ENT", "start_offset": 640, "end_offset": 655}, {"id": 1090871, "label": "ENT", "start_offset": 700, "end_offset": 719}, {"id": 1090872, "label": "ENT", "start_offset": 733, "end_offset": 739}, {"id": 1090873, "label": "ENT", "start_offset": 809, "end_offset": 826}], "relations": [{"id": 174430, "from_id": 1090862, "to_id": 1090861, "type": "USED-FOR"}, {"id": 174431, "from_id": 1090865, "to_id": 1090866, "type": "PART-OF"}, {"id": 174432, "from_id": 1090870, "to_id": 1090869, "type": "USED-FOR"}, {"id": 174433, "from_id": 1090860, "to_id": 1090861, "type": "USED-FOR"}, {"id": 174434, "from_id": 1090864, "to_id": 1090860, "type": "COREF"}, {"id": 174435, "from_id": 1090864, "to_id": 1090865, "type": "USED-FOR"}, {"id": 174436, "from_id": 1090869, "to_id": 1090868, "type": "COREF"}, {"id": 174437, "from_id": 1090871, "to_id": 1090869, "type": "USED-FOR"}, {"id": 174438, "from_id": 1090870, "to_id": 1090871, "type": "CONJUNCTION"}, {"id": 174439, "from_id": 1090864, "to_id": 1090867, "type": "COREF"}, {"id": 174440, "from_id": 1090867, "to_id": 1090868, "type": "USED-FOR"}, {"id": 174441, "from_id": 1090864, "to_id": 1090863, "type": "COREF"}, {"id": 174442, "from_id": 1090873, "to_id": 1090872, "type": "USED-FOR"}, {"id": 174443, "from_id": 1090867, "to_id": 1090872, "type": "COREF"}]}
{"id": "C92-1052", "text": "   In this paper  discourse segments  are defined and a method for  discourse segmentation  primarily based on  abduction  of  temporal relations  between  segments  is proposed. This method is precise and  computationally feasible  and is supported by previous work in the area of  temporal anaphora resolution  . ", "Comments": [], "entities": [{"id": 1090900, "label": "ENT", "start_offset": 18, "end_offset": 36}, {"id": 1090901, "label": "ENT", "start_offset": 56, "end_offset": 62}, {"id": 1090902, "label": "ENT", "start_offset": 68, "end_offset": 90}, {"id": 1090903, "label": "ENT", "start_offset": 112, "end_offset": 145}, {"id": 1090904, "label": "ENT", "start_offset": 184, "end_offset": 190}, {"id": 1090905, "label": "ENT", "start_offset": 283, "end_offset": 311}], "relations": [{"id": 174466, "from_id": 1090901, "to_id": 1090902, "type": "USED-FOR"}, {"id": 174467, "from_id": 1090904, "to_id": 1090901, "type": "COREF"}, {"id": 174468, "from_id": 1090905, "to_id": 1090904, "type": "USED-FOR"}, {"id": 174469, "from_id": 1090903, "to_id": 1090902, "type": "USED-FOR"}]}
{"id": "P06-4011", "text": "   This paper introduces a method for  computational analysis of move structures  in  abstracts  of  research articles  . In our approach,  sentences  in a given  abstract  are analyzed and labeled with a specific  move  in light of various  rhetorical functions  . The method involves automatically gathering a large number of  abstracts  from the  Web  and building a  language model  of  abstract moves  . We also present a prototype  concordancer  ,  CARE  , which exploits the  move-tagged abstracts  for  digital learning  . This system provides a promising approach to  Web-based computer-assisted academic writing  . ", "Comments": [], "entities": [{"id": 1090930, "label": "ENT", "start_offset": 27, "end_offset": 33}, {"id": 1090931, "label": "ENT", "start_offset": 39, "end_offset": 80}, {"id": 1090932, "label": "ENT", "start_offset": 86, "end_offset": 118}, {"id": 1090933, "label": "ENT", "start_offset": 129, "end_offset": 137}, {"id": 1090934, "label": "ENT", "start_offset": 242, "end_offset": 262}, {"id": 1090935, "label": "ENT", "start_offset": 270, "end_offset": 276}, {"id": 1090936, "label": "ENT", "start_offset": 329, "end_offset": 338}, {"id": 1090937, "label": "ENT", "start_offset": 350, "end_offset": 353}, {"id": 1090938, "label": "ENT", "start_offset": 371, "end_offset": 385}, {"id": 1090939, "label": "ENT", "start_offset": 391, "end_offset": 405}, {"id": 1090940, "label": "ENT", "start_offset": 427, "end_offset": 450}, {"id": 1090941, "label": "ENT", "start_offset": 455, "end_offset": 459}, {"id": 1090942, "label": "ENT", "start_offset": 483, "end_offset": 504}, {"id": 1090943, "label": "ENT", "start_offset": 511, "end_offset": 527}, {"id": 1090944, "label": "ENT", "start_offset": 536, "end_offset": 542}, {"id": 1090945, "label": "ENT", "start_offset": 564, "end_offset": 572}, {"id": 1090946, "label": "ENT", "start_offset": 577, "end_offset": 621}], "relations": [{"id": 174488, "from_id": 1090939, "to_id": 1090938, "type": "USED-FOR"}, {"id": 174489, "from_id": 1090942, "to_id": 1090943, "type": "USED-FOR"}, {"id": 174490, "from_id": 1090930, "to_id": 1090931, "type": "USED-FOR"}, {"id": 174491, "from_id": 1090932, "to_id": 1090931, "type": "USED-FOR"}, {"id": 174492, "from_id": 1090930, "to_id": 1090933, "type": "COREF"}, {"id": 174493, "from_id": 1090933, "to_id": 1090935, "type": "COREF"}, {"id": 174494, "from_id": 1090937, "to_id": 1090936, "type": "USED-FOR"}, {"id": 174495, "from_id": 1090945, "to_id": 1090946, "type": "USED-FOR"}, {"id": 174496, "from_id": 1090941, "to_id": 1090942, "type": "USED-FOR"}, {"id": 174497, "from_id": 1090941, "to_id": 1090940, "type": "HYPONYM-OF"}, {"id": 174498, "from_id": 1090944, "to_id": 1090941, "type": "COREF"}, {"id": 174499, "from_id": 1090944, "to_id": 1090945, "type": "USED-FOR"}]}
{"id": "CVPR_1998_10_abs", "text": "The compact description of a video sequence through a single image map and a dominant motion has applications in several domains, including video browsing and retrieval, compression, mosaicing, and visual summarization. Building such a representation requires the capability to register all the frames with respect to the dominant object in the scene, a task which has been, in the past, addressed through temporally localized motion estimates. In this paper, we show how the lack of temporal consistency associated with such estimates can undermine the validity of the dominant motion assumption, leading to oscillation between different scene interpretations and poor registration. To avoid this oscillation, we augment the motion model with a generic temporal constraint which increases the robustness against competing interpretations, leading to more meaningful content summarization.", "Comments": [], "entities": [{"id": 1091009, "label": "ENT", "start_offset": 4, "end_offset": 43}, {"id": 1091010, "label": "ENT", "start_offset": 61, "end_offset": 70}, {"id": 1091011, "label": "ENT", "start_offset": 77, "end_offset": 92}, {"id": 1091012, "label": "ENT", "start_offset": 121, "end_offset": 128}, {"id": 1091013, "label": "ENT", "start_offset": 140, "end_offset": 168}, {"id": 1091014, "label": "ENT", "start_offset": 170, "end_offset": 181}, {"id": 1091015, "label": "ENT", "start_offset": 183, "end_offset": 192}, {"id": 1091016, "label": "ENT", "start_offset": 198, "end_offset": 218}, {"id": 1091017, "label": "ENT", "start_offset": 236, "end_offset": 250}, {"id": 1091018, "label": "ENT", "start_offset": 354, "end_offset": 358}, {"id": 1091019, "label": "ENT", "start_offset": 417, "end_offset": 443}, {"id": 1091020, "label": "ENT", "start_offset": 476, "end_offset": 504}, {"id": 1091021, "label": "ENT", "start_offset": 526, "end_offset": 535}, {"id": 1091022, "label": "ENT", "start_offset": 554, "end_offset": 596}, {"id": 1091023, "label": "ENT", "start_offset": 609, "end_offset": 682}, {"id": 1091024, "label": "ENT", "start_offset": 698, "end_offset": 709}, {"id": 1091025, "label": "ENT", "start_offset": 726, "end_offset": 738}, {"id": 1091026, "label": "ENT", "start_offset": 746, "end_offset": 773}, {"id": 1091027, "label": "ENT", "start_offset": 794, "end_offset": 804}, {"id": 1091028, "label": "ENT", "start_offset": 867, "end_offset": 888}], "relations": [{"id": 174547, "from_id": 1091013, "to_id": 1091014, "type": "CONJUNCTION"}, {"id": 174548, "from_id": 1091014, "to_id": 1091015, "type": "CONJUNCTION"}, {"id": 174549, "from_id": 1091015, "to_id": 1091016, "type": "CONJUNCTION"}, {"id": 174550, "from_id": 1091013, "to_id": 1091012, "type": "HYPONYM-OF"}, {"id": 174551, "from_id": 1091014, "to_id": 1091012, "type": "HYPONYM-OF"}, {"id": 174552, "from_id": 1091015, "to_id": 1091012, "type": "HYPONYM-OF"}, {"id": 174553, "from_id": 1091009, "to_id": 1091012, "type": "USED-FOR"}, {"id": 174554, "from_id": 1091010, "to_id": 1091009, "type": "USED-FOR"}, {"id": 174555, "from_id": 1091011, "to_id": 1091009, "type": "USED-FOR"}, {"id": 174556, "from_id": 1091010, "to_id": 1091011, "type": "CONJUNCTION"}, {"id": 174557, "from_id": 1091017, "to_id": 1091009, "type": "COREF"}, {"id": 174558, "from_id": 1091019, "to_id": 1091018, "type": "USED-FOR"}, {"id": 174559, "from_id": 1091021, "to_id": 1091019, "type": "COREF"}, {"id": 174560, "from_id": 1091024, "to_id": 1091023, "type": "COREF"}, {"id": 174561, "from_id": 1091026, "to_id": 1091025, "type": "USED-FOR"}, {"id": 174562, "from_id": 1091027, "to_id": 1091026, "type": "EVALUATE-FOR"}, {"id": 174563, "from_id": 1091026, "to_id": 1091028, "type": "USED-FOR"}]}
{"id": "CVPR_2009_11_abs", "text": "Due to the capacity of pan-tilt-zoom (PTZ) cameras to simultaneously cover a panoramic area and maintain high resolution imagery, researches in automated surveillance systems with multiple PTZ cameras have become increasingly important. Most existing algorithms require the prior knowledge of intrinsic parameters of the PTZ camera to infer the relative positioning and orientation among multiple PTZ cameras. To overcome this limitation, we propose a novel mapping algorithm that derives the relative positioning and orientation between two PTZ cameras based on a unified polynomial model. This reduces the dependence on the knowledge of intrinsic parameters of PTZ camera and relative positions. Experimental results demonstrate that our proposed algorithm presents substantially reduced computational complexity and improved flexibility at the cost of slightly decreased pixel accuracy, as compared with the work of Chen and Wang. This slightly decreased pixel accuracy can be compensated by consistent labeling approaches without added cost for the application of automated surveillance systems along with changing configurations and a larger number of PTZ cameras.", "Comments": [], "entities": [{"id": 1091062, "label": "ENT", "start_offset": 23, "end_offset": 50}, {"id": 1091063, "label": "ENT", "start_offset": 77, "end_offset": 91}, {"id": 1091064, "label": "ENT", "start_offset": 105, "end_offset": 128}, {"id": 1091065, "label": "ENT", "start_offset": 144, "end_offset": 174}, {"id": 1091066, "label": "ENT", "start_offset": 189, "end_offset": 200}, {"id": 1091067, "label": "ENT", "start_offset": 251, "end_offset": 261}, {"id": 1091068, "label": "ENT", "start_offset": 274, "end_offset": 331}, {"id": 1091069, "label": "ENT", "start_offset": 345, "end_offset": 365}, {"id": 1091070, "label": "ENT", "start_offset": 370, "end_offset": 381}, {"id": 1091071, "label": "ENT", "start_offset": 397, "end_offset": 408}, {"id": 1091072, "label": "ENT", "start_offset": 458, "end_offset": 475}, {"id": 1091073, "label": "ENT", "start_offset": 493, "end_offset": 513}, {"id": 1091074, "label": "ENT", "start_offset": 518, "end_offset": 529}, {"id": 1091075, "label": "ENT", "start_offset": 542, "end_offset": 553}, {"id": 1091076, "label": "ENT", "start_offset": 565, "end_offset": 589}, {"id": 1091077, "label": "ENT", "start_offset": 663, "end_offset": 673}, {"id": 1091078, "label": "ENT", "start_offset": 678, "end_offset": 696}, {"id": 1091079, "label": "ENT", "start_offset": 749, "end_offset": 758}, {"id": 1091080, "label": "ENT", "start_offset": 790, "end_offset": 814}, {"id": 1091081, "label": "ENT", "start_offset": 828, "end_offset": 839}, {"id": 1091082, "label": "ENT", "start_offset": 874, "end_offset": 888}, {"id": 1091083, "label": "ENT", "start_offset": 958, "end_offset": 972}, {"id": 1091084, "label": "ENT", "start_offset": 995, "end_offset": 1025}, {"id": 1091085, "label": "ENT", "start_offset": 1068, "end_offset": 1098}, {"id": 1091086, "label": "ENT", "start_offset": 1157, "end_offset": 1168}], "relations": [{"id": 174593, "from_id": 1091068, "to_id": 1091067, "type": "USED-FOR"}, {"id": 174594, "from_id": 1091067, "to_id": 1091069, "type": "USED-FOR"}, {"id": 174595, "from_id": 1091067, "to_id": 1091070, "type": "USED-FOR"}, {"id": 174596, "from_id": 1091069, "to_id": 1091070, "type": "CONJUNCTION"}, {"id": 174597, "from_id": 1091069, "to_id": 1091071, "type": "FEATURE-OF"}, {"id": 174598, "from_id": 1091070, "to_id": 1091071, "type": "FEATURE-OF"}, {"id": 174599, "from_id": 1091076, "to_id": 1091072, "type": "USED-FOR"}, {"id": 174600, "from_id": 1091072, "to_id": 1091073, "type": "USED-FOR"}, {"id": 174601, "from_id": 1091072, "to_id": 1091074, "type": "USED-FOR"}, {"id": 174602, "from_id": 1091073, "to_id": 1091074, "type": "CONJUNCTION"}, {"id": 174603, "from_id": 1091074, "to_id": 1091075, "type": "FEATURE-OF"}, {"id": 174604, "from_id": 1091073, "to_id": 1091075, "type": "FEATURE-OF"}, {"id": 174605, "from_id": 1091080, "to_id": 1091079, "type": "EVALUATE-FOR"}, {"id": 174606, "from_id": 1091081, "to_id": 1091079, "type": "EVALUATE-FOR"}, {"id": 174607, "from_id": 1091082, "to_id": 1091079, "type": "EVALUATE-FOR"}, {"id": 174608, "from_id": 1091083, "to_id": 1091082, "type": "COREF"}, {"id": 174609, "from_id": 1091084, "to_id": 1091083, "type": "USED-FOR"}, {"id": 174610, "from_id": 1091062, "to_id": 1091063, "type": "USED-FOR"}, {"id": 174611, "from_id": 1091062, "to_id": 1091064, "type": "USED-FOR"}, {"id": 174612, "from_id": 1091065, "to_id": 1091085, "type": "COREF"}, {"id": 174613, "from_id": 1091072, "to_id": 1091079, "type": "COREF"}, {"id": 174614, "from_id": 1091066, "to_id": 1091065, "type": "FEATURE-OF"}]}
{"id": "C04-1112", "text": " In this paper, we present a  corpus-based supervised word sense disambiguation (WSD) system  for  Dutch  which combines  statistical classification  ( maximum entropy ) with  linguistic information . Instead of building individual  classifiers  per  ambiguous wordform , we introduce a  lemma-based approach . The advantage of this novel method is that it clusters all  inflected forms  of an  ambiguous word  in one  classifier , therefore augmenting the  training material  available to the  algorithm . Testing the  lemma-based model  on the  Dutch Senseval-2 test data , we achieve a significant increase in  accuracy  over the  wordform model . Also, the  WSD system based on lemmas  is smaller and more robust. ", "Comments": [], "entities": [{"id": 1091092, "label": "ENT", "start_offset": 30, "end_offset": 92}, {"id": 1091093, "label": "ENT", "start_offset": 99, "end_offset": 104}, {"id": 1091094, "label": "ENT", "start_offset": 122, "end_offset": 148}, {"id": 1091095, "label": "ENT", "start_offset": 152, "end_offset": 167}, {"id": 1091096, "label": "ENT", "start_offset": 176, "end_offset": 198}, {"id": 1091097, "label": "ENT", "start_offset": 233, "end_offset": 244}, {"id": 1091098, "label": "ENT", "start_offset": 251, "end_offset": 269}, {"id": 1091099, "label": "ENT", "start_offset": 288, "end_offset": 308}, {"id": 1091100, "label": "ENT", "start_offset": 339, "end_offset": 345}, {"id": 1091101, "label": "ENT", "start_offset": 354, "end_offset": 356}, {"id": 1091102, "label": "ENT", "start_offset": 371, "end_offset": 386}, {"id": 1091103, "label": "ENT", "start_offset": 395, "end_offset": 409}, {"id": 1091104, "label": "ENT", "start_offset": 419, "end_offset": 429}, {"id": 1091105, "label": "ENT", "start_offset": 495, "end_offset": 504}, {"id": 1091106, "label": "ENT", "start_offset": 520, "end_offset": 537}, {"id": 1091107, "label": "ENT", "start_offset": 547, "end_offset": 573}, {"id": 1091108, "label": "ENT", "start_offset": 634, "end_offset": 648}, {"id": 1091109, "label": "ENT", "start_offset": 662, "end_offset": 688}], "relations": [{"id": 174616, "from_id": 1091092, "to_id": 1091093, "type": "USED-FOR"}, {"id": 174617, "from_id": 1091097, "to_id": 1091099, "type": "COMPARE"}, {"id": 174618, "from_id": 1091102, "to_id": 1091103, "type": "FEATURE-OF"}, {"id": 174619, "from_id": 1091107, "to_id": 1091106, "type": "EVALUATE-FOR"}, {"id": 174620, "from_id": 1091095, "to_id": 1091094, "type": "COREF"}, {"id": 174621, "from_id": 1091096, "to_id": 1091095, "type": "CONJUNCTION"}, {"id": 174622, "from_id": 1091094, "to_id": 1091092, "type": "PART-OF"}, {"id": 174623, "from_id": 1091096, "to_id": 1091092, "type": "PART-OF"}, {"id": 174624, "from_id": 1091095, "to_id": 1091092, "type": "PART-OF"}, {"id": 174625, "from_id": 1091098, "to_id": 1091097, "type": "USED-FOR"}, {"id": 174626, "from_id": 1091100, "to_id": 1091099, "type": "COREF"}, {"id": 174627, "from_id": 1091105, "to_id": 1091100, "type": "COREF"}, {"id": 174628, "from_id": 1091106, "to_id": 1091108, "type": "COMPARE"}, {"id": 174629, "from_id": 1091109, "to_id": 1091106, "type": "COREF"}, {"id": 174630, "from_id": 1091106, "to_id": 1091105, "type": "COREF"}, {"id": 174631, "from_id": 1091099, "to_id": 1091092, "type": "COREF"}, {"id": 174632, "from_id": 1091101, "to_id": 1091100, "type": "COREF"}]}
{"id": "IJCAI_2010_5_abs", "text": "Recent advances in linear classification have shown that for applications such as document classification, the training can be extremely efficient. However, most of the existing training methods are designed by assuming that data can be stored in the computer memory. These methods cannot be easily applied to data larger than the memory capacity due to the random access to the disk. We propose and analyze a block minimization framework for data larger than the memory size. At each step a block of data is loaded from the disk and handled by certain learning methods. We investigate two implementations of the proposed framework for primal and dual SVMs, respectively. As data cannot fit in memory, many design considerations are very different from those for traditional algorithms. Experiments using data sets 20 times larger than the memory demonstrate the effectiveness of the proposed method.", "Comments": [], "entities": [{"id": 1091195, "label": "ENT", "start_offset": 19, "end_offset": 40}, {"id": 1091196, "label": "ENT", "start_offset": 61, "end_offset": 73}, {"id": 1091197, "label": "ENT", "start_offset": 82, "end_offset": 105}, {"id": 1091198, "label": "ENT", "start_offset": 178, "end_offset": 194}, {"id": 1091199, "label": "ENT", "start_offset": 251, "end_offset": 266}, {"id": 1091200, "label": "ENT", "start_offset": 274, "end_offset": 281}, {"id": 1091201, "label": "ENT", "start_offset": 310, "end_offset": 314}, {"id": 1091202, "label": "ENT", "start_offset": 331, "end_offset": 346}, {"id": 1091203, "label": "ENT", "start_offset": 358, "end_offset": 371}, {"id": 1091204, "label": "ENT", "start_offset": 379, "end_offset": 383}, {"id": 1091205, "label": "ENT", "start_offset": 410, "end_offset": 438}, {"id": 1091206, "label": "ENT", "start_offset": 443, "end_offset": 447}, {"id": 1091207, "label": "ENT", "start_offset": 464, "end_offset": 475}, {"id": 1091208, "label": "ENT", "start_offset": 525, "end_offset": 529}, {"id": 1091209, "label": "ENT", "start_offset": 553, "end_offset": 569}, {"id": 1091210, "label": "ENT", "start_offset": 622, "end_offset": 631}, {"id": 1091211, "label": "ENT", "start_offset": 636, "end_offset": 656}, {"id": 1091212, "label": "ENT", "start_offset": 893, "end_offset": 899}], "relations": [{"id": 174710, "from_id": 1091197, "to_id": 1091196, "type": "HYPONYM-OF"}, {"id": 174711, "from_id": 1091200, "to_id": 1091198, "type": "COREF"}, {"id": 174712, "from_id": 1091205, "to_id": 1091206, "type": "USED-FOR"}, {"id": 174713, "from_id": 1091205, "to_id": 1091210, "type": "COREF"}, {"id": 174714, "from_id": 1091210, "to_id": 1091211, "type": "USED-FOR"}, {"id": 174715, "from_id": 1091212, "to_id": 1091210, "type": "COREF"}, {"id": 174716, "from_id": 1091201, "to_id": 1091202, "type": "COMPARE"}, {"id": 174717, "from_id": 1091206, "to_id": 1091207, "type": "COMPARE"}]}
{"id": "CVPR_2001_110_abs", "text": "Representing images with layers has many important applications , such as video compression, motion analysis, and 3D scene analysis. This paper presents an approach to reliably extracting layers from images by taking advantages of the fact that homographies induced by planar patches in the scene form a low dimensional linear subspace. Layers in the input images will be mapped in the subspace, where it is proven that they form well-defined clusters and can be reliably identified by a simple mean-shift based clustering algorithm. Global optimality is achieved since all valid regions are simultaneously taken into account, and noise can be effectively reduced by enforcing the subspace constraint. Good layer descriptions are shown to be extracted in the experimental results.", "Comments": [], "entities": [{"id": 1091213, "label": "ENT", "start_offset": 0, "end_offset": 31}, {"id": 1091214, "label": "ENT", "start_offset": 51, "end_offset": 63}, {"id": 1091215, "label": "ENT", "start_offset": 74, "end_offset": 91}, {"id": 1091216, "label": "ENT", "start_offset": 93, "end_offset": 108}, {"id": 1091217, "label": "ENT", "start_offset": 114, "end_offset": 131}, {"id": 1091218, "label": "ENT", "start_offset": 156, "end_offset": 164}, {"id": 1091219, "label": "ENT", "start_offset": 188, "end_offset": 194}, {"id": 1091220, "label": "ENT", "start_offset": 200, "end_offset": 206}, {"id": 1091221, "label": "ENT", "start_offset": 245, "end_offset": 257}, {"id": 1091222, "label": "ENT", "start_offset": 269, "end_offset": 283}, {"id": 1091223, "label": "ENT", "start_offset": 291, "end_offset": 296}, {"id": 1091224, "label": "ENT", "start_offset": 304, "end_offset": 335}, {"id": 1091225, "label": "ENT", "start_offset": 337, "end_offset": 343}, {"id": 1091226, "label": "ENT", "start_offset": 357, "end_offset": 363}, {"id": 1091227, "label": "ENT", "start_offset": 386, "end_offset": 394}, {"id": 1091228, "label": "ENT", "start_offset": 443, "end_offset": 451}, {"id": 1091229, "label": "ENT", "start_offset": 495, "end_offset": 532}, {"id": 1091230, "label": "ENT", "start_offset": 534, "end_offset": 551}, {"id": 1091231, "label": "ENT", "start_offset": 580, "end_offset": 587}, {"id": 1091232, "label": "ENT", "start_offset": 631, "end_offset": 636}, {"id": 1091233, "label": "ENT", "start_offset": 681, "end_offset": 700}], "relations": [{"id": 174718, "from_id": 1091219, "to_id": 1091220, "type": "PART-OF"}, {"id": 174719, "from_id": 1091225, "to_id": 1091226, "type": "PART-OF"}, {"id": 174720, "from_id": 1091229, "to_id": 1091228, "type": "USED-FOR"}, {"id": 174721, "from_id": 1091226, "to_id": 1091228, "type": "USED-FOR"}, {"id": 174722, "from_id": 1091233, "to_id": 1091232, "type": "USED-FOR"}, {"id": 174723, "from_id": 1091215, "to_id": 1091214, "type": "HYPONYM-OF"}, {"id": 174724, "from_id": 1091216, "to_id": 1091214, "type": "HYPONYM-OF"}, {"id": 174725, "from_id": 1091217, "to_id": 1091214, "type": "HYPONYM-OF"}, {"id": 174726, "from_id": 1091215, "to_id": 1091216, "type": "CONJUNCTION"}, {"id": 174727, "from_id": 1091216, "to_id": 1091217, "type": "CONJUNCTION"}, {"id": 174728, "from_id": 1091213, "to_id": 1091214, "type": "USED-FOR"}, {"id": 174729, "from_id": 1091218, "to_id": 1091219, "type": "USED-FOR"}, {"id": 174730, "from_id": 1091222, "to_id": 1091223, "type": "PART-OF"}]}
{"id": "ECCV_1998_39_abs", "text": "Image sequence processing techniques are used to study exchange , growth, and transport processes and to tackle key questions in environmental physics and biology. These applications require high accuracy for the estimation of the motion field since the most interesting parameters of the dynamical processes studied are contained in first-order derivatives of the motion field or in dynamical changes of the moving objects. Therefore the performance and optimization of low-level motion estimators is discussed. A tensor method tuned with carefully optimized derivative filters yields reliable and dense displacement vector fields (DVF) with an accuracy of up to a few hundredth pixels/frame for real-world images. The accuracy of the tensor method is verified with computer-generated sequences and a calibrated image sequence. With the improvements in accuracy the motion estimation is now rather limited by imperfections in the CCD sensors, especially the spatial nonuni-formity in the responsivity. With a simple two-point calibration, these effects can efficiently be suppressed. The application of the techniques to the analysis of plant growth, to ocean surface microturbulence in IR image sequences, and to sediment transport is demonstrated.", "Comments": [], "entities": [{"id": 1091256, "label": "ENT", "start_offset": 0, "end_offset": 36}, {"id": 1091257, "label": "ENT", "start_offset": 55, "end_offset": 97}, {"id": 1091258, "label": "ENT", "start_offset": 129, "end_offset": 150}, {"id": 1091259, "label": "ENT", "start_offset": 155, "end_offset": 162}, {"id": 1091260, "label": "ENT", "start_offset": 170, "end_offset": 182}, {"id": 1091261, "label": "ENT", "start_offset": 196, "end_offset": 204}, {"id": 1091262, "label": "ENT", "start_offset": 213, "end_offset": 243}, {"id": 1091263, "label": "ENT", "start_offset": 289, "end_offset": 308}, {"id": 1091264, "label": "ENT", "start_offset": 334, "end_offset": 377}, {"id": 1091265, "label": "ENT", "start_offset": 384, "end_offset": 423}, {"id": 1091266, "label": "ENT", "start_offset": 455, "end_offset": 498}, {"id": 1091267, "label": "ENT", "start_offset": 515, "end_offset": 528}, {"id": 1091268, "label": "ENT", "start_offset": 560, "end_offset": 578}, {"id": 1091269, "label": "ENT", "start_offset": 605, "end_offset": 637}, {"id": 1091270, "label": "ENT", "start_offset": 646, "end_offset": 654}, {"id": 1091271, "label": "ENT", "start_offset": 680, "end_offset": 692}, {"id": 1091272, "label": "ENT", "start_offset": 697, "end_offset": 714}, {"id": 1091273, "label": "ENT", "start_offset": 720, "end_offset": 728}, {"id": 1091274, "label": "ENT", "start_offset": 736, "end_offset": 749}, {"id": 1091275, "label": "ENT", "start_offset": 767, "end_offset": 795}, {"id": 1091276, "label": "ENT", "start_offset": 802, "end_offset": 827}, {"id": 1091277, "label": "ENT", "start_offset": 854, "end_offset": 862}, {"id": 1091278, "label": "ENT", "start_offset": 867, "end_offset": 884}, {"id": 1091279, "label": "ENT", "start_offset": 931, "end_offset": 942}, {"id": 1091280, "label": "ENT", "start_offset": 959, "end_offset": 981}, {"id": 1091281, "label": "ENT", "start_offset": 989, "end_offset": 1001}, {"id": 1091282, "label": "ENT", "start_offset": 1017, "end_offset": 1038}, {"id": 1091283, "label": "ENT", "start_offset": 1108, "end_offset": 1118}, {"id": 1091284, "label": "ENT", "start_offset": 1126, "end_offset": 1150}, {"id": 1091285, "label": "ENT", "start_offset": 1155, "end_offset": 1206}, {"id": 1091286, "label": "ENT", "start_offset": 1215, "end_offset": 1233}], "relations": [{"id": 174750, "from_id": 1091258, "to_id": 1091259, "type": "CONJUNCTION"}, {"id": 174751, "from_id": 1091256, "to_id": 1091257, "type": "USED-FOR"}, {"id": 174752, "from_id": 1091261, "to_id": 1091262, "type": "EVALUATE-FOR"}, {"id": 174753, "from_id": 1091260, "to_id": 1091257, "type": "HYPONYM-OF"}, {"id": 174754, "from_id": 1091264, "to_id": 1091265, "type": "CONJUNCTION"}, {"id": 174755, "from_id": 1091268, "to_id": 1091267, "type": "USED-FOR"}, {"id": 174756, "from_id": 1091274, "to_id": 1091267, "type": "COREF"}, {"id": 174757, "from_id": 1091275, "to_id": 1091276, "type": "CONJUNCTION"}, {"id": 174758, "from_id": 1091273, "to_id": 1091274, "type": "EVALUATE-FOR"}, {"id": 174759, "from_id": 1091277, "to_id": 1091278, "type": "EVALUATE-FOR"}, {"id": 174760, "from_id": 1091283, "to_id": 1091256, "type": "COREF"}, {"id": 174761, "from_id": 1091283, "to_id": 1091284, "type": "USED-FOR"}, {"id": 174762, "from_id": 1091283, "to_id": 1091285, "type": "USED-FOR"}, {"id": 174763, "from_id": 1091283, "to_id": 1091286, "type": "USED-FOR"}, {"id": 174764, "from_id": 1091262, "to_id": 1091260, "type": "USED-FOR"}, {"id": 174765, "from_id": 1091272, "to_id": 1091271, "type": "USED-FOR"}, {"id": 174766, "from_id": 1091271, "to_id": 1091269, "type": "EVALUATE-FOR"}, {"id": 174767, "from_id": 1091275, "to_id": 1091274, "type": "EVALUATE-FOR"}, {"id": 174768, "from_id": 1091276, "to_id": 1091274, "type": "EVALUATE-FOR"}, {"id": 174769, "from_id": 1091279, "to_id": 1091278, "type": "USED-FOR"}, {"id": 174770, "from_id": 1091280, "to_id": 1091281, "type": "FEATURE-OF"}, {"id": 174771, "from_id": 1091281, "to_id": 1091279, "type": "FEATURE-OF"}, {"id": 174772, "from_id": 1091284, "to_id": 1091285, "type": "CONJUNCTION"}, {"id": 174773, "from_id": 1091285, "to_id": 1091286, "type": "CONJUNCTION"}]}
{"id": "E93-1066", "text": " This poster paper describes a  full scale two-level morphological description  (Karttunen, 1983; Koskenniemi, 1983) of  Turkish word structures . The description has been implemented using the  PC-KIMMO environment  (Antworth, 1990) and is based on a  root word lexicon  of about 23,000  roots words . Almost all the special cases of and exceptions to  phonological and morphological rules  have been implemented.  Turkish  is an  agglutinative language  with  word structures  formed by  productive affixations of derivational and inflectional suffixes  to  root words .  Turkish  has  finite-state  but nevertheless rather complex morphotactics.  Morphemes  added to a  root word  or a  stem  can convert the  word  from a  nominal  to a  verbal structure  or vice-versa, or can create  adverbial constructs . The  surface realizations  of  morphological constructions  are constrained and modified by a number of  phonetic rules  such as  vowel harmony . ", "Comments": [], "entities": [{"id": 1091461, "label": "ENT", "start_offset": 32, "end_offset": 78}, {"id": 1091462, "label": "ENT", "start_offset": 121, "end_offset": 144}, {"id": 1091463, "label": "ENT", "start_offset": 151, "end_offset": 162}, {"id": 1091464, "label": "ENT", "start_offset": 195, "end_offset": 215}, {"id": 1091465, "label": "ENT", "start_offset": 253, "end_offset": 270}, {"id": 1091466, "label": "ENT", "start_offset": 354, "end_offset": 390}, {"id": 1091467, "label": "ENT", "start_offset": 416, "end_offset": 423}, {"id": 1091468, "label": "ENT", "start_offset": 432, "end_offset": 454}, {"id": 1091469, "label": "ENT", "start_offset": 462, "end_offset": 477}, {"id": 1091470, "label": "ENT", "start_offset": 490, "end_offset": 554}, {"id": 1091471, "label": "ENT", "start_offset": 574, "end_offset": 581}, {"id": 1091472, "label": "ENT", "start_offset": 588, "end_offset": 600}, {"id": 1091473, "label": "ENT", "start_offset": 650, "end_offset": 659}, {"id": 1091474, "label": "ENT", "start_offset": 742, "end_offset": 758}, {"id": 1091475, "label": "ENT", "start_offset": 790, "end_offset": 810}, {"id": 1091476, "label": "ENT", "start_offset": 818, "end_offset": 871}, {"id": 1091477, "label": "ENT", "start_offset": 918, "end_offset": 932}, {"id": 1091478, "label": "ENT", "start_offset": 943, "end_offset": 956}], "relations": [{"id": 174906, "from_id": 1091461, "to_id": 1091462, "type": "USED-FOR"}, {"id": 174907, "from_id": 1091463, "to_id": 1091461, "type": "COREF"}, {"id": 174908, "from_id": 1091464, "to_id": 1091463, "type": "USED-FOR"}, {"id": 174909, "from_id": 1091465, "to_id": 1091463, "type": "USED-FOR"}, {"id": 174910, "from_id": 1091467, "to_id": 1091468, "type": "HYPONYM-OF"}, {"id": 174911, "from_id": 1091471, "to_id": 1091467, "type": "COREF"}, {"id": 174912, "from_id": 1091470, "to_id": 1091469, "type": "PART-OF"}, {"id": 174913, "from_id": 1091478, "to_id": 1091477, "type": "HYPONYM-OF"}, {"id": 174914, "from_id": 1091477, "to_id": 1091476, "type": "USED-FOR"}, {"id": 174915, "from_id": 1091469, "to_id": 1091468, "type": "FEATURE-OF"}]}
{"id": "C04-1103", "text": "  Machine transliteration/back-transliteration  plays an important role in many  multilingual speech and language applications . In this paper, a novel framework for  machine transliteration/backtransliteration  that allows us to carry out  direct orthographical mapping (DOM)  between two different  languages  is presented. Under this framework, a  joint source-channel transliteration model , also called  n-gram transliteration model (n-gram TM) , is further proposed to model the  transliteration process . We evaluate the proposed methods through several  transliteration/backtransliteration experiments  for  English/Chinese and English/Japanese language pairs . Our study reveals that the proposed method not only reduces an extensive  system development effort  but also improves the  transliteration accuracy  significantly. ", "Comments": [], "entities": [{"id": 1091492, "label": "ENT", "start_offset": 2, "end_offset": 46}, {"id": 1091493, "label": "ENT", "start_offset": 81, "end_offset": 126}, {"id": 1091494, "label": "ENT", "start_offset": 152, "end_offset": 161}, {"id": 1091495, "label": "ENT", "start_offset": 167, "end_offset": 210}, {"id": 1091496, "label": "ENT", "start_offset": 241, "end_offset": 276}, {"id": 1091497, "label": "ENT", "start_offset": 337, "end_offset": 346}, {"id": 1091498, "label": "ENT", "start_offset": 351, "end_offset": 393}, {"id": 1091499, "label": "ENT", "start_offset": 409, "end_offset": 449}, {"id": 1091500, "label": "ENT", "start_offset": 486, "end_offset": 509}, {"id": 1091501, "label": "ENT", "start_offset": 537, "end_offset": 544}, {"id": 1091502, "label": "ENT", "start_offset": 562, "end_offset": 597}, {"id": 1091503, "label": "ENT", "start_offset": 616, "end_offset": 667}, {"id": 1091504, "label": "ENT", "start_offset": 706, "end_offset": 712}, {"id": 1091505, "label": "ENT", "start_offset": 794, "end_offset": 818}], "relations": [{"id": 174924, "from_id": 1091492, "to_id": 1091493, "type": "USED-FOR"}, {"id": 174925, "from_id": 1091495, "to_id": 1091496, "type": "USED-FOR"}, {"id": 174926, "from_id": 1091499, "to_id": 1091500, "type": "USED-FOR"}, {"id": 174927, "from_id": 1091495, "to_id": 1091492, "type": "COREF"}, {"id": 174928, "from_id": 1091499, "to_id": 1091498, "type": "COREF"}, {"id": 174929, "from_id": 1091497, "to_id": 1091494, "type": "COREF"}, {"id": 174930, "from_id": 1091501, "to_id": 1091499, "type": "COREF"}, {"id": 174931, "from_id": 1091504, "to_id": 1091501, "type": "COREF"}, {"id": 174932, "from_id": 1091494, "to_id": 1091495, "type": "USED-FOR"}, {"id": 174933, "from_id": 1091497, "to_id": 1091498, "type": "USED-FOR"}, {"id": 174934, "from_id": 1091502, "to_id": 1091501, "type": "EVALUATE-FOR"}, {"id": 174935, "from_id": 1091502, "to_id": 1091503, "type": "USED-FOR"}, {"id": 174936, "from_id": 1091502, "to_id": 1091492, "type": "COREF"}, {"id": 174937, "from_id": 1091505, "to_id": 1091504, "type": "EVALUATE-FOR"}]}
{"id": "H01-1049", "text": "  Listen-Communicate-Show (LCS)  is a new paradigm for  human interaction with data sources  . We integrate a  spoken language understanding system  with  intelligent mobile agents  that mediate between  users  and  information sources  . We have built and will demonstrate an application of this approach called  LCS-Marine  . Using  LCS-Marine  , tactical personnel can converse with their logistics system to place a supply or information request. The request is passed to a  mobile, intelligent agent  for execution at the appropriate  database  .  Requestors  can also instruct the system to notify them when the status of a  request  changes or when a  request  is complete. We have demonstrated this capability in several field exercises with the Marines and are currently developing applications of this technology in  new domains  . ", "Comments": [], "entities": [{"id": 1091569, "label": "ENT", "start_offset": 2, "end_offset": 31}, {"id": 1091570, "label": "ENT", "start_offset": 56, "end_offset": 91}, {"id": 1091571, "label": "ENT", "start_offset": 111, "end_offset": 147}, {"id": 1091572, "label": "ENT", "start_offset": 155, "end_offset": 180}, {"id": 1091573, "label": "ENT", "start_offset": 216, "end_offset": 235}, {"id": 1091574, "label": "ENT", "start_offset": 297, "end_offset": 305}, {"id": 1091575, "label": "ENT", "start_offset": 314, "end_offset": 324}, {"id": 1091576, "label": "ENT", "start_offset": 335, "end_offset": 345}, {"id": 1091577, "label": "ENT", "start_offset": 479, "end_offset": 504}, {"id": 1091578, "label": "ENT", "start_offset": 587, "end_offset": 593}, {"id": 1091579, "label": "ENT", "start_offset": 827, "end_offset": 838}], "relations": [{"id": 174991, "from_id": 1091572, "to_id": 1091571, "type": "PART-OF"}, {"id": 174992, "from_id": 1091569, "to_id": 1091570, "type": "USED-FOR"}, {"id": 174993, "from_id": 1091576, "to_id": 1091575, "type": "COREF"}, {"id": 174994, "from_id": 1091578, "to_id": 1091576, "type": "COREF"}, {"id": 174995, "from_id": 1091574, "to_id": 1091571, "type": "COREF"}, {"id": 174996, "from_id": 1091574, "to_id": 1091575, "type": "USED-FOR"}]}
{"id": "IJCAI_1995_190_abs", "text": "We propose a process model for hierarchical perceptual sound organization, which recognizes perceptual sounds included in incoming sound signals. We consider perceptual sound organization as a scene analysis problem in the auditory domain. Our model consists of multiple processing modules and a hypothesis network for quantitative integration of multiple sources of information. When input information for each processing module is available, the module rises to process it and asynchronously writes output information to the hypothesis network. On the hypothesis network, individual information is integrated and an optimal internal model of perceptual sounds is automatically constructed. Based on the model, a music scene analysis system has been developed for acoustic signals of ensemble music, which recognizes rhythm, chords, and source-separated musical notes. Experimental results show that our method has permitted autonomous, stable and effective information integration to construct the internal model of hierarchical perceptual sounds. ", "Comments": [], "entities": [{"id": 1091580, "label": "ENT", "start_offset": 13, "end_offset": 26}, {"id": 1091581, "label": "ENT", "start_offset": 31, "end_offset": 73}, {"id": 1091582, "label": "ENT", "start_offset": 92, "end_offset": 109}, {"id": 1091583, "label": "ENT", "start_offset": 122, "end_offset": 144}, {"id": 1091584, "label": "ENT", "start_offset": 158, "end_offset": 187}, {"id": 1091585, "label": "ENT", "start_offset": 193, "end_offset": 215}, {"id": 1091586, "label": "ENT", "start_offset": 223, "end_offset": 238}, {"id": 1091587, "label": "ENT", "start_offset": 244, "end_offset": 249}, {"id": 1091588, "label": "ENT", "start_offset": 271, "end_offset": 289}, {"id": 1091589, "label": "ENT", "start_offset": 296, "end_offset": 314}, {"id": 1091590, "label": "ENT", "start_offset": 412, "end_offset": 429}, {"id": 1091591, "label": "ENT", "start_offset": 448, "end_offset": 454}, {"id": 1091592, "label": "ENT", "start_offset": 527, "end_offset": 545}, {"id": 1091593, "label": "ENT", "start_offset": 554, "end_offset": 572}, {"id": 1091594, "label": "ENT", "start_offset": 626, "end_offset": 640}, {"id": 1091595, "label": "ENT", "start_offset": 644, "end_offset": 661}, {"id": 1091596, "label": "ENT", "start_offset": 705, "end_offset": 710}, {"id": 1091597, "label": "ENT", "start_offset": 714, "end_offset": 741}, {"id": 1091598, "label": "ENT", "start_offset": 765, "end_offset": 799}, {"id": 1091599, "label": "ENT", "start_offset": 818, "end_offset": 824}, {"id": 1091600, "label": "ENT", "start_offset": 826, "end_offset": 832}, {"id": 1091601, "label": "ENT", "start_offset": 838, "end_offset": 868}, {"id": 1091602, "label": "ENT", "start_offset": 905, "end_offset": 911}, {"id": 1091603, "label": "ENT", "start_offset": 959, "end_offset": 982}, {"id": 1091604, "label": "ENT", "start_offset": 1000, "end_offset": 1014}, {"id": 1091605, "label": "ENT", "start_offset": 1018, "end_offset": 1048}], "relations": [{"id": 174997, "from_id": 1091580, "to_id": 1091581, "type": "USED-FOR"}, {"id": 174998, "from_id": 1091582, "to_id": 1091583, "type": "PART-OF"}, {"id": 174999, "from_id": 1091585, "to_id": 1091584, "type": "USED-FOR"}, {"id": 175000, "from_id": 1091581, "to_id": 1091584, "type": "HYPONYM-OF"}, {"id": 175001, "from_id": 1091588, "to_id": 1091589, "type": "CONJUNCTION"}, {"id": 175002, "from_id": 1091588, "to_id": 1091587, "type": "PART-OF"}, {"id": 175003, "from_id": 1091590, "to_id": 1091588, "type": "COREF"}, {"id": 175004, "from_id": 1091592, "to_id": 1091589, "type": "COREF"}, {"id": 175005, "from_id": 1091593, "to_id": 1091592, "type": "COREF"}, {"id": 175006, "from_id": 1091596, "to_id": 1091594, "type": "COREF"}, {"id": 175007, "from_id": 1091600, "to_id": 1091601, "type": "CONJUNCTION"}, {"id": 175008, "from_id": 1091597, "to_id": 1091599, "type": "USED-FOR"}, {"id": 175009, "from_id": 1091594, "to_id": 1091593, "type": "PART-OF"}, {"id": 175010, "from_id": 1091586, "to_id": 1091585, "type": "FEATURE-OF"}, {"id": 175011, "from_id": 1091589, "to_id": 1091587, "type": "PART-OF"}, {"id": 175012, "from_id": 1091590, "to_id": 1091591, "type": "COREF"}, {"id": 175013, "from_id": 1091594, "to_id": 1091595, "type": "USED-FOR"}, {"id": 175014, "from_id": 1091597, "to_id": 1091598, "type": "USED-FOR"}, {"id": 175015, "from_id": 1091599, "to_id": 1091600, "type": "CONJUNCTION"}, {"id": 175016, "from_id": 1091597, "to_id": 1091600, "type": "USED-FOR"}, {"id": 175017, "from_id": 1091597, "to_id": 1091601, "type": "USED-FOR"}, {"id": 175018, "from_id": 1091604, "to_id": 1091594, "type": "COREF"}, {"id": 175019, "from_id": 1091604, "to_id": 1091605, "type": "USED-FOR"}, {"id": 175020, "from_id": 1091603, "to_id": 1091602, "type": "FEATURE-OF"}, {"id": 175021, "from_id": 1091603, "to_id": 1091604, "type": "USED-FOR"}, {"id": 175022, "from_id": 1091602, "to_id": 1091587, "type": "COREF"}, {"id": 175023, "from_id": 1091587, "to_id": 1091580, "type": "COREF"}]}
{"id": "E87-1037", "text": " Currently several  grammatical formalisms  converge towards being declarative and towards utilizing  context-free phrase-structure grammar  as a backbone, e.g.  LFG  and  PATR-II . Typically the processing of these formalisms is organized within a  chart-parsing framework . The declarative character of the  formalisms  makes it important to decide upon an overall  optimal control strategy  on the part of the processor. In particular, this brings the  rule-invocation strategy  into critical focus: to gain maximal  processing efficiency , one has to determine the best way of putting the  rules  to use. The aim of this paper is to provide a survey and a practical comparison of fundamental  rule-invocation strategies  within  context-free chart parsing . ", "Comments": [], "entities": [{"id": 1091644, "label": "ENT", "start_offset": 20, "end_offset": 42}, {"id": 1091645, "label": "ENT", "start_offset": 102, "end_offset": 139}, {"id": 1091646, "label": "ENT", "start_offset": 162, "end_offset": 165}, {"id": 1091647, "label": "ENT", "start_offset": 172, "end_offset": 179}, {"id": 1091648, "label": "ENT", "start_offset": 216, "end_offset": 226}, {"id": 1091649, "label": "ENT", "start_offset": 250, "end_offset": 273}, {"id": 1091650, "label": "ENT", "start_offset": 310, "end_offset": 320}, {"id": 1091651, "label": "ENT", "start_offset": 368, "end_offset": 392}, {"id": 1091652, "label": "ENT", "start_offset": 456, "end_offset": 480}, {"id": 1091653, "label": "ENT", "start_offset": 594, "end_offset": 599}, {"id": 1091654, "label": "ENT", "start_offset": 697, "end_offset": 723}, {"id": 1091655, "label": "ENT", "start_offset": 733, "end_offset": 759}], "relations": [{"id": 175050, "from_id": 1091645, "to_id": 1091644, "type": "USED-FOR"}, {"id": 175051, "from_id": 1091654, "to_id": 1091655, "type": "PART-OF"}, {"id": 175052, "from_id": 1091646, "to_id": 1091647, "type": "CONJUNCTION"}, {"id": 175053, "from_id": 1091646, "to_id": 1091644, "type": "HYPONYM-OF"}, {"id": 175054, "from_id": 1091647, "to_id": 1091644, "type": "HYPONYM-OF"}, {"id": 175055, "from_id": 1091648, "to_id": 1091644, "type": "COREF"}, {"id": 175056, "from_id": 1091650, "to_id": 1091648, "type": "COREF"}, {"id": 175057, "from_id": 1091654, "to_id": 1091652, "type": "COREF"}, {"id": 175058, "from_id": 1091655, "to_id": 1091649, "type": "COREF"}, {"id": 175059, "from_id": 1091649, "to_id": 1091648, "type": "FEATURE-OF"}]}
{"id": "H05-1095", "text": " This paper presents a  phrase-based statistical machine translation method  , based on  non-contiguous phrases  , i.e.  phrases  with gaps. A method for producing such  phrases  from a  word-aligned corpora  is proposed. A  statistical translation model  is also presented that deals such  phrases  , as well as a  training method  based on the maximization of  translation accuracy  , as measured with the  NIST evaluation metric  .  Translations  are produced by means of a  beam-search decoder  . Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the  training data  . ", "Comments": [], "entities": [{"id": 1091670, "label": "ENT", "start_offset": 24, "end_offset": 75}, {"id": 1091671, "label": "ENT", "start_offset": 89, "end_offset": 111}, {"id": 1091672, "label": "ENT", "start_offset": 143, "end_offset": 149}, {"id": 1091673, "label": "ENT", "start_offset": 170, "end_offset": 177}, {"id": 1091674, "label": "ENT", "start_offset": 187, "end_offset": 207}, {"id": 1091675, "label": "ENT", "start_offset": 225, "end_offset": 254}, {"id": 1091676, "label": "ENT", "start_offset": 291, "end_offset": 298}, {"id": 1091677, "label": "ENT", "start_offset": 316, "end_offset": 331}, {"id": 1091678, "label": "ENT", "start_offset": 346, "end_offset": 383}, {"id": 1091679, "label": "ENT", "start_offset": 409, "end_offset": 431}, {"id": 1091680, "label": "ENT", "start_offset": 436, "end_offset": 448}, {"id": 1091681, "label": "ENT", "start_offset": 478, "end_offset": 497}, {"id": 1091682, "label": "ENT", "start_offset": 571, "end_offset": 577}], "relations": [{"id": 175071, "from_id": 1091671, "to_id": 1091670, "type": "USED-FOR"}, {"id": 175072, "from_id": 1091675, "to_id": 1091676, "type": "USED-FOR"}, {"id": 175073, "from_id": 1091681, "to_id": 1091680, "type": "USED-FOR"}, {"id": 175074, "from_id": 1091673, "to_id": 1091671, "type": "COREF"}, {"id": 175075, "from_id": 1091672, "to_id": 1091673, "type": "USED-FOR"}, {"id": 175076, "from_id": 1091674, "to_id": 1091672, "type": "EVALUATE-FOR"}, {"id": 175077, "from_id": 1091676, "to_id": 1091673, "type": "COREF"}, {"id": 175078, "from_id": 1091679, "to_id": 1091675, "type": "EVALUATE-FOR"}, {"id": 175079, "from_id": 1091682, "to_id": 1091670, "type": "COREF"}, {"id": 175080, "from_id": 1091675, "to_id": 1091670, "type": "COREF"}, {"id": 175081, "from_id": 1091678, "to_id": 1091677, "type": "USED-FOR"}]}
{"id": "C90-1013", "text": "   This article introduces a  bidirectional grammar generation system  called  feature structure-directed generation  , developed for a  dialogue translation system  . The system utilizes  typed feature structures  to control the  top-down derivation  in a declarative way. This  generation system  also uses  disjunctive feature structures  to reduce the number of copies of the  derivation tree  . The  grammar  for this  generator  is designed to properly generate the  speaker's intention  in a  telephone dialogue  . ", "Comments": [], "entities": [{"id": 1091683, "label": "ENT", "start_offset": 30, "end_offset": 69}, {"id": 1091684, "label": "ENT", "start_offset": 79, "end_offset": 116}, {"id": 1091685, "label": "ENT", "start_offset": 137, "end_offset": 164}, {"id": 1091686, "label": "ENT", "start_offset": 172, "end_offset": 178}, {"id": 1091687, "label": "ENT", "start_offset": 189, "end_offset": 213}, {"id": 1091688, "label": "ENT", "start_offset": 231, "end_offset": 250}, {"id": 1091689, "label": "ENT", "start_offset": 280, "end_offset": 297}, {"id": 1091690, "label": "ENT", "start_offset": 310, "end_offset": 340}, {"id": 1091691, "label": "ENT", "start_offset": 381, "end_offset": 396}, {"id": 1091692, "label": "ENT", "start_offset": 405, "end_offset": 412}, {"id": 1091693, "label": "ENT", "start_offset": 424, "end_offset": 433}, {"id": 1091694, "label": "ENT", "start_offset": 473, "end_offset": 492}, {"id": 1091695, "label": "ENT", "start_offset": 500, "end_offset": 518}], "relations": [{"id": 175082, "from_id": 1091684, "to_id": 1091685, "type": "USED-FOR"}, {"id": 175083, "from_id": 1091687, "to_id": 1091688, "type": "USED-FOR"}, {"id": 175084, "from_id": 1091690, "to_id": 1091689, "type": "USED-FOR"}, {"id": 175085, "from_id": 1091692, "to_id": 1091693, "type": "USED-FOR"}, {"id": 175086, "from_id": 1091684, "to_id": 1091683, "type": "HYPONYM-OF"}, {"id": 175087, "from_id": 1091683, "to_id": 1091685, "type": "USED-FOR"}, {"id": 175088, "from_id": 1091686, "to_id": 1091684, "type": "COREF"}, {"id": 175089, "from_id": 1091687, "to_id": 1091686, "type": "USED-FOR"}, {"id": 175090, "from_id": 1091689, "to_id": 1091686, "type": "COREF"}, {"id": 175091, "from_id": 1091693, "to_id": 1091689, "type": "COREF"}, {"id": 175092, "from_id": 1091695, "to_id": 1091694, "type": "FEATURE-OF"}, {"id": 175093, "from_id": 1091692, "to_id": 1091694, "type": "USED-FOR"}, {"id": 175094, "from_id": 1091690, "to_id": 1091691, "type": "USED-FOR"}]}
{"id": "ICCV_2009_47_abs", "text": "In this work, we present a technique for robust estimation , which by explicitly incorporating the inherent uncertainty of the estimation procedure, results in a more efficient robust estimation algorithm. In addition, we build on recent work in randomized model verification, and use this to characterize the 'non-randomness' of a solution. The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques, while requiring no prior information to guide the sampling process. In particular, our algorithm requires, on average, 3-10 times fewer samples than standard RANSAC, which is in close agreement with theoretical predictions. The efficiency of the algorithm is demonstrated on a selection of geometric estimation problems .", "Comments": [], "entities": [{"id": 1091739, "label": "ENT", "start_offset": 27, "end_offset": 36}, {"id": 1091740, "label": "ENT", "start_offset": 41, "end_offset": 58}, {"id": 1091741, "label": "ENT", "start_offset": 99, "end_offset": 147}, {"id": 1091742, "label": "ENT", "start_offset": 167, "end_offset": 204}, {"id": 1091743, "label": "ENT", "start_offset": 246, "end_offset": 275}, {"id": 1091744, "label": "ENT", "start_offset": 285, "end_offset": 289}, {"id": 1091745, "label": "ENT", "start_offset": 371, "end_offset": 381}, {"id": 1091746, "label": "ENT", "start_offset": 395, "end_offset": 422}, {"id": 1091747, "label": "ENT", "start_offset": 474, "end_offset": 491}, {"id": 1091748, "label": "ENT", "start_offset": 512, "end_offset": 529}, {"id": 1091749, "label": "ENT", "start_offset": 543, "end_offset": 559}, {"id": 1091750, "label": "ENT", "start_offset": 580, "end_offset": 589}, {"id": 1091751, "label": "ENT", "start_offset": 651, "end_offset": 657}, {"id": 1091752, "label": "ENT", "start_offset": 692, "end_offset": 715}, {"id": 1091753, "label": "ENT", "start_offset": 739, "end_offset": 748}, {"id": 1091754, "label": "ENT", "start_offset": 783, "end_offset": 812}], "relations": [{"id": 175127, "from_id": 1091739, "to_id": 1091740, "type": "USED-FOR"}, {"id": 175128, "from_id": 1091741, "to_id": 1091739, "type": "USED-FOR"}, {"id": 175129, "from_id": 1091744, "to_id": 1091743, "type": "COREF"}, {"id": 175130, "from_id": 1091745, "to_id": 1091746, "type": "USED-FOR"}, {"id": 175131, "from_id": 1091739, "to_id": 1091742, "type": "USED-FOR"}, {"id": 175132, "from_id": 1091742, "to_id": 1091746, "type": "COREF"}, {"id": 175133, "from_id": 1091747, "to_id": 1091746, "type": "COMPARE"}, {"id": 175134, "from_id": 1091750, "to_id": 1091746, "type": "COREF"}, {"id": 175135, "from_id": 1091751, "to_id": 1091747, "type": "COREF"}, {"id": 175136, "from_id": 1091750, "to_id": 1091751, "type": "COMPARE"}, {"id": 175137, "from_id": 1091753, "to_id": 1091750, "type": "COREF"}, {"id": 175138, "from_id": 1091754, "to_id": 1091753, "type": "EVALUATE-FOR"}]}
{"id": "CVPR_2004_10_abs", "text": "Image composition (or mosaicing) has attracted a growing attention in recent years as one of the main elements in video analysis and representation. In this paper we deal with the problem of global alignment and super-resolution. We also propose to evaluate the quality of the resulting mosaic by measuring the amount of blurring. Global registration is achieved by combining a graph-based technique \u2013 that exploits the topological structure of the sequence induced by the spatial overlap \u2013 with a bundle adjustment which uses only the homographies computed in the previous steps. Experimental comparison with other techniques shows the effectiveness of our approach.", "Comments": [], "entities": [{"id": 1091766, "label": "ENT", "start_offset": 0, "end_offset": 32}, {"id": 1091767, "label": "ENT", "start_offset": 114, "end_offset": 147}, {"id": 1091768, "label": "ENT", "start_offset": 191, "end_offset": 207}, {"id": 1091769, "label": "ENT", "start_offset": 212, "end_offset": 228}, {"id": 1091770, "label": "ENT", "start_offset": 287, "end_offset": 293}, {"id": 1091771, "label": "ENT", "start_offset": 311, "end_offset": 329}, {"id": 1091772, "label": "ENT", "start_offset": 331, "end_offset": 350}, {"id": 1091773, "label": "ENT", "start_offset": 378, "end_offset": 399}, {"id": 1091774, "label": "ENT", "start_offset": 420, "end_offset": 441}, {"id": 1091775, "label": "ENT", "start_offset": 473, "end_offset": 488}, {"id": 1091776, "label": "ENT", "start_offset": 498, "end_offset": 515}, {"id": 1091777, "label": "ENT", "start_offset": 536, "end_offset": 548}, {"id": 1091778, "label": "ENT", "start_offset": 616, "end_offset": 626}, {"id": 1091779, "label": "ENT", "start_offset": 658, "end_offset": 666}], "relations": [{"id": 175148, "from_id": 1091768, "to_id": 1091769, "type": "CONJUNCTION"}, {"id": 175149, "from_id": 1091771, "to_id": 1091770, "type": "EVALUATE-FOR"}, {"id": 175150, "from_id": 1091773, "to_id": 1091776, "type": "CONJUNCTION"}, {"id": 175151, "from_id": 1091773, "to_id": 1091772, "type": "USED-FOR"}, {"id": 175152, "from_id": 1091776, "to_id": 1091772, "type": "USED-FOR"}, {"id": 175153, "from_id": 1091773, "to_id": 1091774, "type": "USED-FOR"}, {"id": 175154, "from_id": 1091777, "to_id": 1091776, "type": "USED-FOR"}, {"id": 175155, "from_id": 1091779, "to_id": 1091773, "type": "COREF"}, {"id": 175156, "from_id": 1091779, "to_id": 1091778, "type": "COMPARE"}, {"id": 175157, "from_id": 1091766, "to_id": 1091767, "type": "PART-OF"}]}
{"id": "P03-1005", "text": " This paper proposes the  Hierarchical Directed Acyclic Graph (HDAG) Kernel  for  structured natural language data  . The  HDAG Kernel  directly accepts several levels of both  chunks  and their  relations  , and then efficiently computes the  weighed sum  of the number of common  attribute sequences  of the  HDAGs  . We applied the proposed method to  question classification  and  sentence alignment tasks  to evaluate its performance as a  similarity measure  and a  kernel function  . The results of the experiments demonstrate that the  HDAG Kernel  is superior to other  kernel functions  and  baseline methods  . ", "Comments": [], "entities": [{"id": 1091876, "label": "ENT", "start_offset": 26, "end_offset": 75}, {"id": 1091877, "label": "ENT", "start_offset": 82, "end_offset": 114}, {"id": 1091878, "label": "ENT", "start_offset": 123, "end_offset": 134}, {"id": 1091879, "label": "ENT", "start_offset": 311, "end_offset": 316}, {"id": 1091880, "label": "ENT", "start_offset": 344, "end_offset": 350}, {"id": 1091881, "label": "ENT", "start_offset": 355, "end_offset": 409}, {"id": 1091882, "label": "ENT", "start_offset": 445, "end_offset": 463}, {"id": 1091883, "label": "ENT", "start_offset": 472, "end_offset": 487}, {"id": 1091884, "label": "ENT", "start_offset": 544, "end_offset": 555}, {"id": 1091885, "label": "ENT", "start_offset": 579, "end_offset": 595}, {"id": 1091886, "label": "ENT", "start_offset": 602, "end_offset": 618}], "relations": [{"id": 175234, "from_id": 1091876, "to_id": 1091877, "type": "USED-FOR"}, {"id": 175235, "from_id": 1091884, "to_id": 1091885, "type": "COMPARE"}, {"id": 175236, "from_id": 1091878, "to_id": 1091876, "type": "COREF"}, {"id": 175237, "from_id": 1091878, "to_id": 1091879, "type": "COREF"}, {"id": 175238, "from_id": 1091879, "to_id": 1091880, "type": "COREF"}, {"id": 175239, "from_id": 1091880, "to_id": 1091881, "type": "USED-FOR"}, {"id": 175240, "from_id": 1091880, "to_id": 1091884, "type": "COREF"}, {"id": 175241, "from_id": 1091884, "to_id": 1091886, "type": "COMPARE"}, {"id": 175242, "from_id": 1091885, "to_id": 1091886, "type": "CONJUNCTION"}, {"id": 175243, "from_id": 1091882, "to_id": 1091880, "type": "EVALUATE-FOR"}, {"id": 175244, "from_id": 1091883, "to_id": 1091880, "type": "EVALUATE-FOR"}, {"id": 175245, "from_id": 1091882, "to_id": 1091883, "type": "CONJUNCTION"}]}
{"id": "E06-1004", "text": "   In this paper we study a set of problems that are of considerable importance to  Statistical Machine Translation (SMT)  but which have not been addressed satisfactorily by the  SMT research community  . Over the last decade, a variety of  SMT algorithms  have been built and empirically tested whereas little is known about the  computational complexity  of some of the fundamental problems of  SMT  . Our work aims at providing useful insights into the the  computational complexity  of those problems. We prove that while  IBM Models 1-2  are conceptually and computationally simple, computations involving the higher (and more useful)  models  are  hard  . Since it is unlikely that there exists a  polynomial time solution  for any of these  hard problems  (unless  P = NP  and  P#P = P  ), our results highlight and justify the need for developing  polynomial time approximations  for these computations. We also discuss some practical ways of dealing with  complexity  . ", "Comments": [], "entities": [{"id": 1091961, "label": "ENT", "start_offset": 84, "end_offset": 121}, {"id": 1091962, "label": "ENT", "start_offset": 242, "end_offset": 256}, {"id": 1091963, "label": "ENT", "start_offset": 332, "end_offset": 356}, {"id": 1091964, "label": "ENT", "start_offset": 385, "end_offset": 393}, {"id": 1091965, "label": "ENT", "start_offset": 398, "end_offset": 401}, {"id": 1091966, "label": "ENT", "start_offset": 462, "end_offset": 486}, {"id": 1091967, "label": "ENT", "start_offset": 497, "end_offset": 505}, {"id": 1091968, "label": "ENT", "start_offset": 528, "end_offset": 542}, {"id": 1091969, "label": "ENT", "start_offset": 589, "end_offset": 601}, {"id": 1091970, "label": "ENT", "start_offset": 642, "end_offset": 648}, {"id": 1091971, "label": "ENT", "start_offset": 705, "end_offset": 729}, {"id": 1091972, "label": "ENT", "start_offset": 749, "end_offset": 762}, {"id": 1091973, "label": "ENT", "start_offset": 857, "end_offset": 887}, {"id": 1091974, "label": "ENT", "start_offset": 899, "end_offset": 911}, {"id": 1091975, "label": "ENT", "start_offset": 966, "end_offset": 976}], "relations": [{"id": 175301, "from_id": 1091971, "to_id": 1091972, "type": "USED-FOR"}, {"id": 175302, "from_id": 1091967, "to_id": 1091964, "type": "COREF"}, {"id": 175303, "from_id": 1091966, "to_id": 1091967, "type": "EVALUATE-FOR"}, {"id": 175304, "from_id": 1091968, "to_id": 1091970, "type": "COMPARE"}, {"id": 175305, "from_id": 1091972, "to_id": 1091967, "type": "COREF"}, {"id": 175306, "from_id": 1091965, "to_id": 1091961, "type": "COREF"}, {"id": 175307, "from_id": 1091974, "to_id": 1091969, "type": "COREF"}, {"id": 175308, "from_id": 1091973, "to_id": 1091974, "type": "USED-FOR"}, {"id": 175309, "from_id": 1091963, "to_id": 1091964, "type": "EVALUATE-FOR"}, {"id": 175310, "from_id": 1091964, "to_id": 1091965, "type": "PART-OF"}]}
{"id": "IJCAI_2016_420_abs", "text": "In cross-domain learning, there is a more challenging problem that the domain divergence involves more than one dominant factors, e.g., different viewpoints , various resolutions and changing illuminations. Fortunately, an intermediate domain could often be found to build a bridge across them to facilitate the learning problem. In this paper, we propose a Coupled Marginalized Denoising Auto-encoders framework to address the cross-domain problem. Specifically, we design two marginalized denoising auto-encoders, one for the target and the other for source as well as the intermediate one. To better couple the two denoising auto-encoders learning, we incorporate a feature mapping, which tends to transfer knowledge between the intermediate domain and the target one. Furthermore, the maximum margin criterion, e.g., intra-class com-pactness and inter-class penalty, on the output layer is imposed to seek more discriminative features across different domains. Extensive experiments on two tasks have demonstrated the superiority of our method over the state-of-the-art methods.", "Comments": [], "entities": [{"id": 1092007, "label": "ENT", "start_offset": 3, "end_offset": 24}, {"id": 1092008, "label": "ENT", "start_offset": 71, "end_offset": 88}, {"id": 1092009, "label": "ENT", "start_offset": 112, "end_offset": 128}, {"id": 1092010, "label": "ENT", "start_offset": 146, "end_offset": 156}, {"id": 1092011, "label": "ENT", "start_offset": 167, "end_offset": 178}, {"id": 1092012, "label": "ENT", "start_offset": 192, "end_offset": 205}, {"id": 1092013, "label": "ENT", "start_offset": 223, "end_offset": 242}, {"id": 1092014, "label": "ENT", "start_offset": 312, "end_offset": 328}, {"id": 1092015, "label": "ENT", "start_offset": 358, "end_offset": 412}, {"id": 1092016, "label": "ENT", "start_offset": 428, "end_offset": 448}, {"id": 1092017, "label": "ENT", "start_offset": 478, "end_offset": 514}, {"id": 1092018, "label": "ENT", "start_offset": 516, "end_offset": 519}, {"id": 1092019, "label": "ENT", "start_offset": 543, "end_offset": 548}, {"id": 1092020, "label": "ENT", "start_offset": 618, "end_offset": 650}, {"id": 1092021, "label": "ENT", "start_offset": 669, "end_offset": 684}, {"id": 1092022, "label": "ENT", "start_offset": 732, "end_offset": 751}, {"id": 1092023, "label": "ENT", "start_offset": 789, "end_offset": 813}, {"id": 1092024, "label": "ENT", "start_offset": 821, "end_offset": 845}, {"id": 1092025, "label": "ENT", "start_offset": 850, "end_offset": 869}, {"id": 1092026, "label": "ENT", "start_offset": 915, "end_offset": 938}, {"id": 1092027, "label": "ENT", "start_offset": 994, "end_offset": 999}, {"id": 1092028, "label": "ENT", "start_offset": 1041, "end_offset": 1047}, {"id": 1092029, "label": "ENT", "start_offset": 1057, "end_offset": 1081}], "relations": [{"id": 175330, "from_id": 1092010, "to_id": 1092009, "type": "HYPONYM-OF"}, {"id": 175331, "from_id": 1092011, "to_id": 1092009, "type": "HYPONYM-OF"}, {"id": 175332, "from_id": 1092009, "to_id": 1092008, "type": "PART-OF"}, {"id": 175333, "from_id": 1092010, "to_id": 1092011, "type": "CONJUNCTION"}, {"id": 175334, "from_id": 1092011, "to_id": 1092012, "type": "CONJUNCTION"}, {"id": 175335, "from_id": 1092014, "to_id": 1092007, "type": "COREF"}, {"id": 175336, "from_id": 1092013, "to_id": 1092014, "type": "USED-FOR"}, {"id": 175337, "from_id": 1092016, "to_id": 1092014, "type": "COREF"}, {"id": 175338, "from_id": 1092015, "to_id": 1092016, "type": "USED-FOR"}, {"id": 175339, "from_id": 1092018, "to_id": 1092017, "type": "HYPONYM-OF"}, {"id": 175340, "from_id": 1092019, "to_id": 1092017, "type": "HYPONYM-OF"}, {"id": 175341, "from_id": 1092021, "to_id": 1092020, "type": "PART-OF"}, {"id": 175342, "from_id": 1092021, "to_id": 1092022, "type": "USED-FOR"}, {"id": 175343, "from_id": 1092024, "to_id": 1092023, "type": "HYPONYM-OF"}, {"id": 175344, "from_id": 1092025, "to_id": 1092023, "type": "HYPONYM-OF"}, {"id": 175345, "from_id": 1092024, "to_id": 1092025, "type": "CONJUNCTION"}, {"id": 175346, "from_id": 1092028, "to_id": 1092029, "type": "COMPARE"}, {"id": 175347, "from_id": 1092028, "to_id": 1092015, "type": "COREF"}, {"id": 175348, "from_id": 1092027, "to_id": 1092028, "type": "EVALUATE-FOR"}, {"id": 175349, "from_id": 1092018, "to_id": 1092019, "type": "CONJUNCTION"}]}
{"id": "H05-1041", "text": " We present a  practically unsupervised learning method  to produce  single-snippet answers  to  definition questions  in  question answering systems  that supplement  Web search engines . The method exploits  on-line encyclopedias and dictionaries  to generate automatically an arbitrarily large number of  positive and negative definition examples , which are then used to train an  svm  to separate the two classes. We show experimentally that the proposed method is viable, that it outperforms the alternative of training the  system  on  questions  and  news articles from trec , and that it helps the  search engine  handle  definition questions  significantly better. ", "Comments": [], "entities": [{"id": 1092139, "label": "ENT", "start_offset": 27, "end_offset": 55}, {"id": 1092140, "label": "ENT", "start_offset": 69, "end_offset": 91}, {"id": 1092141, "label": "ENT", "start_offset": 123, "end_offset": 149}, {"id": 1092142, "label": "ENT", "start_offset": 168, "end_offset": 186}, {"id": 1092143, "label": "ENT", "start_offset": 193, "end_offset": 199}, {"id": 1092144, "label": "ENT", "start_offset": 210, "end_offset": 248}, {"id": 1092145, "label": "ENT", "start_offset": 308, "end_offset": 349}, {"id": 1092146, "label": "ENT", "start_offset": 385, "end_offset": 388}, {"id": 1092147, "label": "ENT", "start_offset": 460, "end_offset": 466}, {"id": 1092148, "label": "ENT", "start_offset": 483, "end_offset": 485}, {"id": 1092149, "label": "ENT", "start_offset": 502, "end_offset": 513}, {"id": 1092150, "label": "ENT", "start_offset": 531, "end_offset": 537}, {"id": 1092151, "label": "ENT", "start_offset": 559, "end_offset": 572}, {"id": 1092152, "label": "ENT", "start_offset": 578, "end_offset": 582}, {"id": 1092153, "label": "ENT", "start_offset": 594, "end_offset": 596}, {"id": 1092154, "label": "ENT", "start_offset": 608, "end_offset": 621}], "relations": [{"id": 175441, "from_id": 1092144, "to_id": 1092145, "type": "USED-FOR"}, {"id": 175442, "from_id": 1092145, "to_id": 1092146, "type": "USED-FOR"}, {"id": 175443, "from_id": 1092147, "to_id": 1092143, "type": "COREF"}, {"id": 175444, "from_id": 1092139, "to_id": 1092143, "type": "COREF"}, {"id": 175445, "from_id": 1092148, "to_id": 1092147, "type": "COREF"}, {"id": 175446, "from_id": 1092148, "to_id": 1092149, "type": "COMPARE"}, {"id": 175447, "from_id": 1092154, "to_id": 1092142, "type": "COREF"}, {"id": 175448, "from_id": 1092153, "to_id": 1092147, "type": "COREF"}, {"id": 175449, "from_id": 1092153, "to_id": 1092154, "type": "USED-FOR"}, {"id": 175450, "from_id": 1092139, "to_id": 1092140, "type": "USED-FOR"}, {"id": 175451, "from_id": 1092141, "to_id": 1092142, "type": "USED-FOR"}, {"id": 175452, "from_id": 1092150, "to_id": 1092141, "type": "COREF"}, {"id": 175453, "from_id": 1092143, "to_id": 1092144, "type": "USED-FOR"}, {"id": 175454, "from_id": 1092151, "to_id": 1092152, "type": "PART-OF"}, {"id": 175455, "from_id": 1092151, "to_id": 1092150, "type": "USED-FOR"}]}
{"id": "INTERSPEECH_2006_31_abs", "text": "Within the EU Network of Excellence PASCAL, a challenge was organized to design a statistical machine learning algorithm that segments words into the smallest meaning-bearing units of language , morphemes. Ideally, these are basic vocabulary units suitable for different tasks, such as speech and text understanding, machine translation, information retrieval, and statistical language modeling. Twelve research groups participated in the challenge and had submitted segmentation results obtained by their algorithms. In this paper, we evaluate the application of these segmen-tation algorithms to large vocabulary speech recognition using statistical n-gram language models based on the proposed word segments instead of entire words. Experiments were done for two ag-glutinative and morphologically rich languages: Finnish and Turk-ish. We also investigate combining various segmentations to improve the performance of the recognizer.", "Comments": [], "entities": [{"id": 1092186, "label": "ENT", "start_offset": 82, "end_offset": 120}, {"id": 1092187, "label": "ENT", "start_offset": 150, "end_offset": 192}, {"id": 1092188, "label": "ENT", "start_offset": 195, "end_offset": 204}, {"id": 1092189, "label": "ENT", "start_offset": 215, "end_offset": 220}, {"id": 1092190, "label": "ENT", "start_offset": 271, "end_offset": 276}, {"id": 1092191, "label": "ENT", "start_offset": 286, "end_offset": 315}, {"id": 1092192, "label": "ENT", "start_offset": 317, "end_offset": 336}, {"id": 1092193, "label": "ENT", "start_offset": 338, "end_offset": 359}, {"id": 1092194, "label": "ENT", "start_offset": 365, "end_offset": 394}, {"id": 1092195, "label": "ENT", "start_offset": 570, "end_offset": 594}, {"id": 1092196, "label": "ENT", "start_offset": 598, "end_offset": 633}, {"id": 1092197, "label": "ENT", "start_offset": 640, "end_offset": 674}, {"id": 1092198, "label": "ENT", "start_offset": 766, "end_offset": 815}, {"id": 1092199, "label": "ENT", "start_offset": 817, "end_offset": 824}, {"id": 1092200, "label": "ENT", "start_offset": 829, "end_offset": 837}], "relations": [{"id": 175478, "from_id": 1092188, "to_id": 1092187, "type": "HYPONYM-OF"}, {"id": 175479, "from_id": 1092186, "to_id": 1092187, "type": "USED-FOR"}, {"id": 175480, "from_id": 1092199, "to_id": 1092200, "type": "CONJUNCTION"}, {"id": 175481, "from_id": 1092199, "to_id": 1092198, "type": "HYPONYM-OF"}, {"id": 175482, "from_id": 1092200, "to_id": 1092198, "type": "HYPONYM-OF"}, {"id": 175483, "from_id": 1092191, "to_id": 1092190, "type": "HYPONYM-OF"}, {"id": 175484, "from_id": 1092192, "to_id": 1092190, "type": "HYPONYM-OF"}, {"id": 175485, "from_id": 1092191, "to_id": 1092192, "type": "CONJUNCTION"}, {"id": 175486, "from_id": 1092193, "to_id": 1092190, "type": "HYPONYM-OF"}, {"id": 175487, "from_id": 1092192, "to_id": 1092193, "type": "CONJUNCTION"}, {"id": 175488, "from_id": 1092194, "to_id": 1092190, "type": "HYPONYM-OF"}, {"id": 175489, "from_id": 1092193, "to_id": 1092194, "type": "CONJUNCTION"}, {"id": 175490, "from_id": 1092195, "to_id": 1092196, "type": "USED-FOR"}, {"id": 175491, "from_id": 1092188, "to_id": 1092189, "type": "COREF"}, {"id": 175492, "from_id": 1092189, "to_id": 1092190, "type": "USED-FOR"}, {"id": 175493, "from_id": 1092197, "to_id": 1092195, "type": "EVALUATE-FOR"}]}
{"id": "INTERSPEECH_2006_21_abs", "text": "In this paper, we discuss language model adaptation methods given a word list and a raw corpus. In this situation, the general method is to segment the raw corpus automatically using a word list, correct the output sentences by hand, and build a model from the segmented corpus. In this sentence-by-sentence error correction method, however, the annotator encounters grammatically complicated positions and this results in a decrease of productivity. In this paper, we propose to concentrate on correcting the positions in which the words in the list appear by taking a word as a correction unit. This method allows us to avoid these problems and go directly to capturing the statistical behavior of specific words in the application. In the experiments, we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies. The results showed the advantages of our method.", "Comments": [], "entities": [{"id": 1092201, "label": "ENT", "start_offset": 26, "end_offset": 59}, {"id": 1092202, "label": "ENT", "start_offset": 68, "end_offset": 77}, {"id": 1092203, "label": "ENT", "start_offset": 84, "end_offset": 94}, {"id": 1092204, "label": "ENT", "start_offset": 127, "end_offset": 133}, {"id": 1092205, "label": "ENT", "start_offset": 152, "end_offset": 162}, {"id": 1092206, "label": "ENT", "start_offset": 185, "end_offset": 194}, {"id": 1092207, "label": "ENT", "start_offset": 246, "end_offset": 251}, {"id": 1092208, "label": "ENT", "start_offset": 261, "end_offset": 277}, {"id": 1092209, "label": "ENT", "start_offset": 287, "end_offset": 331}, {"id": 1092210, "label": "ENT", "start_offset": 602, "end_offset": 608}, {"id": 1092211, "label": "ENT", "start_offset": 776, "end_offset": 783}, {"id": 1092212, "label": "ENT", "start_offset": 788, "end_offset": 816}, {"id": 1092213, "label": "ENT", "start_offset": 834, "end_offset": 849}, {"id": 1092214, "label": "ENT", "start_offset": 859, "end_offset": 888}, {"id": 1092215, "label": "ENT", "start_offset": 931, "end_offset": 937}], "relations": [{"id": 175494, "from_id": 1092203, "to_id": 1092201, "type": "USED-FOR"}, {"id": 175495, "from_id": 1092202, "to_id": 1092201, "type": "USED-FOR"}, {"id": 175496, "from_id": 1092202, "to_id": 1092203, "type": "CONJUNCTION"}, {"id": 175497, "from_id": 1092206, "to_id": 1092204, "type": "USED-FOR"}, {"id": 175498, "from_id": 1092204, "to_id": 1092205, "type": "USED-FOR"}, {"id": 175499, "from_id": 1092208, "to_id": 1092207, "type": "USED-FOR"}, {"id": 175500, "from_id": 1092211, "to_id": 1092212, "type": "USED-FOR"}, {"id": 175501, "from_id": 1092214, "to_id": 1092213, "type": "EVALUATE-FOR"}, {"id": 175502, "from_id": 1092201, "to_id": 1092210, "type": "COREF"}, {"id": 175503, "from_id": 1092210, "to_id": 1092215, "type": "COREF"}]}
{"id": "W04-2703", "text": " This paper describes a new,  large scale discourse-level annotation  project - the  Penn Discourse TreeBank (PDTB) . We present an approach to annotating a level of  discourse structure  that is based on identifying  discourse connectives  and their  arguments . The  PDTB  is being built directly on top of the  Penn TreeBank  and  Propbank , thus supporting the extraction of useful  syntactic and semantic features  and providing a richer substrate for the development and evaluation of  practical algorithms . We provide a detailed preliminary analysis of  inter-annotator agreement  - both the  level of agreement  and the types of  inter-annotator variation . ", "Comments": [], "entities": [{"id": 1092260, "label": "ENT", "start_offset": 30, "end_offset": 68}, {"id": 1092261, "label": "ENT", "start_offset": 85, "end_offset": 115}, {"id": 1092262, "label": "ENT", "start_offset": 132, "end_offset": 140}, {"id": 1092263, "label": "ENT", "start_offset": 167, "end_offset": 186}, {"id": 1092264, "label": "ENT", "start_offset": 218, "end_offset": 239}, {"id": 1092265, "label": "ENT", "start_offset": 269, "end_offset": 273}, {"id": 1092266, "label": "ENT", "start_offset": 314, "end_offset": 327}, {"id": 1092267, "label": "ENT", "start_offset": 334, "end_offset": 342}, {"id": 1092268, "label": "ENT", "start_offset": 365, "end_offset": 418}, {"id": 1092269, "label": "ENT", "start_offset": 492, "end_offset": 512}, {"id": 1092270, "label": "ENT", "start_offset": 562, "end_offset": 587}, {"id": 1092271, "label": "ENT", "start_offset": 601, "end_offset": 619}, {"id": 1092272, "label": "ENT", "start_offset": 639, "end_offset": 664}], "relations": [{"id": 175539, "from_id": 1092261, "to_id": 1092260, "type": "COREF"}, {"id": 175540, "from_id": 1092265, "to_id": 1092261, "type": "COREF"}, {"id": 175541, "from_id": 1092266, "to_id": 1092267, "type": "CONJUNCTION"}, {"id": 175542, "from_id": 1092262, "to_id": 1092263, "type": "USED-FOR"}, {"id": 175543, "from_id": 1092266, "to_id": 1092265, "type": "USED-FOR"}, {"id": 175544, "from_id": 1092267, "to_id": 1092265, "type": "USED-FOR"}, {"id": 175545, "from_id": 1092264, "to_id": 1092262, "type": "USED-FOR"}, {"id": 175546, "from_id": 1092265, "to_id": 1092269, "type": "EVALUATE-FOR"}, {"id": 175547, "from_id": 1092265, "to_id": 1092268, "type": "USED-FOR"}, {"id": 175548, "from_id": 1092271, "to_id": 1092270, "type": "FEATURE-OF"}, {"id": 175549, "from_id": 1092272, "to_id": 1092270, "type": "FEATURE-OF"}, {"id": 175550, "from_id": 1092271, "to_id": 1092272, "type": "CONJUNCTION"}]}
{"id": "P05-2016", "text": " We present a  Czech-English statistical machine translation system  which performs  tree-to-tree translation  of  dependency structures  . The only  bilingual resource  required is a  sentence-aligned parallel corpus  . All other  resources  are  monolingual  . We also refer to an  evaluation method  and plan to compare our  system's output  with a  benchmark system  . ", "Comments": [], "entities": [{"id": 1092285, "label": "ENT", "start_offset": 15, "end_offset": 67}, {"id": 1092286, "label": "ENT", "start_offset": 85, "end_offset": 136}, {"id": 1092287, "label": "ENT", "start_offset": 150, "end_offset": 168}, {"id": 1092288, "label": "ENT", "start_offset": 185, "end_offset": 217}, {"id": 1092289, "label": "ENT", "start_offset": 328, "end_offset": 334}, {"id": 1092290, "label": "ENT", "start_offset": 353, "end_offset": 369}], "relations": [{"id": 175564, "from_id": 1092285, "to_id": 1092286, "type": "USED-FOR"}, {"id": 175565, "from_id": 1092288, "to_id": 1092287, "type": "USED-FOR"}, {"id": 175566, "from_id": 1092289, "to_id": 1092290, "type": "COMPARE"}, {"id": 175567, "from_id": 1092285, "to_id": 1092289, "type": "COREF"}]}
{"id": "IJCAI_2001_12_abs", "text": "Visitors who browse the web from wireless PDAs, cell phones, and pagers are frequently stymied by web interfaces optimized for desktop PCs. Simply replacing graphics with text and reformatting tables does not solve the problem, because deep link structures can still require minutes to traverse. In this paper we develop an algorithm, MINPATH, that automatically improves wireless web navigation by suggesting useful shortcut links in real time. MINPATH finds shortcuts by using a learned model of web visitor behavior to estimate the savings of shortcut links, and suggests only the few best links. We explore a variety of predictive models, including Na\u00a8\u0131ve Bayes mixture models and mixtures of Markov models, and report empirical evidence that MINPATH finds useful shortcuts that save substantial navigational effort.", "Comments": [], "entities": [{"id": 1092305, "label": "ENT", "start_offset": 98, "end_offset": 112}, {"id": 1092306, "label": "ENT", "start_offset": 127, "end_offset": 138}, {"id": 1092307, "label": "ENT", "start_offset": 236, "end_offset": 256}, {"id": 1092308, "label": "ENT", "start_offset": 324, "end_offset": 333}, {"id": 1092309, "label": "ENT", "start_offset": 335, "end_offset": 342}, {"id": 1092310, "label": "ENT", "start_offset": 372, "end_offset": 395}, {"id": 1092311, "label": "ENT", "start_offset": 446, "end_offset": 453}, {"id": 1092312, "label": "ENT", "start_offset": 489, "end_offset": 494}, {"id": 1092313, "label": "ENT", "start_offset": 498, "end_offset": 518}, {"id": 1092314, "label": "ENT", "start_offset": 535, "end_offset": 560}, {"id": 1092315, "label": "ENT", "start_offset": 624, "end_offset": 641}, {"id": 1092316, "label": "ENT", "start_offset": 653, "end_offset": 680}, {"id": 1092317, "label": "ENT", "start_offset": 685, "end_offset": 710}, {"id": 1092318, "label": "ENT", "start_offset": 747, "end_offset": 754}], "relations": [{"id": 175581, "from_id": 1092309, "to_id": 1092308, "type": "COREF"}, {"id": 175582, "from_id": 1092305, "to_id": 1092306, "type": "USED-FOR"}, {"id": 175583, "from_id": 1092308, "to_id": 1092310, "type": "USED-FOR"}, {"id": 175584, "from_id": 1092311, "to_id": 1092309, "type": "COREF"}, {"id": 175585, "from_id": 1092308, "to_id": 1092310, "type": "USED-FOR"}, {"id": 175586, "from_id": 1092316, "to_id": 1092315, "type": "HYPONYM-OF"}, {"id": 175587, "from_id": 1092317, "to_id": 1092315, "type": "HYPONYM-OF"}, {"id": 175588, "from_id": 1092318, "to_id": 1092311, "type": "COREF"}, {"id": 175589, "from_id": 1092312, "to_id": 1092313, "type": "USED-FOR"}, {"id": 175590, "from_id": 1092315, "to_id": 1092312, "type": "COREF"}, {"id": 175591, "from_id": 1092312, "to_id": 1092311, "type": "USED-FOR"}, {"id": 175592, "from_id": 1092312, "to_id": 1092314, "type": "USED-FOR"}, {"id": 175593, "from_id": 1092316, "to_id": 1092317, "type": "CONJUNCTION"}]}
{"id": "P03-1034", "text": "  Pipelined Natural Language Generation (NLG) systems  have grown increasingly complex as  architectural modules  were added to support  language functionalities  such as  referring expressions ,  lexical choice , and  revision . This has given rise to discussions about the relative placement of these new  modules  in the overall  architecture . Recent work on another aspect of  multi-paragraph text ,  discourse markers , indicates it is time to consider where a  discourse marker insertion algorithm  fits in. We present examples which suggest that in a  pipelined NLG architecture , the best approach is to strongly tie it to a  revision component . Finally, we evaluate the approach in a working  multi-page system . ", "Comments": [], "entities": [{"id": 1092344, "label": "ENT", "start_offset": 2, "end_offset": 53}, {"id": 1092345, "label": "ENT", "start_offset": 91, "end_offset": 112}, {"id": 1092346, "label": "ENT", "start_offset": 137, "end_offset": 161}, {"id": 1092347, "label": "ENT", "start_offset": 172, "end_offset": 193}, {"id": 1092348, "label": "ENT", "start_offset": 197, "end_offset": 211}, {"id": 1092349, "label": "ENT", "start_offset": 219, "end_offset": 227}, {"id": 1092350, "label": "ENT", "start_offset": 308, "end_offset": 315}, {"id": 1092351, "label": "ENT", "start_offset": 324, "end_offset": 345}, {"id": 1092352, "label": "ENT", "start_offset": 382, "end_offset": 402}, {"id": 1092353, "label": "ENT", "start_offset": 406, "end_offset": 423}, {"id": 1092354, "label": "ENT", "start_offset": 468, "end_offset": 504}, {"id": 1092355, "label": "ENT", "start_offset": 560, "end_offset": 586}, {"id": 1092356, "label": "ENT", "start_offset": 598, "end_offset": 606}, {"id": 1092357, "label": "ENT", "start_offset": 626, "end_offset": 628}, {"id": 1092358, "label": "ENT", "start_offset": 635, "end_offset": 653}, {"id": 1092359, "label": "ENT", "start_offset": 681, "end_offset": 689}, {"id": 1092360, "label": "ENT", "start_offset": 704, "end_offset": 721}], "relations": [{"id": 175617, "from_id": 1092345, "to_id": 1092346, "type": "USED-FOR"}, {"id": 175618, "from_id": 1092358, "to_id": 1092355, "type": "PART-OF"}, {"id": 175619, "from_id": 1092347, "to_id": 1092346, "type": "HYPONYM-OF"}, {"id": 175620, "from_id": 1092348, "to_id": 1092346, "type": "HYPONYM-OF"}, {"id": 175621, "from_id": 1092349, "to_id": 1092346, "type": "HYPONYM-OF"}, {"id": 175622, "from_id": 1092347, "to_id": 1092348, "type": "CONJUNCTION"}, {"id": 175623, "from_id": 1092348, "to_id": 1092349, "type": "CONJUNCTION"}, {"id": 175624, "from_id": 1092345, "to_id": 1092350, "type": "COREF"}, {"id": 175625, "from_id": 1092350, "to_id": 1092351, "type": "PART-OF"}, {"id": 175626, "from_id": 1092344, "to_id": 1092351, "type": "COREF"}, {"id": 175627, "from_id": 1092351, "to_id": 1092355, "type": "COREF"}, {"id": 175628, "from_id": 1092360, "to_id": 1092359, "type": "EVALUATE-FOR"}, {"id": 175629, "from_id": 1092354, "to_id": 1092357, "type": "COREF"}, {"id": 175630, "from_id": 1092357, "to_id": 1092358, "type": "CONJUNCTION"}, {"id": 175631, "from_id": 1092356, "to_id": 1092359, "type": "COREF"}]}
{"id": "ECCV_2016_110_abs", "text": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets. Unfortunately, creating large datasets with pixel-level labels has been extremely costly due to the amount of human effort required. In this paper, we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games. ", "Comments": [], "entities": [{"id": 1092417, "label": "ENT", "start_offset": 19, "end_offset": 34}, {"id": 1092418, "label": "ENT", "start_offset": 54, "end_offset": 74}, {"id": 1092419, "label": "ENT", "start_offset": 86, "end_offset": 100}, {"id": 1092420, "label": "ENT", "start_offset": 126, "end_offset": 140}, {"id": 1092421, "label": "ENT", "start_offset": 146, "end_offset": 164}, {"id": 1092422, "label": "ENT", "start_offset": 264, "end_offset": 272}, {"id": 1092423, "label": "ENT", "start_offset": 293, "end_offset": 327}, {"id": 1092424, "label": "ENT", "start_offset": 332, "end_offset": 338}, {"id": 1092425, "label": "ENT", "start_offset": 354, "end_offset": 375}], "relations": [{"id": 175684, "from_id": 1092421, "to_id": 1092420, "type": "FEATURE-OF"}, {"id": 175685, "from_id": 1092418, "to_id": 1092417, "type": "USED-FOR"}, {"id": 175686, "from_id": 1092419, "to_id": 1092418, "type": "USED-FOR"}, {"id": 175687, "from_id": 1092420, "to_id": 1092419, "type": "COREF"}, {"id": 175688, "from_id": 1092422, "to_id": 1092423, "type": "USED-FOR"}, {"id": 175689, "from_id": 1092423, "to_id": 1092424, "type": "USED-FOR"}, {"id": 175690, "from_id": 1092424, "to_id": 1092425, "type": "PART-OF"}]}
{"id": "P06-3007", "text": "   We investigate independent and relevant event-based extractive  mutli-document summarization approaches  . In this paper,  events  are defined as  event terms  and  associated event elements  . With independent approach, we identify important  contents  by frequency of  events  . With relevant approach, we identify important contents by  PageRank algorithm  on the  event map  constructed from  documents  . Experimental results are encouraging. ", "Comments": [], "entities": [{"id": 1092459, "label": "ENT", "start_offset": 18, "end_offset": 106}, {"id": 1092460, "label": "ENT", "start_offset": 202, "end_offset": 222}, {"id": 1092461, "label": "ENT", "start_offset": 289, "end_offset": 306}, {"id": 1092462, "label": "ENT", "start_offset": 343, "end_offset": 361}, {"id": 1092463, "label": "ENT", "start_offset": 371, "end_offset": 380}, {"id": 1092464, "label": "ENT", "start_offset": 400, "end_offset": 409}], "relations": [{"id": 175719, "from_id": 1092464, "to_id": 1092463, "type": "USED-FOR"}, {"id": 175720, "from_id": 1092460, "to_id": 1092459, "type": "HYPONYM-OF"}, {"id": 175721, "from_id": 1092461, "to_id": 1092459, "type": "HYPONYM-OF"}, {"id": 175722, "from_id": 1092462, "to_id": 1092461, "type": "USED-FOR"}, {"id": 175723, "from_id": 1092463, "to_id": 1092462, "type": "USED-FOR"}]}
{"id": "CVPR_2003_21_abs", "text": "This paper investigates critical configurations for projective reconstruction from multiple images taken by a camera moving in a straight line. Projective reconstruction refers to a determination of the 3D geometrical configuration of a set of 3D points and cameras, given only correspondences between points in the images. A configuration of points and cameras is critical if it can not be determined uniquely (up to a projective transform) from the image coordinates of the points. It is shown that a configuration consisting of any number of cameras lying on a straight line, and any number of points lying on a twisted cubic constitutes a critical configuration. An alternative configuration consisting of a set of points and cameras all lying on a rational quartic curve exists.", "Comments": [], "entities": [{"id": 1092465, "label": "ENT", "start_offset": 52, "end_offset": 77}, {"id": 1092466, "label": "ENT", "start_offset": 92, "end_offset": 98}, {"id": 1092467, "label": "ENT", "start_offset": 144, "end_offset": 169}, {"id": 1092468, "label": "ENT", "start_offset": 203, "end_offset": 231}, {"id": 1092469, "label": "ENT", "start_offset": 244, "end_offset": 265}, {"id": 1092470, "label": "ENT", "start_offset": 451, "end_offset": 468}, {"id": 1092471, "label": "ENT", "start_offset": 753, "end_offset": 775}], "relations": [{"id": 175724, "from_id": 1092466, "to_id": 1092465, "type": "USED-FOR"}, {"id": 175725, "from_id": 1092467, "to_id": 1092465, "type": "COREF"}, {"id": 175726, "from_id": 1092468, "to_id": 1092469, "type": "FEATURE-OF"}]}
{"id": "ECCV_2016_99_abs", "text": "Human action recognition from well-segmented 3D skeleton data has been intensively studied and attracting an increasing attention. Online action detection goes one step further and is more challenging, which identifies the action type and localizes the action positions on the fly from the untrimmed stream. In this paper, we study the problem of online action detection from the streaming skeleton data. We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localiza-tion information. By employing a joint classification and regression optimization objective, this network is capable of automatically localizing the start and end points of actions more accurately. Specifically, by leveraging the merits of the deep Long Short-Term Memory (LSTM) subnetwork, the proposed model automatically captures the complex long-range temporal dynamics, which naturally avoids the typical sliding window design and thus ensures high computational efficiency. Furthermore, the subtask of regression optimization provides the ability to forecast the action prior to its occurrence. To evaluate our proposed model, we build a large streaming video dataset with annotations. Experimental results on our dataset and the public G3D dataset both demonstrate very promising performance of our scheme.", "Comments": [], "entities": [{"id": 1092557, "label": "ENT", "start_offset": 0, "end_offset": 24}, {"id": 1092558, "label": "ENT", "start_offset": 30, "end_offset": 61}, {"id": 1092559, "label": "ENT", "start_offset": 131, "end_offset": 154}, {"id": 1092560, "label": "ENT", "start_offset": 223, "end_offset": 234}, {"id": 1092561, "label": "ENT", "start_offset": 253, "end_offset": 269}, {"id": 1092562, "label": "ENT", "start_offset": 290, "end_offset": 306}, {"id": 1092563, "label": "ENT", "start_offset": 347, "end_offset": 370}, {"id": 1092564, "label": "ENT", "start_offset": 380, "end_offset": 403}, {"id": 1092565, "label": "ENT", "start_offset": 418, "end_offset": 496}, {"id": 1092566, "label": "ENT", "start_offset": 519, "end_offset": 530}, {"id": 1092567, "label": "ENT", "start_offset": 535, "end_offset": 569}, {"id": 1092568, "label": "ENT", "start_offset": 586, "end_offset": 644}, {"id": 1092569, "label": "ENT", "start_offset": 651, "end_offset": 658}, {"id": 1092570, "label": "ENT", "start_offset": 797, "end_offset": 842}, {"id": 1092571, "label": "ENT", "start_offset": 857, "end_offset": 862}, {"id": 1092572, "label": "ENT", "start_offset": 898, "end_offset": 926}, {"id": 1092573, "label": "ENT", "start_offset": 963, "end_offset": 984}, {"id": 1092574, "label": "ENT", "start_offset": 1007, "end_offset": 1031}, {"id": 1092575, "label": "ENT", "start_offset": 1061, "end_offset": 1084}, {"id": 1092576, "label": "ENT", "start_offset": 1179, "end_offset": 1184}, {"id": 1092577, "label": "ENT", "start_offset": 1203, "end_offset": 1226}, {"id": 1092578, "label": "ENT", "start_offset": 1273, "end_offset": 1280}, {"id": 1092579, "label": "ENT", "start_offset": 1296, "end_offset": 1307}], "relations": [{"id": 175790, "from_id": 1092558, "to_id": 1092557, "type": "USED-FOR"}, {"id": 175791, "from_id": 1092559, "to_id": 1092560, "type": "USED-FOR"}, {"id": 175792, "from_id": 1092564, "to_id": 1092563, "type": "USED-FOR"}, {"id": 175793, "from_id": 1092559, "to_id": 1092561, "type": "USED-FOR"}, {"id": 175794, "from_id": 1092562, "to_id": 1092559, "type": "USED-FOR"}, {"id": 175795, "from_id": 1092563, "to_id": 1092559, "type": "COREF"}, {"id": 175796, "from_id": 1092565, "to_id": 1092566, "type": "USED-FOR"}, {"id": 175797, "from_id": 1092565, "to_id": 1092567, "type": "USED-FOR"}, {"id": 175798, "from_id": 1092566, "to_id": 1092567, "type": "CONJUNCTION"}, {"id": 175799, "from_id": 1092560, "to_id": 1092561, "type": "CONJUNCTION"}, {"id": 175800, "from_id": 1092569, "to_id": 1092565, "type": "COREF"}, {"id": 175801, "from_id": 1092568, "to_id": 1092569, "type": "USED-FOR"}, {"id": 175802, "from_id": 1092571, "to_id": 1092569, "type": "COREF"}, {"id": 175803, "from_id": 1092572, "to_id": 1092571, "type": "FEATURE-OF"}, {"id": 175804, "from_id": 1092576, "to_id": 1092571, "type": "COREF"}, {"id": 175805, "from_id": 1092577, "to_id": 1092576, "type": "EVALUATE-FOR"}, {"id": 175806, "from_id": 1092578, "to_id": 1092577, "type": "COREF"}, {"id": 175807, "from_id": 1092578, "to_id": 1092579, "type": "CONJUNCTION"}, {"id": 175808, "from_id": 1092570, "to_id": 1092571, "type": "USED-FOR"}]}
{"id": "N03-4004", "text": "   The  TAP-XL Automated Analyst's Assistant  is an application designed to help an  English  -speaking analyst write a  topical report  , culling information from a large inflow of  multilingual, multimedia data  . It gives users the ability to spend their time finding more data relevant to their task, and gives them translingual reach into other  languages  by leveraging  human language technology  . ", "Comments": [], "entities": [{"id": 1092620, "label": "ENT", "start_offset": 8, "end_offset": 44}, {"id": 1092621, "label": "ENT", "start_offset": 183, "end_offset": 212}, {"id": 1092622, "label": "ENT", "start_offset": 216, "end_offset": 218}, {"id": 1092623, "label": "ENT", "start_offset": 377, "end_offset": 402}], "relations": [{"id": 175844, "from_id": 1092621, "to_id": 1092620, "type": "USED-FOR"}, {"id": 175845, "from_id": 1092622, "to_id": 1092620, "type": "COREF"}, {"id": 175846, "from_id": 1092623, "to_id": 1092622, "type": "USED-FOR"}]}
{"id": "INTERSPEECH_2006_28_abs", "text": "We investigated whether automatic phonetic transcriptions (APTs) can replace manually verified phonetic transcriptions (MPTs) in a large corpus-based study on pronunciation variation. To this end, we compared the performance of both transcription types in a classification experiment aimed at establishing the direct influence of a particular situational setting on pronunciation variation. We trained classifiers on the speech processes extracted from the alignments of an APT and an MPT with a canonical transcription. We tested whether the classifiers were equally good at verifying whether unknown transcriptions represent read speech or telephone dialogues, and whether the same speech processes were identified to distinguish between transcriptions of the two situational settings. Our results not only show that similar distinguishing speech processes were identified; our APT-based classifier yielded better classification accuracy than the MPT-based classifier whilst using fewer classification features.", "Comments": [], "entities": [{"id": 1092657, "label": "ENT", "start_offset": 24, "end_offset": 64}, {"id": 1092658, "label": "ENT", "start_offset": 77, "end_offset": 118}, {"id": 1092659, "label": "ENT", "start_offset": 159, "end_offset": 182}, {"id": 1092660, "label": "ENT", "start_offset": 258, "end_offset": 272}, {"id": 1092661, "label": "ENT", "start_offset": 366, "end_offset": 389}, {"id": 1092662, "label": "ENT", "start_offset": 402, "end_offset": 413}, {"id": 1092663, "label": "ENT", "start_offset": 421, "end_offset": 437}, {"id": 1092664, "label": "ENT", "start_offset": 457, "end_offset": 467}, {"id": 1092665, "label": "ENT", "start_offset": 474, "end_offset": 477}, {"id": 1092666, "label": "ENT", "start_offset": 485, "end_offset": 488}, {"id": 1092667, "label": "ENT", "start_offset": 496, "end_offset": 519}, {"id": 1092668, "label": "ENT", "start_offset": 543, "end_offset": 554}, {"id": 1092669, "label": "ENT", "start_offset": 594, "end_offset": 616}, {"id": 1092670, "label": "ENT", "start_offset": 627, "end_offset": 638}, {"id": 1092671, "label": "ENT", "start_offset": 642, "end_offset": 661}, {"id": 1092672, "label": "ENT", "start_offset": 684, "end_offset": 700}, {"id": 1092673, "label": "ENT", "start_offset": 880, "end_offset": 900}, {"id": 1092674, "label": "ENT", "start_offset": 916, "end_offset": 939}, {"id": 1092675, "label": "ENT", "start_offset": 949, "end_offset": 969}, {"id": 1092676, "label": "ENT", "start_offset": 989, "end_offset": 1012}], "relations": [{"id": 175875, "from_id": 1092657, "to_id": 1092659, "type": "USED-FOR"}, {"id": 175876, "from_id": 1092658, "to_id": 1092659, "type": "USED-FOR"}, {"id": 175877, "from_id": 1092657, "to_id": 1092658, "type": "COMPARE"}, {"id": 175878, "from_id": 1092659, "to_id": 1092661, "type": "COREF"}, {"id": 175879, "from_id": 1092665, "to_id": 1092657, "type": "COREF"}, {"id": 175880, "from_id": 1092666, "to_id": 1092658, "type": "COREF"}, {"id": 175881, "from_id": 1092664, "to_id": 1092663, "type": "USED-FOR"}, {"id": 175882, "from_id": 1092663, "to_id": 1092662, "type": "USED-FOR"}, {"id": 175883, "from_id": 1092667, "to_id": 1092664, "type": "USED-FOR"}, {"id": 175884, "from_id": 1092664, "to_id": 1092665, "type": "USED-FOR"}, {"id": 175885, "from_id": 1092664, "to_id": 1092666, "type": "USED-FOR"}, {"id": 175886, "from_id": 1092665, "to_id": 1092666, "type": "CONJUNCTION"}, {"id": 175887, "from_id": 1092662, "to_id": 1092668, "type": "COREF"}, {"id": 175888, "from_id": 1092669, "to_id": 1092670, "type": "USED-FOR"}, {"id": 175889, "from_id": 1092669, "to_id": 1092671, "type": "USED-FOR"}, {"id": 175890, "from_id": 1092670, "to_id": 1092671, "type": "CONJUNCTION"}, {"id": 175891, "from_id": 1092668, "to_id": 1092669, "type": "USED-FOR"}, {"id": 175892, "from_id": 1092674, "to_id": 1092673, "type": "EVALUATE-FOR"}, {"id": 175893, "from_id": 1092673, "to_id": 1092675, "type": "COMPARE"}, {"id": 175894, "from_id": 1092676, "to_id": 1092673, "type": "USED-FOR"}, {"id": 175895, "from_id": 1092676, "to_id": 1092675, "type": "USED-FOR"}, {"id": 175896, "from_id": 1092674, "to_id": 1092675, "type": "EVALUATE-FOR"}]}
{"id": "E06-1022", "text": " We present results on  addressee identification  in  four-participants face-to-face meetings  using  Bayesian Network  and  Naive Bayes classifiers  . First, we investigate how well the  addressee  of a  dialogue act  can be predicted based on  gaze  ,  utterance  and  conversational context features  . Then, we explore whether information about  meeting context  can aid  classifiers  '  performances  . Both  classifiers  perform the best when  conversational context  and  utterance features  are combined with  speaker's gaze information  . The  classifiers  show little  gain  from information about  meeting context  . ", "Comments": [], "entities": [{"id": 1092688, "label": "ENT", "start_offset": 24, "end_offset": 93}, {"id": 1092689, "label": "ENT", "start_offset": 102, "end_offset": 118}, {"id": 1092690, "label": "ENT", "start_offset": 125, "end_offset": 148}, {"id": 1092691, "label": "ENT", "start_offset": 188, "end_offset": 217}, {"id": 1092692, "label": "ENT", "start_offset": 246, "end_offset": 250}, {"id": 1092693, "label": "ENT", "start_offset": 255, "end_offset": 264}, {"id": 1092694, "label": "ENT", "start_offset": 271, "end_offset": 302}, {"id": 1092695, "label": "ENT", "start_offset": 350, "end_offset": 365}, {"id": 1092696, "label": "ENT", "start_offset": 376, "end_offset": 387}, {"id": 1092697, "label": "ENT", "start_offset": 414, "end_offset": 425}, {"id": 1092698, "label": "ENT", "start_offset": 450, "end_offset": 472}, {"id": 1092699, "label": "ENT", "start_offset": 479, "end_offset": 497}, {"id": 1092700, "label": "ENT", "start_offset": 518, "end_offset": 544}, {"id": 1092701, "label": "ENT", "start_offset": 553, "end_offset": 564}, {"id": 1092702, "label": "ENT", "start_offset": 609, "end_offset": 624}], "relations": [{"id": 175904, "from_id": 1092690, "to_id": 1092689, "type": "CONJUNCTION"}, {"id": 175905, "from_id": 1092692, "to_id": 1092693, "type": "CONJUNCTION"}, {"id": 175906, "from_id": 1092693, "to_id": 1092694, "type": "CONJUNCTION"}, {"id": 175907, "from_id": 1092698, "to_id": 1092699, "type": "CONJUNCTION"}, {"id": 175908, "from_id": 1092700, "to_id": 1092699, "type": "CONJUNCTION"}, {"id": 175909, "from_id": 1092701, "to_id": 1092697, "type": "COREF"}, {"id": 175910, "from_id": 1092689, "to_id": 1092697, "type": "HYPONYM-OF"}, {"id": 175911, "from_id": 1092690, "to_id": 1092697, "type": "HYPONYM-OF"}, {"id": 175912, "from_id": 1092698, "to_id": 1092697, "type": "USED-FOR"}, {"id": 175913, "from_id": 1092699, "to_id": 1092697, "type": "USED-FOR"}, {"id": 175914, "from_id": 1092700, "to_id": 1092697, "type": "USED-FOR"}, {"id": 175915, "from_id": 1092692, "to_id": 1092691, "type": "USED-FOR"}, {"id": 175916, "from_id": 1092693, "to_id": 1092691, "type": "USED-FOR"}, {"id": 175917, "from_id": 1092694, "to_id": 1092691, "type": "USED-FOR"}, {"id": 175918, "from_id": 1092697, "to_id": 1092696, "type": "COREF"}, {"id": 175919, "from_id": 1092689, "to_id": 1092688, "type": "USED-FOR"}, {"id": 175920, "from_id": 1092690, "to_id": 1092688, "type": "USED-FOR"}]}
{"id": "A97-1020", "text": "  GLOSSER  is designed to support reading and learning to read in a foreign  language . There are four  language pairs  currently supported by  GLOSSER :  English-Bulgarian ,  English-Estonian ,  English-Hungarian  and  French-Dutch . The program is operational on UNIX and Windows '95 platforms, and has undergone a pilot user-study. A demonstration (in UNIX) for  Applied Natural Language Processing  emphasizes components put to novel technical uses in  intelligent computer-assisted morphological analysis (ICALL) , including  disambiguated morphological analysis  and  lemmatized indexing  for an  aligned bilingual corpus  of  word examples . ", "Comments": [], "entities": [{"id": 1092830, "label": "ENT", "start_offset": 2, "end_offset": 9}, {"id": 1092831, "label": "ENT", "start_offset": 34, "end_offset": 54}, {"id": 1092832, "label": "ENT", "start_offset": 104, "end_offset": 118}, {"id": 1092833, "label": "ENT", "start_offset": 144, "end_offset": 151}, {"id": 1092834, "label": "ENT", "start_offset": 155, "end_offset": 172}, {"id": 1092835, "label": "ENT", "start_offset": 176, "end_offset": 192}, {"id": 1092836, "label": "ENT", "start_offset": 196, "end_offset": 213}, {"id": 1092837, "label": "ENT", "start_offset": 220, "end_offset": 232}, {"id": 1092838, "label": "ENT", "start_offset": 239, "end_offset": 246}, {"id": 1092839, "label": "ENT", "start_offset": 265, "end_offset": 295}, {"id": 1092840, "label": "ENT", "start_offset": 323, "end_offset": 333}, {"id": 1092841, "label": "ENT", "start_offset": 366, "end_offset": 401}, {"id": 1092842, "label": "ENT", "start_offset": 414, "end_offset": 424}, {"id": 1092843, "label": "ENT", "start_offset": 457, "end_offset": 517}, {"id": 1092844, "label": "ENT", "start_offset": 531, "end_offset": 567}, {"id": 1092845, "label": "ENT", "start_offset": 574, "end_offset": 593}, {"id": 1092846, "label": "ENT", "start_offset": 603, "end_offset": 627}], "relations": [{"id": 176020, "from_id": 1092842, "to_id": 1092843, "type": "USED-FOR"}, {"id": 176021, "from_id": 1092833, "to_id": 1092830, "type": "COREF"}, {"id": 176022, "from_id": 1092834, "to_id": 1092835, "type": "CONJUNCTION"}, {"id": 176023, "from_id": 1092835, "to_id": 1092836, "type": "CONJUNCTION"}, {"id": 176024, "from_id": 1092836, "to_id": 1092837, "type": "CONJUNCTION"}, {"id": 176025, "from_id": 1092838, "to_id": 1092833, "type": "COREF"}, {"id": 176026, "from_id": 1092832, "to_id": 1092833, "type": "USED-FOR"}, {"id": 176027, "from_id": 1092834, "to_id": 1092832, "type": "HYPONYM-OF"}, {"id": 176028, "from_id": 1092835, "to_id": 1092832, "type": "HYPONYM-OF"}, {"id": 176029, "from_id": 1092836, "to_id": 1092832, "type": "HYPONYM-OF"}, {"id": 176030, "from_id": 1092837, "to_id": 1092832, "type": "HYPONYM-OF"}, {"id": 176031, "from_id": 1092830, "to_id": 1092831, "type": "USED-FOR"}, {"id": 176032, "from_id": 1092844, "to_id": 1092842, "type": "HYPONYM-OF"}, {"id": 176033, "from_id": 1092845, "to_id": 1092842, "type": "HYPONYM-OF"}, {"id": 176034, "from_id": 1092844, "to_id": 1092845, "type": "CONJUNCTION"}, {"id": 176035, "from_id": 1092845, "to_id": 1092846, "type": "USED-FOR"}, {"id": 176036, "from_id": 1092844, "to_id": 1092846, "type": "USED-FOR"}]}
{"id": "W03-0406", "text": " In this paper, we improve an  unsupervised learning method  using the  Expectation-Maximization (EM) algorithm  proposed by Nigam et al. for  text classification problems  in order to apply it to  word sense disambiguation (WSD) problems . The improved method stops the  EM algorithm  at the  optimum iteration number . To estimate that number, we propose two methods. In experiments, we solved 50  noun WSD problems  in the  Japanese Dictionary Task in SENSEVAL2 . The score of our method is a match for the best public score of this task. Furthermore, our methods were confirmed to be effective also for  verb WSD problems . ", "Comments": [], "entities": [{"id": 1092858, "label": "ENT", "start_offset": 31, "end_offset": 59}, {"id": 1092859, "label": "ENT", "start_offset": 72, "end_offset": 111}, {"id": 1092860, "label": "ENT", "start_offset": 143, "end_offset": 171}, {"id": 1092861, "label": "ENT", "start_offset": 191, "end_offset": 193}, {"id": 1092862, "label": "ENT", "start_offset": 198, "end_offset": 238}, {"id": 1092863, "label": "ENT", "start_offset": 254, "end_offset": 260}, {"id": 1092864, "label": "ENT", "start_offset": 272, "end_offset": 284}, {"id": 1092865, "label": "ENT", "start_offset": 294, "end_offset": 318}, {"id": 1092866, "label": "ENT", "start_offset": 338, "end_offset": 344}, {"id": 1092867, "label": "ENT", "start_offset": 400, "end_offset": 417}, {"id": 1092868, "label": "ENT", "start_offset": 427, "end_offset": 451}, {"id": 1092869, "label": "ENT", "start_offset": 455, "end_offset": 464}, {"id": 1092870, "label": "ENT", "start_offset": 484, "end_offset": 490}, {"id": 1092871, "label": "ENT", "start_offset": 536, "end_offset": 540}, {"id": 1092872, "label": "ENT", "start_offset": 559, "end_offset": 566}, {"id": 1092873, "label": "ENT", "start_offset": 608, "end_offset": 625}], "relations": [{"id": 176045, "from_id": 1092859, "to_id": 1092858, "type": "USED-FOR"}, {"id": 176046, "from_id": 1092859, "to_id": 1092860, "type": "USED-FOR"}, {"id": 176047, "from_id": 1092861, "to_id": 1092858, "type": "COREF"}, {"id": 176048, "from_id": 1092861, "to_id": 1092862, "type": "USED-FOR"}, {"id": 176049, "from_id": 1092863, "to_id": 1092858, "type": "COREF"}, {"id": 176050, "from_id": 1092866, "to_id": 1092865, "type": "COREF"}, {"id": 176051, "from_id": 1092868, "to_id": 1092869, "type": "FEATURE-OF"}, {"id": 176052, "from_id": 1092871, "to_id": 1092868, "type": "COREF"}, {"id": 176053, "from_id": 1092872, "to_id": 1092873, "type": "USED-FOR"}, {"id": 176054, "from_id": 1092872, "to_id": 1092870, "type": "COREF"}, {"id": 176055, "from_id": 1092870, "to_id": 1092863, "type": "COREF"}]}
{"id": "ECCV_2016_205_abs", "text": "Two main classes of approaches have been studied to perform monocular nonrigid 3D reconstruction: Template-based methods and Non-rigid Structure from Motion techniques. While the first ones have been applied to reconstruct poorly-textured surfaces, they assume the availability of a 3D shape model prior to reconstruction. By contrast, the second ones do not require such a shape template, but, instead, rely on points being tracked throughout a video sequence, and are thus ill-suited to handle poorly-textured surfaces. In this paper, we introduce a template-free approach to reconstructing a poorly-textured, deformable surface. To this end, we leverage surface isometry and formulate 3D reconstruction as the joint problem of non-rigid image registration and depth estimation. Our experiments demonstrate that our approach yields much more accurate 3D reconstructions than state-of-the-art techniques.", "Comments": [], "entities": [{"id": 1092885, "label": "ENT", "start_offset": 20, "end_offset": 30}, {"id": 1092886, "label": "ENT", "start_offset": 60, "end_offset": 96}, {"id": 1092887, "label": "ENT", "start_offset": 98, "end_offset": 120}, {"id": 1092888, "label": "ENT", "start_offset": 125, "end_offset": 167}, {"id": 1092889, "label": "ENT", "start_offset": 185, "end_offset": 189}, {"id": 1092890, "label": "ENT", "start_offset": 223, "end_offset": 247}, {"id": 1092891, "label": "ENT", "start_offset": 249, "end_offset": 253}, {"id": 1092892, "label": "ENT", "start_offset": 283, "end_offset": 297}, {"id": 1092893, "label": "ENT", "start_offset": 307, "end_offset": 321}, {"id": 1092894, "label": "ENT", "start_offset": 347, "end_offset": 351}, {"id": 1092895, "label": "ENT", "start_offset": 374, "end_offset": 388}, {"id": 1092896, "label": "ENT", "start_offset": 446, "end_offset": 460}, {"id": 1092897, "label": "ENT", "start_offset": 496, "end_offset": 520}, {"id": 1092898, "label": "ENT", "start_offset": 552, "end_offset": 574}, {"id": 1092899, "label": "ENT", "start_offset": 595, "end_offset": 630}, {"id": 1092900, "label": "ENT", "start_offset": 657, "end_offset": 673}, {"id": 1092901, "label": "ENT", "start_offset": 688, "end_offset": 705}, {"id": 1092902, "label": "ENT", "start_offset": 713, "end_offset": 779}, {"id": 1092903, "label": "ENT", "start_offset": 818, "end_offset": 826}, {"id": 1092904, "label": "ENT", "start_offset": 853, "end_offset": 871}, {"id": 1092905, "label": "ENT", "start_offset": 877, "end_offset": 904}], "relations": [{"id": 176065, "from_id": 1092885, "to_id": 1092886, "type": "USED-FOR"}, {"id": 176066, "from_id": 1092887, "to_id": 1092885, "type": "HYPONYM-OF"}, {"id": 176067, "from_id": 1092888, "to_id": 1092885, "type": "HYPONYM-OF"}, {"id": 176068, "from_id": 1092887, "to_id": 1092889, "type": "COREF"}, {"id": 176069, "from_id": 1092889, "to_id": 1092890, "type": "USED-FOR"}, {"id": 176070, "from_id": 1092889, "to_id": 1092891, "type": "COREF"}, {"id": 176071, "from_id": 1092892, "to_id": 1092891, "type": "USED-FOR"}, {"id": 176072, "from_id": 1092888, "to_id": 1092894, "type": "COREF"}, {"id": 176073, "from_id": 1092898, "to_id": 1092899, "type": "USED-FOR"}, {"id": 176074, "from_id": 1092902, "to_id": 1092901, "type": "USED-FOR"}, {"id": 176075, "from_id": 1092898, "to_id": 1092903, "type": "COREF"}, {"id": 176076, "from_id": 1092887, "to_id": 1092888, "type": "CONJUNCTION"}, {"id": 176077, "from_id": 1092903, "to_id": 1092905, "type": "COMPARE"}, {"id": 176078, "from_id": 1092904, "to_id": 1092903, "type": "EVALUATE-FOR"}, {"id": 176079, "from_id": 1092904, "to_id": 1092905, "type": "EVALUATE-FOR"}, {"id": 176080, "from_id": 1092900, "to_id": 1092901, "type": "USED-FOR"}, {"id": 176081, "from_id": 1092901, "to_id": 1092904, "type": "COREF"}, {"id": 176082, "from_id": 1092886, "to_id": 1092901, "type": "COREF"}, {"id": 176083, "from_id": 1092886, "to_id": 1092893, "type": "COREF"}]}
{"id": "ICCV_2003_161_abs", "text": "The perception of transparent objects from images is known to be a very hard problem in vision. Given a single image, it is difficult to even detect the presence of transparent objects in the scene. In this paper, we explore what can be said about transparent objects by a moving observer. We show how features that are imaged through a transparent object behave differently from those that are rigidly attached to the scene. We present a novel model-based approach to recover the shapes and the poses of transparent objects from known motion. The objects can be complex in that they may be composed of multiple layers with different refractive indices. We have conducted numerous simulations to verify the practical feasibility of our algorithm. We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy. ", "Comments": [], "entities": [{"id": 1092975, "label": "ENT", "start_offset": 4, "end_offset": 37}, {"id": 1092976, "label": "ENT", "start_offset": 43, "end_offset": 49}, {"id": 1092977, "label": "ENT", "start_offset": 165, "end_offset": 184}, {"id": 1092978, "label": "ENT", "start_offset": 248, "end_offset": 267}, {"id": 1092979, "label": "ENT", "start_offset": 302, "end_offset": 310}, {"id": 1092980, "label": "ENT", "start_offset": 337, "end_offset": 355}, {"id": 1092981, "label": "ENT", "start_offset": 380, "end_offset": 385}, {"id": 1092982, "label": "ENT", "start_offset": 445, "end_offset": 465}, {"id": 1092983, "label": "ENT", "start_offset": 481, "end_offset": 524}, {"id": 1092984, "label": "ENT", "start_offset": 530, "end_offset": 542}, {"id": 1092985, "label": "ENT", "start_offset": 548, "end_offset": 555}, {"id": 1092986, "label": "ENT", "start_offset": 579, "end_offset": 583}, {"id": 1092987, "label": "ENT", "start_offset": 603, "end_offset": 618}, {"id": 1092988, "label": "ENT", "start_offset": 634, "end_offset": 652}, {"id": 1092989, "label": "ENT", "start_offset": 736, "end_offset": 745}, {"id": 1092990, "label": "ENT", "start_offset": 763, "end_offset": 765}, {"id": 1092991, "label": "ENT", "start_offset": 769, "end_offset": 780}, {"id": 1092992, "label": "ENT", "start_offset": 794, "end_offset": 813}, {"id": 1092993, "label": "ENT", "start_offset": 832, "end_offset": 853}, {"id": 1092994, "label": "ENT", "start_offset": 864, "end_offset": 872}], "relations": [{"id": 176141, "from_id": 1092976, "to_id": 1092975, "type": "USED-FOR"}, {"id": 176142, "from_id": 1092981, "to_id": 1092979, "type": "COMPARE"}, {"id": 176143, "from_id": 1092982, "to_id": 1092983, "type": "USED-FOR"}, {"id": 176144, "from_id": 1092984, "to_id": 1092983, "type": "USED-FOR"}, {"id": 176145, "from_id": 1092985, "to_id": 1092986, "type": "COREF"}, {"id": 176146, "from_id": 1092987, "to_id": 1092986, "type": "PART-OF"}, {"id": 176147, "from_id": 1092982, "to_id": 1092989, "type": "COREF"}, {"id": 176148, "from_id": 1092988, "to_id": 1092987, "type": "FEATURE-OF"}, {"id": 176149, "from_id": 1092990, "to_id": 1092989, "type": "COREF"}, {"id": 176150, "from_id": 1092990, "to_id": 1092991, "type": "USED-FOR"}, {"id": 176151, "from_id": 1092992, "to_id": 1092991, "type": "PART-OF"}, {"id": 176152, "from_id": 1092990, "to_id": 1092993, "type": "USED-FOR"}, {"id": 176153, "from_id": 1092994, "to_id": 1092993, "type": "EVALUATE-FOR"}]}
{"id": "ICASSP_1997_714_abs", "text": "LPC based speech coders operating at bit rates below 3.0 kbits/sec are usually associated with buzzy or metallic artefacts in the synthetic speech. These are mainly attributable to the simplifying assumptions made about the excitation source, which are usually required to maintain such low bit rates. In this paper a new LPC vocoder is presented which splits the LPC excitation into two frequency bands using a variable cutoff frequency. The lower band is responsible for representing the voiced parts of speech, whilst the upper band represents unvoiced speech. In doing so the coder's performance during both mixed voicing speech and speech containing acoustic noise is greatly improved, producing soft natural sounding speech. The paper also describes new parameter determination and quantisation techniques vital to the operation of this coder at such low bit rates.", "Comments": [], "entities": [{"id": 1092997, "label": "ENT", "start_offset": 0, "end_offset": 23}, {"id": 1092998, "label": "ENT", "start_offset": 37, "end_offset": 46}, {"id": 1092999, "label": "ENT", "start_offset": 95, "end_offset": 122}, {"id": 1093000, "label": "ENT", "start_offset": 130, "end_offset": 146}, {"id": 1093001, "label": "ENT", "start_offset": 224, "end_offset": 241}, {"id": 1093002, "label": "ENT", "start_offset": 287, "end_offset": 300}, {"id": 1093003, "label": "ENT", "start_offset": 322, "end_offset": 333}, {"id": 1093004, "label": "ENT", "start_offset": 364, "end_offset": 378}, {"id": 1093005, "label": "ENT", "start_offset": 388, "end_offset": 403}, {"id": 1093006, "label": "ENT", "start_offset": 412, "end_offset": 437}, {"id": 1093007, "label": "ENT", "start_offset": 490, "end_offset": 512}, {"id": 1093008, "label": "ENT", "start_offset": 547, "end_offset": 562}, {"id": 1093009, "label": "ENT", "start_offset": 580, "end_offset": 585}, {"id": 1093010, "label": "ENT", "start_offset": 612, "end_offset": 632}, {"id": 1093011, "label": "ENT", "start_offset": 637, "end_offset": 669}, {"id": 1093012, "label": "ENT", "start_offset": 701, "end_offset": 729}, {"id": 1093013, "label": "ENT", "start_offset": 760, "end_offset": 783}, {"id": 1093014, "label": "ENT", "start_offset": 788, "end_offset": 811}, {"id": 1093015, "label": "ENT", "start_offset": 843, "end_offset": 848}, {"id": 1093016, "label": "ENT", "start_offset": 857, "end_offset": 870}], "relations": [{"id": 176155, "from_id": 1092998, "to_id": 1092997, "type": "FEATURE-OF"}, {"id": 176156, "from_id": 1092999, "to_id": 1093000, "type": "FEATURE-OF"}, {"id": 176157, "from_id": 1093006, "to_id": 1093005, "type": "USED-FOR"}, {"id": 176158, "from_id": 1093006, "to_id": 1093004, "type": "USED-FOR"}, {"id": 176159, "from_id": 1093009, "to_id": 1093003, "type": "COREF"}, {"id": 176160, "from_id": 1093010, "to_id": 1093009, "type": "USED-FOR"}, {"id": 176161, "from_id": 1093011, "to_id": 1093009, "type": "USED-FOR"}, {"id": 176162, "from_id": 1093009, "to_id": 1093012, "type": "USED-FOR"}, {"id": 176163, "from_id": 1093009, "to_id": 1093015, "type": "COREF"}, {"id": 176164, "from_id": 1093016, "to_id": 1093015, "type": "FEATURE-OF"}, {"id": 176165, "from_id": 1093014, "to_id": 1093015, "type": "USED-FOR"}, {"id": 176166, "from_id": 1093013, "to_id": 1093015, "type": "USED-FOR"}, {"id": 176167, "from_id": 1093013, "to_id": 1093014, "type": "CONJUNCTION"}]}
{"id": "E83-1021", "text": " This article deals with the  interpretation  of  conceptual operations  underlying the communicative use of  natural language (NL)  within the  Structured Inheritance Network (SI-Nets) paradigm . The operations are reduced to  functions  of a  formal language , thus changing the level of abstraction of the operations to be performed on  SI-Nets . In this sense, operations on  SI-Nets  are not merely isomorphic to single epistemological objects, but can be viewed as a simulation of processes on a different level, that pertaining to the  conceptual system  of  NL . For this purpose, we have designed a version of  KL-ONE  which represents the  epistemological level , while the new experimental language,  KL-Conc , represents the  conceptual level . KL-Conc would seem to be a more natural and intuitive way of interacting with  SI-Nets . ", "Comments": [], "entities": [{"id": 1093029, "label": "ENT", "start_offset": 50, "end_offset": 71}, {"id": 1093030, "label": "ENT", "start_offset": 110, "end_offset": 131}, {"id": 1093031, "label": "ENT", "start_offset": 145, "end_offset": 194}, {"id": 1093032, "label": "ENT", "start_offset": 201, "end_offset": 211}, {"id": 1093033, "label": "ENT", "start_offset": 245, "end_offset": 260}, {"id": 1093034, "label": "ENT", "start_offset": 309, "end_offset": 319}, {"id": 1093035, "label": "ENT", "start_offset": 340, "end_offset": 347}, {"id": 1093036, "label": "ENT", "start_offset": 365, "end_offset": 375}, {"id": 1093037, "label": "ENT", "start_offset": 380, "end_offset": 387}, {"id": 1093038, "label": "ENT", "start_offset": 425, "end_offset": 448}, {"id": 1093039, "label": "ENT", "start_offset": 543, "end_offset": 560}, {"id": 1093040, "label": "ENT", "start_offset": 566, "end_offset": 568}, {"id": 1093041, "label": "ENT", "start_offset": 620, "end_offset": 626}, {"id": 1093042, "label": "ENT", "start_offset": 650, "end_offset": 671}, {"id": 1093043, "label": "ENT", "start_offset": 688, "end_offset": 709}, {"id": 1093044, "label": "ENT", "start_offset": 712, "end_offset": 719}, {"id": 1093045, "label": "ENT", "start_offset": 738, "end_offset": 754}, {"id": 1093046, "label": "ENT", "start_offset": 757, "end_offset": 764}, {"id": 1093047, "label": "ENT", "start_offset": 836, "end_offset": 843}], "relations": [{"id": 176177, "from_id": 1093040, "to_id": 1093039, "type": "USED-FOR"}, {"id": 176178, "from_id": 1093042, "to_id": 1093041, "type": "FEATURE-OF"}, {"id": 176179, "from_id": 1093045, "to_id": 1093044, "type": "FEATURE-OF"}, {"id": 176180, "from_id": 1093034, "to_id": 1093032, "type": "COREF"}, {"id": 176181, "from_id": 1093035, "to_id": 1093031, "type": "COREF"}, {"id": 176182, "from_id": 1093034, "to_id": 1093035, "type": "USED-FOR"}, {"id": 176183, "from_id": 1093037, "to_id": 1093035, "type": "COREF"}, {"id": 176184, "from_id": 1093036, "to_id": 1093034, "type": "COREF"}, {"id": 176185, "from_id": 1093040, "to_id": 1093030, "type": "COREF"}, {"id": 176186, "from_id": 1093046, "to_id": 1093044, "type": "COREF"}, {"id": 176187, "from_id": 1093047, "to_id": 1093037, "type": "COREF"}, {"id": 176188, "from_id": 1093041, "to_id": 1093044, "type": "COMPARE"}, {"id": 176189, "from_id": 1093036, "to_id": 1093037, "type": "USED-FOR"}, {"id": 176190, "from_id": 1093032, "to_id": 1093029, "type": "COREF"}, {"id": 176191, "from_id": 1093030, "to_id": 1093031, "type": "USED-FOR"}, {"id": 176192, "from_id": 1093044, "to_id": 1093043, "type": "COREF"}]}
{"id": "P05-1069", "text": " In this paper, we present a novel  training method  for a  localized phrase-based prediction model  for  statistical machine translation (SMT)  . The  model  predicts  blocks  with orientation to handle  local phrase re-ordering  . We use a  maximum likelihood criterion  to train a  log-linear block bigram model  which uses  real-valued features  (e.g. a  language model score  ) as well as  binary features  based on the  block  identities themselves, e.g. block bigram features. Our  training algorithm  can easily handle millions of  features  . The best system obtains a 18.6% improvement over the  baseline  on a standard  Arabic-English translation task  . ", "Comments": [], "entities": [{"id": 1093066, "label": "ENT", "start_offset": 36, "end_offset": 51}, {"id": 1093067, "label": "ENT", "start_offset": 60, "end_offset": 99}, {"id": 1093068, "label": "ENT", "start_offset": 106, "end_offset": 143}, {"id": 1093069, "label": "ENT", "start_offset": 152, "end_offset": 157}, {"id": 1093070, "label": "ENT", "start_offset": 205, "end_offset": 229}, {"id": 1093071, "label": "ENT", "start_offset": 243, "end_offset": 271}, {"id": 1093072, "label": "ENT", "start_offset": 285, "end_offset": 314}, {"id": 1093073, "label": "ENT", "start_offset": 328, "end_offset": 348}, {"id": 1093074, "label": "ENT", "start_offset": 359, "end_offset": 379}, {"id": 1093075, "label": "ENT", "start_offset": 395, "end_offset": 410}, {"id": 1093076, "label": "ENT", "start_offset": 489, "end_offset": 507}, {"id": 1093077, "label": "ENT", "start_offset": 540, "end_offset": 548}, {"id": 1093078, "label": "ENT", "start_offset": 561, "end_offset": 567}, {"id": 1093079, "label": "ENT", "start_offset": 606, "end_offset": 614}, {"id": 1093080, "label": "ENT", "start_offset": 631, "end_offset": 662}], "relations": [{"id": 176219, "from_id": 1093067, "to_id": 1093068, "type": "USED-FOR"}, {"id": 176220, "from_id": 1093073, "to_id": 1093072, "type": "USED-FOR"}, {"id": 176221, "from_id": 1093066, "to_id": 1093067, "type": "USED-FOR"}, {"id": 176222, "from_id": 1093067, "to_id": 1093069, "type": "COREF"}, {"id": 176223, "from_id": 1093069, "to_id": 1093070, "type": "USED-FOR"}, {"id": 176224, "from_id": 1093074, "to_id": 1093073, "type": "HYPONYM-OF"}, {"id": 176225, "from_id": 1093071, "to_id": 1093072, "type": "USED-FOR"}, {"id": 176226, "from_id": 1093076, "to_id": 1093066, "type": "COREF"}, {"id": 176227, "from_id": 1093077, "to_id": 1093076, "type": "USED-FOR"}, {"id": 176228, "from_id": 1093078, "to_id": 1093079, "type": "COMPARE"}, {"id": 176229, "from_id": 1093080, "to_id": 1093079, "type": "EVALUATE-FOR"}, {"id": 176230, "from_id": 1093080, "to_id": 1093078, "type": "EVALUATE-FOR"}, {"id": 176231, "from_id": 1093075, "to_id": 1093072, "type": "USED-FOR"}, {"id": 176232, "from_id": 1093073, "to_id": 1093075, "type": "CONJUNCTION"}]}
{"id": "CVPR_2013_10_abs", "text": "We present a novel algorithm for estimating the broad 3D geometric structure of outdoor video scenes. Leveraging spatio-temporal video segmentation, we decompose a dynamic scene captured by a video into geometric classes, based on predictions made by region-classifiers that are trained on appearance and motion features. By examining the homogeneity of the prediction, we combine predictions across multiple segmentation hierarchy levels alleviating the need to determine the granularity a priori. We built a novel, extensive dataset on geometric context of video to evaluate our method, consisting of over 100 ground-truth annotated outdoor videos with over 20,000 frames. To further scale beyond this dataset, we propose a semi-supervised learning framework to expand the pool of labeled data with high confidence predictions obtained from unlabeled data. Our system produces an accurate prediction of geometric context of video achieving 96% accuracy across main geometric classes.", "Comments": [], "entities": [{"id": 1093124, "label": "ENT", "start_offset": 19, "end_offset": 28}, {"id": 1093125, "label": "ENT", "start_offset": 54, "end_offset": 100}, {"id": 1093126, "label": "ENT", "start_offset": 113, "end_offset": 147}, {"id": 1093127, "label": "ENT", "start_offset": 164, "end_offset": 177}, {"id": 1093128, "label": "ENT", "start_offset": 203, "end_offset": 220}, {"id": 1093129, "label": "ENT", "start_offset": 251, "end_offset": 269}, {"id": 1093130, "label": "ENT", "start_offset": 290, "end_offset": 320}, {"id": 1093131, "label": "ENT", "start_offset": 409, "end_offset": 438}, {"id": 1093132, "label": "ENT", "start_offset": 477, "end_offset": 497}, {"id": 1093133, "label": "ENT", "start_offset": 527, "end_offset": 534}, {"id": 1093134, "label": "ENT", "start_offset": 538, "end_offset": 564}, {"id": 1093135, "label": "ENT", "start_offset": 581, "end_offset": 587}, {"id": 1093136, "label": "ENT", "start_offset": 625, "end_offset": 649}, {"id": 1093137, "label": "ENT", "start_offset": 704, "end_offset": 711}, {"id": 1093138, "label": "ENT", "start_offset": 726, "end_offset": 760}, {"id": 1093139, "label": "ENT", "start_offset": 783, "end_offset": 795}, {"id": 1093140, "label": "ENT", "start_offset": 801, "end_offset": 828}, {"id": 1093141, "label": "ENT", "start_offset": 843, "end_offset": 857}, {"id": 1093142, "label": "ENT", "start_offset": 863, "end_offset": 869}, {"id": 1093143, "label": "ENT", "start_offset": 905, "end_offset": 931}, {"id": 1093144, "label": "ENT", "start_offset": 946, "end_offset": 954}], "relations": [{"id": 176266, "from_id": 1093124, "to_id": 1093125, "type": "USED-FOR"}, {"id": 176267, "from_id": 1093129, "to_id": 1093128, "type": "USED-FOR"}, {"id": 176268, "from_id": 1093126, "to_id": 1093127, "type": "USED-FOR"}, {"id": 176269, "from_id": 1093136, "to_id": 1093133, "type": "PART-OF"}, {"id": 176270, "from_id": 1093138, "to_id": 1093139, "type": "USED-FOR"}, {"id": 176271, "from_id": 1093130, "to_id": 1093129, "type": "USED-FOR"}, {"id": 176272, "from_id": 1093133, "to_id": 1093135, "type": "EVALUATE-FOR"}, {"id": 176273, "from_id": 1093135, "to_id": 1093124, "type": "COREF"}, {"id": 176274, "from_id": 1093141, "to_id": 1093140, "type": "USED-FOR"}, {"id": 176275, "from_id": 1093140, "to_id": 1093138, "type": "USED-FOR"}, {"id": 176276, "from_id": 1093144, "to_id": 1093142, "type": "EVALUATE-FOR"}, {"id": 176277, "from_id": 1093142, "to_id": 1093143, "type": "USED-FOR"}, {"id": 176278, "from_id": 1093128, "to_id": 1093127, "type": "PART-OF"}, {"id": 176279, "from_id": 1093135, "to_id": 1093142, "type": "COREF"}, {"id": 176280, "from_id": 1093134, "to_id": 1093133, "type": "FEATURE-OF"}, {"id": 176281, "from_id": 1093133, "to_id": 1093137, "type": "COREF"}]}
{"id": "L08-1050", "text": " The present paper reports on a preparatory research for building a  language corpus annotation scenario  capturing the  discourse relations  in  Czech . We primarily focus on the description of the  syntactically motivated relations  in  discourse , basing our findings on the theoretical background of the  Prague Dependency Treebank 2.0  and the  Penn Discourse Treebank 2 . Our aim is to revisit the present-day  syntactico-semantic (tectogrammatical) annotation  in the  Prague Dependency Treebank , extend it for the purposes of a  sentence-boundary-crossing representation  and eventually to design a new,  discourse level  of  annotation . In this paper, we propose a feasible process of such a transfer, comparing the possibilities the  Praguian dependency-based approach  offers with the  Penn discourse annotation  based primarily on the analysis and classification of  discourse connectives . ", "Comments": [], "entities": [{"id": 1093145, "label": "ENT", "start_offset": 69, "end_offset": 104}, {"id": 1093146, "label": "ENT", "start_offset": 121, "end_offset": 140}, {"id": 1093147, "label": "ENT", "start_offset": 146, "end_offset": 151}, {"id": 1093148, "label": "ENT", "start_offset": 200, "end_offset": 248}, {"id": 1093149, "label": "ENT", "start_offset": 309, "end_offset": 339}, {"id": 1093150, "label": "ENT", "start_offset": 350, "end_offset": 375}, {"id": 1093151, "label": "ENT", "start_offset": 417, "end_offset": 466}, {"id": 1093152, "label": "ENT", "start_offset": 476, "end_offset": 502}, {"id": 1093153, "label": "ENT", "start_offset": 512, "end_offset": 514}, {"id": 1093154, "label": "ENT", "start_offset": 538, "end_offset": 579}, {"id": 1093155, "label": "ENT", "start_offset": 614, "end_offset": 645}, {"id": 1093156, "label": "ENT", "start_offset": 746, "end_offset": 780}, {"id": 1093157, "label": "ENT", "start_offset": 799, "end_offset": 824}, {"id": 1093158, "label": "ENT", "start_offset": 849, "end_offset": 902}], "relations": [{"id": 176282, "from_id": 1093149, "to_id": 1093150, "type": "CONJUNCTION"}, {"id": 176283, "from_id": 1093151, "to_id": 1093153, "type": "COREF"}, {"id": 176284, "from_id": 1093153, "to_id": 1093154, "type": "USED-FOR"}, {"id": 176285, "from_id": 1093149, "to_id": 1093148, "type": "USED-FOR"}, {"id": 176286, "from_id": 1093150, "to_id": 1093148, "type": "USED-FOR"}, {"id": 176287, "from_id": 1093151, "to_id": 1093152, "type": "PART-OF"}, {"id": 176288, "from_id": 1093153, "to_id": 1093155, "type": "USED-FOR"}, {"id": 176289, "from_id": 1093158, "to_id": 1093157, "type": "EVALUATE-FOR"}, {"id": 176290, "from_id": 1093157, "to_id": 1093156, "type": "COMPARE"}, {"id": 176291, "from_id": 1093147, "to_id": 1093146, "type": "FEATURE-OF"}, {"id": 176292, "from_id": 1093145, "to_id": 1093146, "type": "USED-FOR"}, {"id": 176293, "from_id": 1093158, "to_id": 1093156, "type": "EVALUATE-FOR"}]}
{"id": "H05-1115", "text": " We consider the problem of  question-focused sentence retrieval  from complex  news articles  describing  multi-event stories published over time .  Annotators  generated a list of  questions  central to understanding each  story  in our  corpus . Because of the dynamic nature of the  stories , many  questions  are time-sensitive (e.g. \"How many victims have been found?\").  Judges  found  sentences  providing an  answer  to each  question . To address the  sentence retrieval problem , we apply a  stochastic, graph-based method  for comparing the relative importance of the  textual units , which was previously used successfully for  generic summarization . Currently, we present a topic-sensitive version of our  method  and hypothesize that it can outperform a competitive  baseline , which compares the  similarity  of each  sentence  to the input  question  via  IDF-weighted word overlap . In our experiments, the  method  achieves a  TRDR score  that is significantly higher than that of the  baseline . ", "Comments": [], "entities": [{"id": 1093221, "label": "ENT", "start_offset": 29, "end_offset": 64}, {"id": 1093222, "label": "ENT", "start_offset": 80, "end_offset": 93}, {"id": 1093223, "label": "ENT", "start_offset": 107, "end_offset": 126}, {"id": 1093224, "label": "ENT", "start_offset": 462, "end_offset": 488}, {"id": 1093225, "label": "ENT", "start_offset": 503, "end_offset": 533}, {"id": 1093226, "label": "ENT", "start_offset": 641, "end_offset": 662}, {"id": 1093227, "label": "ENT", "start_offset": 721, "end_offset": 727}, {"id": 1093228, "label": "ENT", "start_offset": 750, "end_offset": 752}, {"id": 1093229, "label": "ENT", "start_offset": 783, "end_offset": 791}, {"id": 1093230, "label": "ENT", "start_offset": 874, "end_offset": 899}, {"id": 1093231, "label": "ENT", "start_offset": 927, "end_offset": 933}, {"id": 1093232, "label": "ENT", "start_offset": 947, "end_offset": 957}, {"id": 1093233, "label": "ENT", "start_offset": 1006, "end_offset": 1014}], "relations": [{"id": 176354, "from_id": 1093222, "to_id": 1093221, "type": "USED-FOR"}, {"id": 176355, "from_id": 1093225, "to_id": 1093224, "type": "USED-FOR"}, {"id": 176356, "from_id": 1093223, "to_id": 1093222, "type": "FEATURE-OF"}, {"id": 176357, "from_id": 1093224, "to_id": 1093221, "type": "COREF"}, {"id": 176358, "from_id": 1093225, "to_id": 1093226, "type": "USED-FOR"}, {"id": 176359, "from_id": 1093227, "to_id": 1093225, "type": "COREF"}, {"id": 176360, "from_id": 1093231, "to_id": 1093227, "type": "COREF"}, {"id": 176361, "from_id": 1093233, "to_id": 1093229, "type": "COREF"}, {"id": 176362, "from_id": 1093232, "to_id": 1093231, "type": "EVALUATE-FOR"}, {"id": 176363, "from_id": 1093232, "to_id": 1093233, "type": "EVALUATE-FOR"}, {"id": 176364, "from_id": 1093228, "to_id": 1093227, "type": "COREF"}, {"id": 176365, "from_id": 1093229, "to_id": 1093228, "type": "COMPARE"}, {"id": 176366, "from_id": 1093231, "to_id": 1093233, "type": "COMPARE"}]}
{"id": "I05-2048", "text": "  Statistical machine translation (SMT)  is currently one of the hot spots in  natural language processing  . Over the last few years dramatic improvements have been made, and a number of comparative evaluations have shown, that  SMT  gives competitive results to  rule-based translation systems  , requiring significantly less development time. This is particularly important when building  translation systems  for new  language pairs  or new  domains  . This workshop is intended to give an introduction to  statistical machine translation  with a focus on practical considerations. Participants should be able, after attending this workshop, to set out building an  SMT system  themselves and achieving good  baseline results  in a short time. The tutorial will cover the basics of  SMT  : Theory will be put into practice.  STTK  , a  statistical machine translation tool kit  , will be introduced and used to build a working  translation system  .  STTK  has been developed by the presenter and co-workers over a number of years and is currently used as the basis of  CMU's SMT system  . It has also successfully been coupled with  rule-based and example based machine translation modules  to build a  multi engine machine translation system  . The  source code  of the  tool kit  will be made available. ", "Comments": [], "entities": [{"id": 1093262, "label": "ENT", "start_offset": 2, "end_offset": 39}, {"id": 1093263, "label": "ENT", "start_offset": 79, "end_offset": 106}, {"id": 1093264, "label": "ENT", "start_offset": 230, "end_offset": 233}, {"id": 1093265, "label": "ENT", "start_offset": 265, "end_offset": 295}, {"id": 1093266, "label": "ENT", "start_offset": 392, "end_offset": 411}, {"id": 1093267, "label": "ENT", "start_offset": 417, "end_offset": 436}, {"id": 1093268, "label": "ENT", "start_offset": 441, "end_offset": 453}, {"id": 1093269, "label": "ENT", "start_offset": 511, "end_offset": 542}, {"id": 1093270, "label": "ENT", "start_offset": 670, "end_offset": 680}, {"id": 1093271, "label": "ENT", "start_offset": 787, "end_offset": 790}, {"id": 1093272, "label": "ENT", "start_offset": 829, "end_offset": 833}, {"id": 1093273, "label": "ENT", "start_offset": 840, "end_offset": 880}, {"id": 1093274, "label": "ENT", "start_offset": 932, "end_offset": 950}, {"id": 1093275, "label": "ENT", "start_offset": 955, "end_offset": 959}, {"id": 1093276, "label": "ENT", "start_offset": 1080, "end_offset": 1090}, {"id": 1093277, "label": "ENT", "start_offset": 1094, "end_offset": 1096}, {"id": 1093278, "label": "ENT", "start_offset": 1138, "end_offset": 1194}, {"id": 1093279, "label": "ENT", "start_offset": 1208, "end_offset": 1247}, {"id": 1093280, "label": "ENT", "start_offset": 1277, "end_offset": 1285}], "relations": [{"id": 176389, "from_id": 1093264, "to_id": 1093265, "type": "COMPARE"}, {"id": 176390, "from_id": 1093262, "to_id": 1093263, "type": "HYPONYM-OF"}, {"id": 176391, "from_id": 1093264, "to_id": 1093262, "type": "COREF"}, {"id": 176392, "from_id": 1093269, "to_id": 1093264, "type": "COREF"}, {"id": 176393, "from_id": 1093270, "to_id": 1093269, "type": "COREF"}, {"id": 176394, "from_id": 1093271, "to_id": 1093269, "type": "COREF"}, {"id": 176395, "from_id": 1093272, "to_id": 1093273, "type": "HYPONYM-OF"}, {"id": 176396, "from_id": 1093272, "to_id": 1093274, "type": "USED-FOR"}, {"id": 176397, "from_id": 1093274, "to_id": 1093266, "type": "COREF"}, {"id": 176398, "from_id": 1093275, "to_id": 1093272, "type": "COREF"}, {"id": 176399, "from_id": 1093275, "to_id": 1093276, "type": "USED-FOR"}, {"id": 176400, "from_id": 1093277, "to_id": 1093275, "type": "COREF"}, {"id": 176401, "from_id": 1093277, "to_id": 1093278, "type": "CONJUNCTION"}, {"id": 176402, "from_id": 1093278, "to_id": 1093279, "type": "USED-FOR"}, {"id": 176403, "from_id": 1093277, "to_id": 1093279, "type": "USED-FOR"}, {"id": 176404, "from_id": 1093280, "to_id": 1093275, "type": "COREF"}, {"id": 176405, "from_id": 1093265, "to_id": 1093278, "type": "HYPONYM-OF"}, {"id": 176406, "from_id": 1093266, "to_id": 1093267, "type": "USED-FOR"}, {"id": 176407, "from_id": 1093266, "to_id": 1093268, "type": "USED-FOR"}, {"id": 176408, "from_id": 1093267, "to_id": 1093268, "type": "CONJUNCTION"}]}
{"id": "H91-1010", "text": " The following describes recent work on the  Lincoln CSR system . Some new variations in  semiphone modeling  have been tested. A very simple improved  duration model  has reduced the  error rate  by about 10% in both  triphone and semiphone systems . A new  training strategy  has been tested which, by itself, did not provide useful improvements but suggests that improvements can be obtained by a related rapid adaptation technique. Finally, the  recognizer  has been modified to use  bigram back-off language models . The system was then transferred from the  RM task  to the  ATIS CSR task  and a limited number of development tests performed. Evaluation test results are presented for both the  RM and ATIS CSR tasks . ", "Comments": [], "entities": [{"id": 1093506, "label": "ENT", "start_offset": 45, "end_offset": 63}, {"id": 1093507, "label": "ENT", "start_offset": 90, "end_offset": 108}, {"id": 1093508, "label": "ENT", "start_offset": 152, "end_offset": 166}, {"id": 1093509, "label": "ENT", "start_offset": 185, "end_offset": 195}, {"id": 1093510, "label": "ENT", "start_offset": 219, "end_offset": 249}, {"id": 1093511, "label": "ENT", "start_offset": 259, "end_offset": 276}, {"id": 1093512, "label": "ENT", "start_offset": 408, "end_offset": 434}, {"id": 1093513, "label": "ENT", "start_offset": 450, "end_offset": 460}, {"id": 1093514, "label": "ENT", "start_offset": 488, "end_offset": 519}, {"id": 1093515, "label": "ENT", "start_offset": 526, "end_offset": 532}, {"id": 1093516, "label": "ENT", "start_offset": 564, "end_offset": 571}, {"id": 1093517, "label": "ENT", "start_offset": 581, "end_offset": 594}, {"id": 1093518, "label": "ENT", "start_offset": 701, "end_offset": 722}], "relations": [{"id": 176608, "from_id": 1093514, "to_id": 1093513, "type": "USED-FOR"}, {"id": 176609, "from_id": 1093508, "to_id": 1093510, "type": "USED-FOR"}, {"id": 176610, "from_id": 1093507, "to_id": 1093510, "type": "HYPONYM-OF"}, {"id": 176611, "from_id": 1093516, "to_id": 1093518, "type": "HYPONYM-OF"}, {"id": 176612, "from_id": 1093517, "to_id": 1093518, "type": "HYPONYM-OF"}, {"id": 176613, "from_id": 1093515, "to_id": 1093516, "type": "USED-FOR"}, {"id": 176614, "from_id": 1093515, "to_id": 1093517, "type": "USED-FOR"}, {"id": 176615, "from_id": 1093516, "to_id": 1093517, "type": "CONJUNCTION"}, {"id": 176616, "from_id": 1093509, "to_id": 1093510, "type": "EVALUATE-FOR"}, {"id": 176617, "from_id": 1093506, "to_id": 1093515, "type": "COREF"}, {"id": 176618, "from_id": 1093512, "to_id": 1093511, "type": "USED-FOR"}]}
{"id": "C04-1096", "text": " Past work of generating  referring expressions  mainly utilized attributes of  objects  and  binary relations  between  objects . However, such an approach does not work well when there is no distinctive attribute among  objects . To overcome this limitation, this paper proposes a method utilizing the perceptual groups of  objects  and  n-ary relations  among them. The key is to identify groups of  objects  that are naturally recognized by humans. We conducted psychological experiments with 42 subjects to collect  referring expressions  in such situations, and built a  generation algorithm  based on the results. The evaluation using another 23 subjects showed that the proposed method could effectively generate proper referring expressions. ", "Comments": [], "entities": [{"id": 1093519, "label": "ENT", "start_offset": 26, "end_offset": 47}, {"id": 1093520, "label": "ENT", "start_offset": 94, "end_offset": 110}, {"id": 1093521, "label": "ENT", "start_offset": 340, "end_offset": 355}, {"id": 1093522, "label": "ENT", "start_offset": 521, "end_offset": 542}, {"id": 1093523, "label": "ENT", "start_offset": 577, "end_offset": 597}, {"id": 1093524, "label": "ENT", "start_offset": 687, "end_offset": 693}, {"id": 1093525, "label": "ENT", "start_offset": 728, "end_offset": 749}], "relations": [{"id": 176619, "from_id": 1093524, "to_id": 1093523, "type": "COREF"}]}
{"id": "NIPS_2015_21_abs", "text": "Despite their success, convolutional neural networks are computationally expensive because they must examine all image locations. Stochastic attention-based models have been shown to improve computational efficiency at test time, but they remain difficult to train because of intractable posterior inference and high variance in the stochastic gradient estimates. Borrowing techniques from the literature on training deep generative models, we present the Wake-Sleep Recurrent Attention Model, a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients. We show that our method can greatly speed up the training time for stochastic attention networks in the domains of image classification and caption generation.", "Comments": [], "entities": [{"id": 1093692, "label": "ENT", "start_offset": 23, "end_offset": 52}, {"id": 1093693, "label": "ENT", "start_offset": 91, "end_offset": 95}, {"id": 1093694, "label": "ENT", "start_offset": 130, "end_offset": 163}, {"id": 1093695, "label": "ENT", "start_offset": 191, "end_offset": 215}, {"id": 1093696, "label": "ENT", "start_offset": 234, "end_offset": 238}, {"id": 1093697, "label": "ENT", "start_offset": 276, "end_offset": 307}, {"id": 1093698, "label": "ENT", "start_offset": 333, "end_offset": 362}, {"id": 1093699, "label": "ENT", "start_offset": 364, "end_offset": 384}, {"id": 1093700, "label": "ENT", "start_offset": 417, "end_offset": 439}, {"id": 1093701, "label": "ENT", "start_offset": 456, "end_offset": 492}, {"id": 1093702, "label": "ENT", "start_offset": 496, "end_offset": 502}, {"id": 1093703, "label": "ENT", "start_offset": 516, "end_offset": 545}, {"id": 1093704, "label": "ENT", "start_offset": 561, "end_offset": 580}, {"id": 1093705, "label": "ENT", "start_offset": 622, "end_offset": 642}, {"id": 1093706, "label": "ENT", "start_offset": 661, "end_offset": 667}, {"id": 1093707, "label": "ENT", "start_offset": 693, "end_offset": 706}, {"id": 1093708, "label": "ENT", "start_offset": 711, "end_offset": 740}, {"id": 1093709, "label": "ENT", "start_offset": 759, "end_offset": 779}, {"id": 1093710, "label": "ENT", "start_offset": 784, "end_offset": 802}], "relations": [{"id": 176765, "from_id": 1093695, "to_id": 1093694, "type": "EVALUATE-FOR"}, {"id": 176766, "from_id": 1093701, "to_id": 1093702, "type": "COREF"}, {"id": 176767, "from_id": 1093699, "to_id": 1093700, "type": "USED-FOR"}, {"id": 176768, "from_id": 1093702, "to_id": 1093703, "type": "USED-FOR"}, {"id": 176769, "from_id": 1093703, "to_id": 1093704, "type": "USED-FOR"}, {"id": 176770, "from_id": 1093701, "to_id": 1093706, "type": "COREF"}, {"id": 176771, "from_id": 1093709, "to_id": 1093706, "type": "EVALUATE-FOR"}, {"id": 176772, "from_id": 1093710, "to_id": 1093706, "type": "EVALUATE-FOR"}, {"id": 176773, "from_id": 1093709, "to_id": 1093710, "type": "CONJUNCTION"}, {"id": 176774, "from_id": 1093697, "to_id": 1093698, "type": "CONJUNCTION"}, {"id": 176775, "from_id": 1093694, "to_id": 1093696, "type": "COREF"}, {"id": 176776, "from_id": 1093692, "to_id": 1093693, "type": "COREF"}, {"id": 176777, "from_id": 1093694, "to_id": 1093703, "type": "COREF"}, {"id": 176778, "from_id": 1093708, "to_id": 1093703, "type": "COREF"}, {"id": 176779, "from_id": 1093707, "to_id": 1093708, "type": "FEATURE-OF"}, {"id": 176780, "from_id": 1093707, "to_id": 1093706, "type": "EVALUATE-FOR"}]}
{"id": "I05-6011", "text": " This paper proposes an  annotating scheme  that encodes  honorifics  (respectful words).  Honorifics  are used extensively in  Japanese  , reflecting the social relationship (e.g. social ranks and age) of the  referents  . This  referential information  is vital for resolving  zero pronouns  and improving  machine translation outputs  . Annotating  honorifics  is a complex task that involves identifying a  predicate  with  honorifics  , assigning  ranks  to  referents  of the  predicate  , calibrating the  ranks  , and connecting  referents  with their  predicates  . ", "Comments": [], "entities": [{"id": 1093751, "label": "ENT", "start_offset": 25, "end_offset": 42}, {"id": 1093752, "label": "ENT", "start_offset": 58, "end_offset": 68}, {"id": 1093753, "label": "ENT", "start_offset": 71, "end_offset": 87}, {"id": 1093754, "label": "ENT", "start_offset": 91, "end_offset": 101}, {"id": 1093755, "label": "ENT", "start_offset": 128, "end_offset": 136}, {"id": 1093756, "label": "ENT", "start_offset": 230, "end_offset": 253}, {"id": 1093757, "label": "ENT", "start_offset": 279, "end_offset": 292}, {"id": 1093758, "label": "ENT", "start_offset": 309, "end_offset": 336}, {"id": 1093759, "label": "ENT", "start_offset": 352, "end_offset": 362}, {"id": 1093760, "label": "ENT", "start_offset": 428, "end_offset": 438}, {"id": 1093761, "label": "ENT", "start_offset": 453, "end_offset": 458}, {"id": 1093762, "label": "ENT", "start_offset": 513, "end_offset": 518}], "relations": [{"id": 176821, "from_id": 1093751, "to_id": 1093752, "type": "USED-FOR"}, {"id": 176822, "from_id": 1093752, "to_id": 1093753, "type": "HYPONYM-OF"}, {"id": 176823, "from_id": 1093754, "to_id": 1093755, "type": "USED-FOR"}, {"id": 176824, "from_id": 1093754, "to_id": 1093752, "type": "COREF"}, {"id": 176825, "from_id": 1093756, "to_id": 1093757, "type": "USED-FOR"}, {"id": 176826, "from_id": 1093756, "to_id": 1093758, "type": "USED-FOR"}, {"id": 176827, "from_id": 1093759, "to_id": 1093754, "type": "COREF"}, {"id": 176828, "from_id": 1093760, "to_id": 1093759, "type": "COREF"}, {"id": 176829, "from_id": 1093762, "to_id": 1093761, "type": "COREF"}]}
{"id": "E91-1012", "text": " A purely functional implementation of  LR-parsers  is given, together with a simple  correctness proof . It is presented as a generalization of the  recursive descent parser . For  non-LR grammars  the time-complexity of our  parser  is cubic if the functions that constitute the  parser  are implemented as  memo-functions , i.e. functions that memorize the results of previous invocations.  Memo-functions  also facilitate a simple way to construct a very compact representation of the  parse forest . For  LR(0) grammars , our algorithm is closely related to the  recursive ascent parsers  recently discovered by Kruse-man Aretz [1] and Roberts [2].  Extended CF grammars  ( grammars  with  regular expressions  at the right hand side) can be parsed with a simple modification of the  LR-parser  for normal  CF grammars . ", "Comments": [], "entities": [{"id": 1093771, "label": "ENT", "start_offset": 40, "end_offset": 50}, {"id": 1093772, "label": "ENT", "start_offset": 86, "end_offset": 103}, {"id": 1093773, "label": "ENT", "start_offset": 106, "end_offset": 108}, {"id": 1093774, "label": "ENT", "start_offset": 150, "end_offset": 174}, {"id": 1093775, "label": "ENT", "start_offset": 182, "end_offset": 197}, {"id": 1093776, "label": "ENT", "start_offset": 203, "end_offset": 218}, {"id": 1093777, "label": "ENT", "start_offset": 227, "end_offset": 233}, {"id": 1093778, "label": "ENT", "start_offset": 282, "end_offset": 288}, {"id": 1093779, "label": "ENT", "start_offset": 310, "end_offset": 324}, {"id": 1093780, "label": "ENT", "start_offset": 394, "end_offset": 408}, {"id": 1093781, "label": "ENT", "start_offset": 490, "end_offset": 502}, {"id": 1093782, "label": "ENT", "start_offset": 510, "end_offset": 524}, {"id": 1093783, "label": "ENT", "start_offset": 531, "end_offset": 540}, {"id": 1093784, "label": "ENT", "start_offset": 568, "end_offset": 592}, {"id": 1093785, "label": "ENT", "start_offset": 655, "end_offset": 675}, {"id": 1093786, "label": "ENT", "start_offset": 679, "end_offset": 687}, {"id": 1093787, "label": "ENT", "start_offset": 695, "end_offset": 714}, {"id": 1093788, "label": "ENT", "start_offset": 789, "end_offset": 798}, {"id": 1093789, "label": "ENT", "start_offset": 812, "end_offset": 823}], "relations": [{"id": 176832, "from_id": 1093780, "to_id": 1093781, "type": "USED-FOR"}, {"id": 176833, "from_id": 1093788, "to_id": 1093789, "type": "USED-FOR"}, {"id": 176834, "from_id": 1093772, "to_id": 1093771, "type": "CONJUNCTION"}, {"id": 176835, "from_id": 1093778, "to_id": 1093777, "type": "COREF"}, {"id": 176836, "from_id": 1093780, "to_id": 1093779, "type": "COREF"}, {"id": 176837, "from_id": 1093786, "to_id": 1093785, "type": "COREF"}, {"id": 176838, "from_id": 1093787, "to_id": 1093786, "type": "FEATURE-OF"}, {"id": 176839, "from_id": 1093788, "to_id": 1093785, "type": "USED-FOR"}, {"id": 176840, "from_id": 1093779, "to_id": 1093778, "type": "USED-FOR"}, {"id": 176841, "from_id": 1093783, "to_id": 1093778, "type": "COREF"}, {"id": 176842, "from_id": 1093788, "to_id": 1093783, "type": "COREF"}, {"id": 176843, "from_id": 1093771, "to_id": 1093777, "type": "COREF"}, {"id": 176844, "from_id": 1093783, "to_id": 1093784, "type": "CONJUNCTION"}, {"id": 176845, "from_id": 1093771, "to_id": 1093773, "type": "COREF"}, {"id": 176846, "from_id": 1093774, "to_id": 1093773, "type": "USED-FOR"}, {"id": 176847, "from_id": 1093777, "to_id": 1093775, "type": "USED-FOR"}, {"id": 176848, "from_id": 1093783, "to_id": 1093782, "type": "USED-FOR"}, {"id": 176849, "from_id": 1093776, "to_id": 1093777, "type": "EVALUATE-FOR"}]}
{"id": "N04-1024", "text": "  CriterionSM Online Essay Evaluation Service  includes a capability that labels  sentences  in student  writing  with  essay-based discourse elements  (e.g.,  thesis statements  ). We describe a new system that enhances  Criterion  's capability, by evaluating multiple aspects of  coherence  in  essays  . This system identifies  features  of  sentences  based on  semantic similarity measures  and  discourse structure  . A  support vector machine  uses these  features  to capture  breakdowns in coherence  due to relatedness to the  essay question  and relatedness between  discourse elements  .  Intra-sentential quality  is evaluated with  rule-based heuristics  . Results indicate that the system yields higher performance than a  baseline  on all three aspects. ", "Comments": [], "entities": [{"id": 1093825, "label": "ENT", "start_offset": 2, "end_offset": 45}, {"id": 1093826, "label": "ENT", "start_offset": 120, "end_offset": 150}, {"id": 1093827, "label": "ENT", "start_offset": 160, "end_offset": 177}, {"id": 1093828, "label": "ENT", "start_offset": 200, "end_offset": 206}, {"id": 1093829, "label": "ENT", "start_offset": 222, "end_offset": 246}, {"id": 1093830, "label": "ENT", "start_offset": 283, "end_offset": 304}, {"id": 1093831, "label": "ENT", "start_offset": 313, "end_offset": 319}, {"id": 1093832, "label": "ENT", "start_offset": 332, "end_offset": 340}, {"id": 1093833, "label": "ENT", "start_offset": 367, "end_offset": 395}, {"id": 1093834, "label": "ENT", "start_offset": 402, "end_offset": 421}, {"id": 1093835, "label": "ENT", "start_offset": 428, "end_offset": 450}, {"id": 1093836, "label": "ENT", "start_offset": 464, "end_offset": 472}, {"id": 1093837, "label": "ENT", "start_offset": 486, "end_offset": 509}, {"id": 1093838, "label": "ENT", "start_offset": 579, "end_offset": 597}, {"id": 1093839, "label": "ENT", "start_offset": 602, "end_offset": 626}, {"id": 1093840, "label": "ENT", "start_offset": 647, "end_offset": 668}, {"id": 1093841, "label": "ENT", "start_offset": 698, "end_offset": 704}, {"id": 1093842, "label": "ENT", "start_offset": 739, "end_offset": 747}], "relations": [{"id": 176880, "from_id": 1093836, "to_id": 1093835, "type": "USED-FOR"}, {"id": 176881, "from_id": 1093840, "to_id": 1093839, "type": "EVALUATE-FOR"}, {"id": 176882, "from_id": 1093826, "to_id": 1093825, "type": "PART-OF"}, {"id": 176883, "from_id": 1093828, "to_id": 1093829, "type": "USED-FOR"}, {"id": 176884, "from_id": 1093831, "to_id": 1093828, "type": "COREF"}, {"id": 176885, "from_id": 1093831, "to_id": 1093832, "type": "USED-FOR"}, {"id": 176886, "from_id": 1093834, "to_id": 1093833, "type": "CONJUNCTION"}, {"id": 176887, "from_id": 1093841, "to_id": 1093831, "type": "COREF"}, {"id": 176888, "from_id": 1093827, "to_id": 1093826, "type": "HYPONYM-OF"}, {"id": 176889, "from_id": 1093841, "to_id": 1093842, "type": "COMPARE"}, {"id": 176890, "from_id": 1093836, "to_id": 1093832, "type": "COREF"}, {"id": 176891, "from_id": 1093833, "to_id": 1093832, "type": "USED-FOR"}, {"id": 176892, "from_id": 1093834, "to_id": 1093832, "type": "USED-FOR"}, {"id": 176893, "from_id": 1093830, "to_id": 1093828, "type": "EVALUATE-FOR"}, {"id": 176894, "from_id": 1093836, "to_id": 1093837, "type": "USED-FOR"}]}
{"id": "C08-2010", "text": "  Language resource quality  is crucial in  NLP . Many of the resources used are derived from data created by human beings out of an  NLP  context, especially regarding  MT  and  reference translations . Indeed,  automatic evaluations  need  high-quality data  that allow the comparison of both  automatic and human translations . The validation of these resources is widely recommended before being used. This paper describes the impact of using  different-quality references  on  evaluation . Surprisingly enough, similar scores are obtained in many cases regardless of the quality. Thus, the limitations of the  automatic metrics  used within  MT  are also discussed in this regard. ", "Comments": [], "entities": [{"id": 1093879, "label": "ENT", "start_offset": 2, "end_offset": 27}, {"id": 1093880, "label": "ENT", "start_offset": 44, "end_offset": 47}, {"id": 1093881, "label": "ENT", "start_offset": 134, "end_offset": 137}, {"id": 1093882, "label": "ENT", "start_offset": 170, "end_offset": 172}, {"id": 1093883, "label": "ENT", "start_offset": 179, "end_offset": 201}, {"id": 1093884, "label": "ENT", "start_offset": 213, "end_offset": 234}, {"id": 1093885, "label": "ENT", "start_offset": 242, "end_offset": 259}, {"id": 1093886, "label": "ENT", "start_offset": 355, "end_offset": 364}, {"id": 1093887, "label": "ENT", "start_offset": 448, "end_offset": 476}, {"id": 1093888, "label": "ENT", "start_offset": 482, "end_offset": 492}, {"id": 1093889, "label": "ENT", "start_offset": 615, "end_offset": 632}, {"id": 1093890, "label": "ENT", "start_offset": 647, "end_offset": 649}], "relations": [{"id": 176922, "from_id": 1093885, "to_id": 1093884, "type": "EVALUATE-FOR"}, {"id": 176923, "from_id": 1093889, "to_id": 1093890, "type": "EVALUATE-FOR"}, {"id": 176924, "from_id": 1093888, "to_id": 1093884, "type": "COREF"}, {"id": 176925, "from_id": 1093882, "to_id": 1093881, "type": "HYPONYM-OF"}, {"id": 176926, "from_id": 1093883, "to_id": 1093881, "type": "HYPONYM-OF"}, {"id": 176927, "from_id": 1093890, "to_id": 1093882, "type": "COREF"}, {"id": 176928, "from_id": 1093881, "to_id": 1093880, "type": "COREF"}, {"id": 176929, "from_id": 1093886, "to_id": 1093885, "type": "COREF"}, {"id": 176930, "from_id": 1093882, "to_id": 1093883, "type": "CONJUNCTION"}, {"id": 176931, "from_id": 1093887, "to_id": 1093888, "type": "USED-FOR"}, {"id": 176932, "from_id": 1093879, "to_id": 1093880, "type": "FEATURE-OF"}]}
{"id": "CVPR_2011_18_abs", "text": "We present a method for estimating the relative pose of two calibrated or uncalibrated non-overlapping surveillance cameras from observing a moving object. We show how to tackle the problem of missing point correspondences heavily required by SfM pipelines and how to go beyond this basic paradigm. We relax the non-linear nature of the problem by accepting two assumptions which surveillance scenarios offer, ie. the presence of a moving object and easily estimable gravity vector. By those assumptions we cast the problem as a Quadratic Eigenvalue Problem offering an elegant way of treating nonlinear monomials and delivering a quasi closed-form solution as a reliable starting point for a further bundle adjustment. We are the first to bring the closed form solution to such a very practical problem arising in video surveillance. Results in different camera setups demonstrate the feasibility of the approach.", "Comments": [], "entities": [{"id": 1093923, "label": "ENT", "start_offset": 13, "end_offset": 19}, {"id": 1093924, "label": "ENT", "start_offset": 39, "end_offset": 123}, {"id": 1093925, "label": "ENT", "start_offset": 193, "end_offset": 222}, {"id": 1093926, "label": "ENT", "start_offset": 243, "end_offset": 256}, {"id": 1093927, "label": "ENT", "start_offset": 289, "end_offset": 297}, {"id": 1093928, "label": "ENT", "start_offset": 312, "end_offset": 329}, {"id": 1093929, "label": "ENT", "start_offset": 337, "end_offset": 344}, {"id": 1093930, "label": "ENT", "start_offset": 362, "end_offset": 373}, {"id": 1093931, "label": "ENT", "start_offset": 380, "end_offset": 402}, {"id": 1093932, "label": "ENT", "start_offset": 467, "end_offset": 481}, {"id": 1093933, "label": "ENT", "start_offset": 492, "end_offset": 503}, {"id": 1093934, "label": "ENT", "start_offset": 516, "end_offset": 523}, {"id": 1093935, "label": "ENT", "start_offset": 529, "end_offset": 557}, {"id": 1093936, "label": "ENT", "start_offset": 594, "end_offset": 613}, {"id": 1093937, "label": "ENT", "start_offset": 631, "end_offset": 657}, {"id": 1093938, "label": "ENT", "start_offset": 701, "end_offset": 718}, {"id": 1093939, "label": "ENT", "start_offset": 750, "end_offset": 770}, {"id": 1093940, "label": "ENT", "start_offset": 796, "end_offset": 803}, {"id": 1093941, "label": "ENT", "start_offset": 815, "end_offset": 833}, {"id": 1093942, "label": "ENT", "start_offset": 905, "end_offset": 913}], "relations": [{"id": 176954, "from_id": 1093926, "to_id": 1093925, "type": "USED-FOR"}, {"id": 176955, "from_id": 1093927, "to_id": 1093926, "type": "COREF"}, {"id": 176956, "from_id": 1093929, "to_id": 1093925, "type": "COREF"}, {"id": 176957, "from_id": 1093928, "to_id": 1093929, "type": "FEATURE-OF"}, {"id": 176958, "from_id": 1093933, "to_id": 1093930, "type": "COREF"}, {"id": 176959, "from_id": 1093934, "to_id": 1093929, "type": "COREF"}, {"id": 176960, "from_id": 1093935, "to_id": 1093934, "type": "USED-FOR"}, {"id": 176961, "from_id": 1093935, "to_id": 1093936, "type": "USED-FOR"}, {"id": 176962, "from_id": 1093935, "to_id": 1093937, "type": "USED-FOR"}, {"id": 176963, "from_id": 1093937, "to_id": 1093938, "type": "USED-FOR"}, {"id": 176964, "from_id": 1093940, "to_id": 1093934, "type": "COREF"}, {"id": 176965, "from_id": 1093939, "to_id": 1093940, "type": "USED-FOR"}, {"id": 176966, "from_id": 1093941, "to_id": 1093940, "type": "FEATURE-OF"}, {"id": 176967, "from_id": 1093939, "to_id": 1093937, "type": "COREF"}, {"id": 176968, "from_id": 1093923, "to_id": 1093924, "type": "USED-FOR"}, {"id": 176969, "from_id": 1093942, "to_id": 1093923, "type": "COREF"}, {"id": 176970, "from_id": 1093942, "to_id": 1093939, "type": "COREF"}]}
{"id": "C92-2068", "text": "    Graph unification  remains the most expensive part of  unification-based grammar parsing  . We focus on one speed-up element in the design of  unification algorithms  : avoidance of  copying  of  unmodified subgraphs  . We propose a method of attaining such a design through a method of  structure-sharing  which avoids  log(d) overheads  often associated with  structure-sharing of graphs  without any use of costly  dependency pointers  . The proposed scheme eliminates  redundant copying  while maintaining the  quasi-destructive scheme's ability  to avoid  over copying  and  early copying  combined with its ability to handle  cyclic structures  without algorithmic additions. ", "Comments": [], "entities": [{"id": 1093943, "label": "ENT", "start_offset": 4, "end_offset": 21}, {"id": 1093944, "label": "ENT", "start_offset": 59, "end_offset": 92}, {"id": 1093945, "label": "ENT", "start_offset": 112, "end_offset": 128}, {"id": 1093946, "label": "ENT", "start_offset": 147, "end_offset": 169}, {"id": 1093947, "label": "ENT", "start_offset": 187, "end_offset": 220}, {"id": 1093948, "label": "ENT", "start_offset": 237, "end_offset": 243}, {"id": 1093949, "label": "ENT", "start_offset": 292, "end_offset": 309}, {"id": 1093950, "label": "ENT", "start_offset": 325, "end_offset": 341}, {"id": 1093951, "label": "ENT", "start_offset": 366, "end_offset": 393}, {"id": 1093952, "label": "ENT", "start_offset": 422, "end_offset": 441}, {"id": 1093953, "label": "ENT", "start_offset": 458, "end_offset": 464}, {"id": 1093954, "label": "ENT", "start_offset": 477, "end_offset": 494}, {"id": 1093955, "label": "ENT", "start_offset": 519, "end_offset": 553}, {"id": 1093956, "label": "ENT", "start_offset": 565, "end_offset": 577}, {"id": 1093957, "label": "ENT", "start_offset": 584, "end_offset": 597}, {"id": 1093958, "label": "ENT", "start_offset": 636, "end_offset": 653}], "relations": [{"id": 176971, "from_id": 1093943, "to_id": 1093944, "type": "PART-OF"}, {"id": 176972, "from_id": 1093953, "to_id": 1093948, "type": "COREF"}, {"id": 176973, "from_id": 1093956, "to_id": 1093957, "type": "CONJUNCTION"}, {"id": 176974, "from_id": 1093955, "to_id": 1093953, "type": "FEATURE-OF"}, {"id": 176975, "from_id": 1093953, "to_id": 1093958, "type": "USED-FOR"}, {"id": 176976, "from_id": 1093949, "to_id": 1093948, "type": "USED-FOR"}, {"id": 176977, "from_id": 1093945, "to_id": 1093946, "type": "PART-OF"}]}
{"id": "ICASSP_2016_3_abs", "text": "Speech-based depression detection has gained importance in recent years, but most research has used relatively quiet conditions or examined a single corpus per study. Little is thus known about the robustness of speech cues in the wild. This study compares the effect of noise and reverberation on depression prediction using 1) standard mel-frequency cepstral coefficients (MFCCs), and 2) features designed for noise robustness, damped oscillator cepstral coefficients (DOCCs). Data come from the 2014 AudioVisual Emotion Recognition Challenge (AVEC). Results using additive noise and reverberation reveal a consistent pattern of findings for multiple evaluation metrics under both matched and mismatched conditions. First and most notably: standard MFCC features suffer dramatically under test/train mismatch for both noise and reverberation; DOCC features are far more robust. Second, including higher-order cepstral coefficients is generally beneficial. Third, artificial neural networks tend to outperform support vector regression. Fourth, spontaneous speech appears to offer better robustness than read speech. Finally, a cross-corpus (and cross-language) experiment reveals better noise and reverberation robustness for DOCCs than for MFCCs. Implications and future directions for real-world robust depression detection are discussed.", "Comments": [], "entities": [{"id": 1093980, "label": "ENT", "start_offset": 0, "end_offset": 33}, {"id": 1093981, "label": "ENT", "start_offset": 198, "end_offset": 208}, {"id": 1093982, "label": "ENT", "start_offset": 212, "end_offset": 223}, {"id": 1093983, "label": "ENT", "start_offset": 271, "end_offset": 276}, {"id": 1093984, "label": "ENT", "start_offset": 281, "end_offset": 294}, {"id": 1093985, "label": "ENT", "start_offset": 298, "end_offset": 319}, {"id": 1093986, "label": "ENT", "start_offset": 338, "end_offset": 381}, {"id": 1093987, "label": "ENT", "start_offset": 390, "end_offset": 398}, {"id": 1093988, "label": "ENT", "start_offset": 412, "end_offset": 428}, {"id": 1093989, "label": "ENT", "start_offset": 430, "end_offset": 477}, {"id": 1093990, "label": "ENT", "start_offset": 503, "end_offset": 551}, {"id": 1093991, "label": "ENT", "start_offset": 567, "end_offset": 581}, {"id": 1093992, "label": "ENT", "start_offset": 586, "end_offset": 599}, {"id": 1093993, "label": "ENT", "start_offset": 653, "end_offset": 671}, {"id": 1093994, "label": "ENT", "start_offset": 751, "end_offset": 764}, {"id": 1093995, "label": "ENT", "start_offset": 820, "end_offset": 825}, {"id": 1093996, "label": "ENT", "start_offset": 830, "end_offset": 843}, {"id": 1093997, "label": "ENT", "start_offset": 845, "end_offset": 858}, {"id": 1093998, "label": "ENT", "start_offset": 898, "end_offset": 932}, {"id": 1093999, "label": "ENT", "start_offset": 965, "end_offset": 991}, {"id": 1094000, "label": "ENT", "start_offset": 1011, "end_offset": 1036}, {"id": 1094001, "label": "ENT", "start_offset": 1046, "end_offset": 1064}, {"id": 1094002, "label": "ENT", "start_offset": 1105, "end_offset": 1116}, {"id": 1094003, "label": "ENT", "start_offset": 1129, "end_offset": 1173}, {"id": 1094004, "label": "ENT", "start_offset": 1189, "end_offset": 1223}, {"id": 1094005, "label": "ENT", "start_offset": 1228, "end_offset": 1233}, {"id": 1094006, "label": "ENT", "start_offset": 1243, "end_offset": 1248}, {"id": 1094007, "label": "ENT", "start_offset": 1289, "end_offset": 1327}], "relations": [{"id": 176991, "from_id": 1093982, "to_id": 1093981, "type": "FEATURE-OF"}, {"id": 176992, "from_id": 1093983, "to_id": 1093984, "type": "CONJUNCTION"}, {"id": 176993, "from_id": 1093984, "to_id": 1093985, "type": "FEATURE-OF"}, {"id": 176994, "from_id": 1093983, "to_id": 1093985, "type": "FEATURE-OF"}, {"id": 176995, "from_id": 1093986, "to_id": 1093985, "type": "USED-FOR"}, {"id": 176996, "from_id": 1093987, "to_id": 1093988, "type": "USED-FOR"}, {"id": 176997, "from_id": 1093989, "to_id": 1093987, "type": "COREF"}, {"id": 176998, "from_id": 1093994, "to_id": 1093986, "type": "COREF"}, {"id": 176999, "from_id": 1093997, "to_id": 1093994, "type": "COMPARE"}, {"id": 177000, "from_id": 1093997, "to_id": 1093989, "type": "COREF"}, {"id": 177001, "from_id": 1093999, "to_id": 1094000, "type": "COMPARE"}, {"id": 177002, "from_id": 1094001, "to_id": 1094002, "type": "COMPARE"}, {"id": 177003, "from_id": 1094005, "to_id": 1094006, "type": "COMPARE"}, {"id": 177004, "from_id": 1094005, "to_id": 1093997, "type": "COREF"}, {"id": 177005, "from_id": 1094006, "to_id": 1093994, "type": "COREF"}, {"id": 177006, "from_id": 1093986, "to_id": 1093987, "type": "CONJUNCTION"}, {"id": 177007, "from_id": 1094004, "to_id": 1094005, "type": "EVALUATE-FOR"}, {"id": 177008, "from_id": 1094004, "to_id": 1094006, "type": "EVALUATE-FOR"}, {"id": 177009, "from_id": 1094003, "to_id": 1094005, "type": "EVALUATE-FOR"}, {"id": 177010, "from_id": 1094003, "to_id": 1094006, "type": "EVALUATE-FOR"}, {"id": 177011, "from_id": 1093995, "to_id": 1093996, "type": "CONJUNCTION"}, {"id": 177012, "from_id": 1093991, "to_id": 1093992, "type": "CONJUNCTION"}, {"id": 177013, "from_id": 1093987, "to_id": 1093989, "type": "CONJUNCTION"}]}
{"id": "J89-4003", "text": " A  model  is presented to characterize the  class of languages  obtained by adding  reduplication  to  context-free languages . The  model  is a  pushdown automaton  augmented with the ability to check  reduplication  by using the  stack  in a new way. The  class of languages  generated is shown to lie strictly between the  context-free languages  and the  indexed languages . The  model  appears capable of accommodating the sort of  reduplications  that have been observed to occur in  natural languages , but it excludes many of the unnatural  constructions  that other  formal models  have permitted. ", "Comments": [], "entities": [{"id": 1094008, "label": "ENT", "start_offset": 4, "end_offset": 9}, {"id": 1094009, "label": "ENT", "start_offset": 45, "end_offset": 63}, {"id": 1094010, "label": "ENT", "start_offset": 85, "end_offset": 98}, {"id": 1094011, "label": "ENT", "start_offset": 104, "end_offset": 126}, {"id": 1094012, "label": "ENT", "start_offset": 134, "end_offset": 139}, {"id": 1094013, "label": "ENT", "start_offset": 147, "end_offset": 165}, {"id": 1094014, "label": "ENT", "start_offset": 204, "end_offset": 217}, {"id": 1094015, "label": "ENT", "start_offset": 233, "end_offset": 238}, {"id": 1094016, "label": "ENT", "start_offset": 259, "end_offset": 277}, {"id": 1094017, "label": "ENT", "start_offset": 327, "end_offset": 349}, {"id": 1094018, "label": "ENT", "start_offset": 360, "end_offset": 377}, {"id": 1094019, "label": "ENT", "start_offset": 385, "end_offset": 390}, {"id": 1094020, "label": "ENT", "start_offset": 438, "end_offset": 452}, {"id": 1094021, "label": "ENT", "start_offset": 491, "end_offset": 508}, {"id": 1094022, "label": "ENT", "start_offset": 515, "end_offset": 517}, {"id": 1094023, "label": "ENT", "start_offset": 577, "end_offset": 590}], "relations": [{"id": 177014, "from_id": 1094008, "to_id": 1094009, "type": "USED-FOR"}, {"id": 177015, "from_id": 1094015, "to_id": 1094013, "type": "USED-FOR"}, {"id": 177016, "from_id": 1094012, "to_id": 1094008, "type": "COREF"}, {"id": 177017, "from_id": 1094012, "to_id": 1094013, "type": "HYPONYM-OF"}, {"id": 177018, "from_id": 1094016, "to_id": 1094009, "type": "COREF"}, {"id": 177019, "from_id": 1094017, "to_id": 1094018, "type": "CONJUNCTION"}, {"id": 177020, "from_id": 1094019, "to_id": 1094012, "type": "COREF"}, {"id": 177021, "from_id": 1094022, "to_id": 1094019, "type": "COREF"}, {"id": 177022, "from_id": 1094015, "to_id": 1094014, "type": "USED-FOR"}, {"id": 177023, "from_id": 1094010, "to_id": 1094011, "type": "USED-FOR"}, {"id": 177024, "from_id": 1094011, "to_id": 1094017, "type": "COREF"}, {"id": 177025, "from_id": 1094019, "to_id": 1094020, "type": "USED-FOR"}]}
{"id": "N04-4028", "text": "  Information extraction techniques  automatically create  structured databases  from  unstructured data sources , such as the Web or  newswire documents . Despite the successes of these systems,  accuracy  will always be imperfect. For many reasons, it is highly desirable to accurately estimate the  confidence  the system has in the correctness of each  extracted field . The  information extraction system  we evaluate is based on a  linear-chain conditional random field (CRF) , a  probabilistic model  which has performed well on  information extraction tasks  because of its ability to capture arbitrary, overlapping  features  of the  input  in a  Markov model . We implement several techniques to estimate the  confidence  of both  extracted fields  and entire  multi-field records , obtaining an  average precision  of 98% for retrieving correct  fields  and 87% for multi-field records. ", "Comments": [], "entities": [{"id": 1094103, "label": "ENT", "start_offset": 2, "end_offset": 35}, {"id": 1094104, "label": "ENT", "start_offset": 59, "end_offset": 79}, {"id": 1094105, "label": "ENT", "start_offset": 87, "end_offset": 112}, {"id": 1094106, "label": "ENT", "start_offset": 127, "end_offset": 130}, {"id": 1094107, "label": "ENT", "start_offset": 135, "end_offset": 153}, {"id": 1094108, "label": "ENT", "start_offset": 187, "end_offset": 194}, {"id": 1094109, "label": "ENT", "start_offset": 197, "end_offset": 205}, {"id": 1094110, "label": "ENT", "start_offset": 318, "end_offset": 324}, {"id": 1094111, "label": "ENT", "start_offset": 380, "end_offset": 409}, {"id": 1094112, "label": "ENT", "start_offset": 438, "end_offset": 481}, {"id": 1094113, "label": "ENT", "start_offset": 487, "end_offset": 506}, {"id": 1094114, "label": "ENT", "start_offset": 537, "end_offset": 565}, {"id": 1094115, "label": "ENT", "start_offset": 601, "end_offset": 633}, {"id": 1094116, "label": "ENT", "start_offset": 643, "end_offset": 648}, {"id": 1094117, "label": "ENT", "start_offset": 656, "end_offset": 668}, {"id": 1094118, "label": "ENT", "start_offset": 692, "end_offset": 702}, {"id": 1094119, "label": "ENT", "start_offset": 741, "end_offset": 757}, {"id": 1094120, "label": "ENT", "start_offset": 771, "end_offset": 790}, {"id": 1094121, "label": "ENT", "start_offset": 807, "end_offset": 824}, {"id": 1094122, "label": "ENT", "start_offset": 877, "end_offset": 896}], "relations": [{"id": 177080, "from_id": 1094103, "to_id": 1094104, "type": "USED-FOR"}, {"id": 177081, "from_id": 1094112, "to_id": 1094111, "type": "USED-FOR"}, {"id": 177082, "from_id": 1094113, "to_id": 1094114, "type": "USED-FOR"}, {"id": 177083, "from_id": 1094105, "to_id": 1094103, "type": "USED-FOR"}, {"id": 177084, "from_id": 1094106, "to_id": 1094105, "type": "HYPONYM-OF"}, {"id": 177085, "from_id": 1094107, "to_id": 1094105, "type": "HYPONYM-OF"}, {"id": 177086, "from_id": 1094106, "to_id": 1094107, "type": "CONJUNCTION"}, {"id": 177087, "from_id": 1094110, "to_id": 1094103, "type": "COREF"}, {"id": 177088, "from_id": 1094108, "to_id": 1094103, "type": "COREF"}, {"id": 177089, "from_id": 1094112, "to_id": 1094113, "type": "HYPONYM-OF"}, {"id": 177090, "from_id": 1094121, "to_id": 1094118, "type": "EVALUATE-FOR"}, {"id": 177091, "from_id": 1094119, "to_id": 1094120, "type": "CONJUNCTION"}, {"id": 177092, "from_id": 1094122, "to_id": 1094120, "type": "COREF"}, {"id": 177093, "from_id": 1094109, "to_id": 1094108, "type": "EVALUATE-FOR"}, {"id": 177094, "from_id": 1094111, "to_id": 1094110, "type": "COREF"}, {"id": 177095, "from_id": 1094115, "to_id": 1094116, "type": "FEATURE-OF"}, {"id": 177096, "from_id": 1094115, "to_id": 1094117, "type": "PART-OF"}, {"id": 177097, "from_id": 1094113, "to_id": 1094115, "type": "USED-FOR"}]}
{"id": "P84-1047", "text": "   An  entity-oriented approach to restricted-domain parsing  is proposed. In this approach, the definitions of the  structure  and  surface representation  of  domain entities  are grouped together. Like  semantic grammar  , this allows easy exploitation of  limited domain semantics  . In addition, it facilitates  fragmentary recognition  and the use of  multiple parsing strategies  , and so is particularly useful for robust  recognition of extra-grammatical input  . Several advantages from the point of view of  language definition  are also noted. Representative samples from an  entity-oriented language definition  are presented, along with a  control structure  for an  entity-oriented parser  , some  parsing strategies  that use the  control structure  , and worked examples of  parses  . A  parser  incorporating the  control structure  and the  parsing strategies  is currently under  implementation  . ", "Comments": [], "entities": [{"id": 1094355, "label": "ENT", "start_offset": 7, "end_offset": 31}, {"id": 1094356, "label": "ENT", "start_offset": 35, "end_offset": 60}, {"id": 1094357, "label": "ENT", "start_offset": 83, "end_offset": 91}, {"id": 1094358, "label": "ENT", "start_offset": 117, "end_offset": 176}, {"id": 1094359, "label": "ENT", "start_offset": 206, "end_offset": 222}, {"id": 1094360, "label": "ENT", "start_offset": 226, "end_offset": 230}, {"id": 1094361, "label": "ENT", "start_offset": 260, "end_offset": 284}, {"id": 1094362, "label": "ENT", "start_offset": 301, "end_offset": 303}, {"id": 1094363, "label": "ENT", "start_offset": 317, "end_offset": 340}, {"id": 1094364, "label": "ENT", "start_offset": 358, "end_offset": 385}, {"id": 1094365, "label": "ENT", "start_offset": 431, "end_offset": 469}, {"id": 1094366, "label": "ENT", "start_offset": 588, "end_offset": 623}, {"id": 1094367, "label": "ENT", "start_offset": 654, "end_offset": 671}, {"id": 1094368, "label": "ENT", "start_offset": 681, "end_offset": 703}, {"id": 1094369, "label": "ENT", "start_offset": 713, "end_offset": 731}, {"id": 1094370, "label": "ENT", "start_offset": 747, "end_offset": 764}, {"id": 1094371, "label": "ENT", "start_offset": 805, "end_offset": 811}, {"id": 1094372, "label": "ENT", "start_offset": 832, "end_offset": 849}, {"id": 1094373, "label": "ENT", "start_offset": 860, "end_offset": 878}], "relations": [{"id": 177304, "from_id": 1094364, "to_id": 1094365, "type": "USED-FOR"}, {"id": 177305, "from_id": 1094367, "to_id": 1094368, "type": "USED-FOR"}, {"id": 177306, "from_id": 1094370, "to_id": 1094369, "type": "USED-FOR"}, {"id": 177307, "from_id": 1094372, "to_id": 1094371, "type": "PART-OF"}, {"id": 177308, "from_id": 1094360, "to_id": 1094361, "type": "USED-FOR"}, {"id": 177309, "from_id": 1094360, "to_id": 1094362, "type": "COREF"}, {"id": 177310, "from_id": 1094362, "to_id": 1094363, "type": "USED-FOR"}, {"id": 177311, "from_id": 1094362, "to_id": 1094364, "type": "USED-FOR"}, {"id": 177312, "from_id": 1094370, "to_id": 1094367, "type": "COREF"}, {"id": 177313, "from_id": 1094372, "to_id": 1094370, "type": "COREF"}, {"id": 177314, "from_id": 1094373, "to_id": 1094369, "type": "COREF"}, {"id": 177315, "from_id": 1094355, "to_id": 1094356, "type": "USED-FOR"}, {"id": 177316, "from_id": 1094355, "to_id": 1094357, "type": "COREF"}]}
{"id": "P06-4014", "text": "   The  LOGON MT demonstrator  assembles independently valuable  general-purpose NLP components  into a  machine translation pipeline  that capitalizes on  output quality  . The demonstrator embodies an interesting combination of  hand-built, symbolic resources  and  stochastic processes  . ", "Comments": [], "entities": [{"id": 1094393, "label": "ENT", "start_offset": 8, "end_offset": 29}, {"id": 1094394, "label": "ENT", "start_offset": 65, "end_offset": 95}, {"id": 1094395, "label": "ENT", "start_offset": 105, "end_offset": 133}, {"id": 1094396, "label": "ENT", "start_offset": 178, "end_offset": 190}, {"id": 1094397, "label": "ENT", "start_offset": 231, "end_offset": 261}, {"id": 1094398, "label": "ENT", "start_offset": 268, "end_offset": 288}], "relations": [{"id": 177326, "from_id": 1094394, "to_id": 1094395, "type": "PART-OF"}, {"id": 177327, "from_id": 1094393, "to_id": 1094396, "type": "COREF"}, {"id": 177328, "from_id": 1094393, "to_id": 1094394, "type": "USED-FOR"}, {"id": 177329, "from_id": 1094397, "to_id": 1094398, "type": "CONJUNCTION"}, {"id": 177330, "from_id": 1094397, "to_id": 1094396, "type": "PART-OF"}, {"id": 177331, "from_id": 1094398, "to_id": 1094396, "type": "PART-OF"}]}
{"id": "P06-1018", "text": "   This paper proposes a generic  mathematical formalism  for the combination of various  structures  :  strings  ,  trees  ,  dags  ,  graphs  , and products of them. The  polarization  of the objects of the  elementary structures  controls the  saturation  of the final  structure  . This formalism is both elementary and powerful enough to strongly simulate many  grammar formalisms  , such as  rewriting systems  ,  dependency grammars  ,  TAG  ,  HPSG  and  LFG  . ", "Comments": [], "entities": [{"id": 1094442, "label": "ENT", "start_offset": 34, "end_offset": 56}, {"id": 1094443, "label": "ENT", "start_offset": 90, "end_offset": 100}, {"id": 1094444, "label": "ENT", "start_offset": 105, "end_offset": 112}, {"id": 1094445, "label": "ENT", "start_offset": 117, "end_offset": 122}, {"id": 1094446, "label": "ENT", "start_offset": 127, "end_offset": 131}, {"id": 1094447, "label": "ENT", "start_offset": 136, "end_offset": 142}, {"id": 1094448, "label": "ENT", "start_offset": 162, "end_offset": 166}, {"id": 1094449, "label": "ENT", "start_offset": 173, "end_offset": 185}, {"id": 1094450, "label": "ENT", "start_offset": 210, "end_offset": 231}, {"id": 1094451, "label": "ENT", "start_offset": 291, "end_offset": 300}, {"id": 1094452, "label": "ENT", "start_offset": 367, "end_offset": 385}, {"id": 1094453, "label": "ENT", "start_offset": 398, "end_offset": 415}, {"id": 1094454, "label": "ENT", "start_offset": 420, "end_offset": 439}, {"id": 1094455, "label": "ENT", "start_offset": 444, "end_offset": 447}, {"id": 1094456, "label": "ENT", "start_offset": 452, "end_offset": 456}, {"id": 1094457, "label": "ENT", "start_offset": 463, "end_offset": 466}], "relations": [{"id": 177376, "from_id": 1094444, "to_id": 1094443, "type": "HYPONYM-OF"}, {"id": 177377, "from_id": 1094445, "to_id": 1094443, "type": "HYPONYM-OF"}, {"id": 177378, "from_id": 1094446, "to_id": 1094443, "type": "HYPONYM-OF"}, {"id": 177379, "from_id": 1094447, "to_id": 1094443, "type": "HYPONYM-OF"}, {"id": 177380, "from_id": 1094444, "to_id": 1094445, "type": "CONJUNCTION"}, {"id": 177381, "from_id": 1094445, "to_id": 1094446, "type": "CONJUNCTION"}, {"id": 177382, "from_id": 1094446, "to_id": 1094447, "type": "CONJUNCTION"}, {"id": 177383, "from_id": 1094443, "to_id": 1094448, "type": "COREF"}, {"id": 177384, "from_id": 1094442, "to_id": 1094451, "type": "COREF"}, {"id": 177385, "from_id": 1094451, "to_id": 1094452, "type": "USED-FOR"}, {"id": 177386, "from_id": 1094456, "to_id": 1094457, "type": "CONJUNCTION"}, {"id": 177387, "from_id": 1094453, "to_id": 1094454, "type": "CONJUNCTION"}, {"id": 177388, "from_id": 1094454, "to_id": 1094455, "type": "CONJUNCTION"}, {"id": 177389, "from_id": 1094455, "to_id": 1094456, "type": "CONJUNCTION"}, {"id": 177390, "from_id": 1094453, "to_id": 1094452, "type": "HYPONYM-OF"}, {"id": 177391, "from_id": 1094454, "to_id": 1094452, "type": "HYPONYM-OF"}, {"id": 177392, "from_id": 1094455, "to_id": 1094452, "type": "HYPONYM-OF"}, {"id": 177393, "from_id": 1094456, "to_id": 1094452, "type": "HYPONYM-OF"}, {"id": 177394, "from_id": 1094457, "to_id": 1094452, "type": "HYPONYM-OF"}]}
{"id": "CVPR_2008_258_abs", "text": "We propose a novel step toward the unsupervised seg-mentation of whole objects by combining \" hints \" of partial scene segmentation offered by multiple soft, binary mattes. These mattes are implied by a set of hypothesized object boundary fragments in the scene. Rather than trying to find or define a single \" best \" segmentation, we generate multiple segmentations of an image. This reflects contemporary methods for unsupervised object discovery from groups of images, and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects. Our proposed approach builds on recent advances in spectral clustering, image matting, and boundary detection. It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge.", "Comments": [], "entities": [{"id": 1094458, "label": "ENT", "start_offset": 35, "end_offset": 78}, {"id": 1094459, "label": "ENT", "start_offset": 105, "end_offset": 131}, {"id": 1094460, "label": "ENT", "start_offset": 152, "end_offset": 171}, {"id": 1094461, "label": "ENT", "start_offset": 179, "end_offset": 185}, {"id": 1094462, "label": "ENT", "start_offset": 210, "end_offset": 248}, {"id": 1094463, "label": "ENT", "start_offset": 394, "end_offset": 414}, {"id": 1094464, "label": "ENT", "start_offset": 419, "end_offset": 448}, {"id": 1094465, "label": "ENT", "start_offset": 598, "end_offset": 626}, {"id": 1094466, "label": "ENT", "start_offset": 641, "end_offset": 649}, {"id": 1094467, "label": "ENT", "start_offset": 679, "end_offset": 698}, {"id": 1094468, "label": "ENT", "start_offset": 700, "end_offset": 713}, {"id": 1094469, "label": "ENT", "start_offset": 719, "end_offset": 737}, {"id": 1094470, "label": "ENT", "start_offset": 739, "end_offset": 741}, {"id": 1094471, "label": "ENT", "start_offset": 796, "end_offset": 813}, {"id": 1094472, "label": "ENT", "start_offset": 850, "end_offset": 879}], "relations": [{"id": 177395, "from_id": 1094459, "to_id": 1094458, "type": "USED-FOR"}, {"id": 177396, "from_id": 1094460, "to_id": 1094459, "type": "USED-FOR"}, {"id": 177397, "from_id": 1094460, "to_id": 1094461, "type": "COREF"}, {"id": 177398, "from_id": 1094462, "to_id": 1094461, "type": "USED-FOR"}, {"id": 177399, "from_id": 1094463, "to_id": 1094464, "type": "USED-FOR"}, {"id": 177400, "from_id": 1094467, "to_id": 1094466, "type": "USED-FOR"}, {"id": 177401, "from_id": 1094468, "to_id": 1094469, "type": "CONJUNCTION"}, {"id": 177402, "from_id": 1094467, "to_id": 1094468, "type": "CONJUNCTION"}, {"id": 177403, "from_id": 1094468, "to_id": 1094466, "type": "USED-FOR"}, {"id": 177404, "from_id": 1094469, "to_id": 1094466, "type": "USED-FOR"}, {"id": 177405, "from_id": 1094472, "to_id": 1094464, "type": "COREF"}, {"id": 177406, "from_id": 1094458, "to_id": 1094464, "type": "COREF"}, {"id": 177407, "from_id": 1094470, "to_id": 1094466, "type": "COREF"}, {"id": 177408, "from_id": 1094471, "to_id": 1094470, "type": "EVALUATE-FOR"}, {"id": 177409, "from_id": 1094470, "to_id": 1094472, "type": "USED-FOR"}]}
{"id": "INTERSPEECH_2007_40_abs", "text": "Information distillation aims to extract relevant pieces of information related to a given query from massive, possibly multilingual, audio and textual document sources. In this paper , we present our approach for using information extraction annotations to augment document retrieval for distillation. We take advantage of the fact that some of the distillation queries can be associated with annotation elements introduced for the NIST Automatic Content Extraction (ACE) task. We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates.", "Comments": [], "entities": [{"id": 1094473, "label": "ENT", "start_offset": 0, "end_offset": 24}, {"id": 1094474, "label": "ENT", "start_offset": 102, "end_offset": 168}, {"id": 1094475, "label": "ENT", "start_offset": 220, "end_offset": 254}, {"id": 1094476, "label": "ENT", "start_offset": 266, "end_offset": 301}, {"id": 1094477, "label": "ENT", "start_offset": 350, "end_offset": 370}, {"id": 1094478, "label": "ENT", "start_offset": 394, "end_offset": 413}, {"id": 1094479, "label": "ENT", "start_offset": 433, "end_offset": 477}, {"id": 1094480, "label": "ENT", "start_offset": 517, "end_offset": 527}, {"id": 1094481, "label": "ENT", "start_offset": 573, "end_offset": 601}, {"id": 1094482, "label": "ENT", "start_offset": 629, "end_offset": 638}, {"id": 1094483, "label": "ENT", "start_offset": 650, "end_offset": 662}], "relations": [{"id": 177410, "from_id": 1094475, "to_id": 1094476, "type": "USED-FOR"}]}
{"id": "ICCV_2015_400_abs", "text": "Hough voting in a geometric transformation space allows us to realize spatial verification, but remains sensitive to feature detection errors because of the inflexible quan-tization of single feature correspondences. To handle this problem, we propose a new method, called adaptive dither voting, for robust spatial verification. For each correspondence , instead of hard-mapping it to a single transformation , the method augments its description by using multiple dithered transformations that are deterministically generated by the other correspondences. The method reduces the probability of losing correspondences during transformation quantization, and provides high robustness as regards mismatches by imposing three geometric constraints on the dithering process. We also propose exploiting the non-uniformity of a Hough histogram as the spatial similarity to handle multiple matching surfaces. Extensive experiments conducted on four datasets show the superiority of our method. The method outperforms its state-of-the-art counterparts in both accuracy and scalability, especially when it comes to the retrieval of small, rotated objects.", "Comments": [], "entities": [{"id": 1094484, "label": "ENT", "start_offset": 0, "end_offset": 12}, {"id": 1094485, "label": "ENT", "start_offset": 18, "end_offset": 48}, {"id": 1094486, "label": "ENT", "start_offset": 70, "end_offset": 90}, {"id": 1094487, "label": "ENT", "start_offset": 117, "end_offset": 141}, {"id": 1094488, "label": "ENT", "start_offset": 157, "end_offset": 215}, {"id": 1094489, "label": "ENT", "start_offset": 258, "end_offset": 264}, {"id": 1094490, "label": "ENT", "start_offset": 273, "end_offset": 295}, {"id": 1094491, "label": "ENT", "start_offset": 301, "end_offset": 328}, {"id": 1094492, "label": "ENT", "start_offset": 416, "end_offset": 422}, {"id": 1094493, "label": "ENT", "start_offset": 457, "end_offset": 490}, {"id": 1094494, "label": "ENT", "start_offset": 562, "end_offset": 568}, {"id": 1094495, "label": "ENT", "start_offset": 626, "end_offset": 653}, {"id": 1094496, "label": "ENT", "start_offset": 687, "end_offset": 705}, {"id": 1094497, "label": "ENT", "start_offset": 724, "end_offset": 745}, {"id": 1094498, "label": "ENT", "start_offset": 753, "end_offset": 770}, {"id": 1094499, "label": "ENT", "start_offset": 803, "end_offset": 817}, {"id": 1094500, "label": "ENT", "start_offset": 823, "end_offset": 838}, {"id": 1094501, "label": "ENT", "start_offset": 846, "end_offset": 864}, {"id": 1094502, "label": "ENT", "start_offset": 875, "end_offset": 901}, {"id": 1094503, "label": "ENT", "start_offset": 980, "end_offset": 986}, {"id": 1094504, "label": "ENT", "start_offset": 992, "end_offset": 998}, {"id": 1094505, "label": "ENT", "start_offset": 1032, "end_offset": 1044}, {"id": 1094506, "label": "ENT", "start_offset": 1053, "end_offset": 1061}, {"id": 1094507, "label": "ENT", "start_offset": 1066, "end_offset": 1077}, {"id": 1094508, "label": "ENT", "start_offset": 1111, "end_offset": 1146}], "relations": [{"id": 177411, "from_id": 1094485, "to_id": 1094484, "type": "FEATURE-OF"}, {"id": 177412, "from_id": 1094484, "to_id": 1094486, "type": "USED-FOR"}, {"id": 177413, "from_id": 1094490, "to_id": 1094489, "type": "COREF"}, {"id": 177414, "from_id": 1094489, "to_id": 1094491, "type": "USED-FOR"}, {"id": 177415, "from_id": 1094491, "to_id": 1094486, "type": "COREF"}, {"id": 177416, "from_id": 1094489, "to_id": 1094492, "type": "COREF"}, {"id": 177417, "from_id": 1094493, "to_id": 1094492, "type": "USED-FOR"}, {"id": 177418, "from_id": 1094494, "to_id": 1094492, "type": "COREF"}, {"id": 177419, "from_id": 1094499, "to_id": 1094500, "type": "FEATURE-OF"}, {"id": 177420, "from_id": 1094499, "to_id": 1094502, "type": "USED-FOR"}, {"id": 177421, "from_id": 1094503, "to_id": 1094494, "type": "COREF"}, {"id": 177422, "from_id": 1094504, "to_id": 1094503, "type": "COREF"}, {"id": 177423, "from_id": 1094505, "to_id": 1094504, "type": "COMPARE"}, {"id": 177424, "from_id": 1094506, "to_id": 1094504, "type": "EVALUATE-FOR"}, {"id": 177425, "from_id": 1094507, "to_id": 1094504, "type": "EVALUATE-FOR"}, {"id": 177426, "from_id": 1094506, "to_id": 1094505, "type": "EVALUATE-FOR"}, {"id": 177427, "from_id": 1094507, "to_id": 1094505, "type": "EVALUATE-FOR"}, {"id": 177428, "from_id": 1094504, "to_id": 1094508, "type": "USED-FOR"}]}
{"id": "P02-1023", "text": " Reducing  language model (LM) size  is a critical issue when applying a  LM  to realistic applications which have memory constraints. In this paper, three measures are studied for the purpose of  LM pruning . They are probability,  rank , and  entropy . We evaluated the performance of the three  pruning criteria  in a real application of  Chinese text input  in terms of  character error rate (CER) . We first present an empirical comparison, showing that  rank  performs the best in most cases. We also show that the high-performance of  rank  lies in its strong correlation with  error rate . We then present a novel method of combining two criteria in  model pruning . Experimental results show that the combined criterion consistently leads to smaller models than the models pruned using either of the criteria separately, at the same  CER . ", "Comments": [], "entities": [{"id": 1094521, "label": "ENT", "start_offset": 1, "end_offset": 35}, {"id": 1094522, "label": "ENT", "start_offset": 74, "end_offset": 76}, {"id": 1094523, "label": "ENT", "start_offset": 115, "end_offset": 134}, {"id": 1094524, "label": "ENT", "start_offset": 197, "end_offset": 207}, {"id": 1094525, "label": "ENT", "start_offset": 233, "end_offset": 237}, {"id": 1094526, "label": "ENT", "start_offset": 245, "end_offset": 252}, {"id": 1094527, "label": "ENT", "start_offset": 298, "end_offset": 314}, {"id": 1094528, "label": "ENT", "start_offset": 342, "end_offset": 360}, {"id": 1094529, "label": "ENT", "start_offset": 375, "end_offset": 401}, {"id": 1094530, "label": "ENT", "start_offset": 460, "end_offset": 464}, {"id": 1094531, "label": "ENT", "start_offset": 542, "end_offset": 546}, {"id": 1094532, "label": "ENT", "start_offset": 585, "end_offset": 595}, {"id": 1094533, "label": "ENT", "start_offset": 622, "end_offset": 628}, {"id": 1094534, "label": "ENT", "start_offset": 659, "end_offset": 672}, {"id": 1094535, "label": "ENT", "start_offset": 843, "end_offset": 846}], "relations": [{"id": 177436, "from_id": 1094525, "to_id": 1094526, "type": "CONJUNCTION"}, {"id": 177437, "from_id": 1094527, "to_id": 1094528, "type": "USED-FOR"}, {"id": 177438, "from_id": 1094529, "to_id": 1094527, "type": "EVALUATE-FOR"}, {"id": 177439, "from_id": 1094532, "to_id": 1094531, "type": "EVALUATE-FOR"}, {"id": 177440, "from_id": 1094535, "to_id": 1094529, "type": "COREF"}, {"id": 177441, "from_id": 1094533, "to_id": 1094534, "type": "USED-FOR"}]}
{"id": "CVPR_1993_10_abs", "text": "A model-based approach to on-line cursive handwriting analysis and recognition is presented and evaluated. In this model, on-line handwriting is considered as a modulation of a simple cycloidal pen motion, described by two coupled oscillations with a constant linear drift along the line of the writing. By slow modulations of the amplitudes and phase lags of the two oscillators, a general pen trajectory can be efficiently encoded. These parameters are then quantized into a small number of values without altering the writing intelligibility. A general procedure for the estimation and quantization of these cycloidal motion parameters for arbitrary handwriting is presented. The result is a discrete motor control representation of the continuous pen motion, via the quantized levels of the model parameters. This motor control representation enables successful word spotting and matching of cursive scripts. Our experiments clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition.", "Comments": [], "entities": [{"id": 1094536, "label": "ENT", "start_offset": 2, "end_offset": 22}, {"id": 1094537, "label": "ENT", "start_offset": 26, "end_offset": 78}, {"id": 1094538, "label": "ENT", "start_offset": 115, "end_offset": 120}, {"id": 1094539, "label": "ENT", "start_offset": 122, "end_offset": 141}, {"id": 1094540, "label": "ENT", "start_offset": 184, "end_offset": 204}, {"id": 1094541, "label": "ENT", "start_offset": 251, "end_offset": 272}, {"id": 1094542, "label": "ENT", "start_offset": 391, "end_offset": 405}, {"id": 1094543, "label": "ENT", "start_offset": 521, "end_offset": 544}, {"id": 1094544, "label": "ENT", "start_offset": 611, "end_offset": 638}, {"id": 1094545, "label": "ENT", "start_offset": 643, "end_offset": 664}, {"id": 1094546, "label": "ENT", "start_offset": 695, "end_offset": 732}, {"id": 1094547, "label": "ENT", "start_offset": 740, "end_offset": 761}, {"id": 1094548, "label": "ENT", "start_offset": 818, "end_offset": 846}, {"id": 1094549, "label": "ENT", "start_offset": 866, "end_offset": 879}, {"id": 1094550, "label": "ENT", "start_offset": 884, "end_offset": 911}, {"id": 1094551, "label": "ENT", "start_offset": 968, "end_offset": 990}, {"id": 1094552, "label": "ENT", "start_offset": 1004, "end_offset": 1035}], "relations": [{"id": 177442, "from_id": 1094536, "to_id": 1094537, "type": "USED-FOR"}, {"id": 177443, "from_id": 1094538, "to_id": 1094536, "type": "COREF"}, {"id": 177444, "from_id": 1094539, "to_id": 1094540, "type": "PART-OF"}, {"id": 177445, "from_id": 1094544, "to_id": 1094545, "type": "USED-FOR"}, {"id": 177446, "from_id": 1094546, "to_id": 1094547, "type": "USED-FOR"}, {"id": 177447, "from_id": 1094538, "to_id": 1094539, "type": "USED-FOR"}, {"id": 177448, "from_id": 1094549, "to_id": 1094550, "type": "CONJUNCTION"}, {"id": 177449, "from_id": 1094548, "to_id": 1094549, "type": "USED-FOR"}, {"id": 177450, "from_id": 1094548, "to_id": 1094550, "type": "USED-FOR"}, {"id": 177451, "from_id": 1094551, "to_id": 1094548, "type": "COREF"}, {"id": 177452, "from_id": 1094548, "to_id": 1094546, "type": "COREF"}, {"id": 177453, "from_id": 1094551, "to_id": 1094552, "type": "USED-FOR"}, {"id": 177454, "from_id": 1094552, "to_id": 1094537, "type": "HYPONYM-OF"}]}
{"id": "P05-1046", "text": " The applicability of many current  information extraction techniques  is severely limited by the need for  supervised training data .  We demonstrate that for certain  field structured extraction tasks , such as classified advertisements and bibliographic citations, small amounts of  prior knowledge  can be used to learn effective models in a primarily unsupervised fashion. Although  hidden Markov models (HMMs)  provide a suitable  generative model  for  field structured text , general  unsupervised HMM learning  fails to learn useful structure in either of our domains. However, one can dramatically improve the quality of the learned structure by exploiting simple  prior knowledge  of the desired solutions. In both domains, we found that  unsupervised methods  can attain  accuracies  with 400  unlabeled examples  comparable to those attained by  supervised methods  on 50  labeled examples , and that  semi-supervised methods  can make good use of small amounts of  labeled data . ", "Comments": [], "entities": [{"id": 1094553, "label": "ENT", "start_offset": 36, "end_offset": 69}, {"id": 1094554, "label": "ENT", "start_offset": 108, "end_offset": 132}, {"id": 1094555, "label": "ENT", "start_offset": 169, "end_offset": 202}, {"id": 1094556, "label": "ENT", "start_offset": 213, "end_offset": 238}, {"id": 1094557, "label": "ENT", "start_offset": 243, "end_offset": 266}, {"id": 1094558, "label": "ENT", "start_offset": 286, "end_offset": 301}, {"id": 1094559, "label": "ENT", "start_offset": 388, "end_offset": 415}, {"id": 1094560, "label": "ENT", "start_offset": 437, "end_offset": 453}, {"id": 1094561, "label": "ENT", "start_offset": 460, "end_offset": 481}, {"id": 1094562, "label": "ENT", "start_offset": 493, "end_offset": 518}, {"id": 1094563, "label": "ENT", "start_offset": 675, "end_offset": 690}, {"id": 1094564, "label": "ENT", "start_offset": 750, "end_offset": 770}, {"id": 1094565, "label": "ENT", "start_offset": 784, "end_offset": 794}, {"id": 1094566, "label": "ENT", "start_offset": 806, "end_offset": 824}, {"id": 1094567, "label": "ENT", "start_offset": 859, "end_offset": 877}, {"id": 1094568, "label": "ENT", "start_offset": 886, "end_offset": 902}, {"id": 1094569, "label": "ENT", "start_offset": 915, "end_offset": 938}, {"id": 1094570, "label": "ENT", "start_offset": 979, "end_offset": 991}], "relations": [{"id": 177455, "from_id": 1094554, "to_id": 1094553, "type": "USED-FOR"}, {"id": 177456, "from_id": 1094558, "to_id": 1094555, "type": "USED-FOR"}, {"id": 177457, "from_id": 1094560, "to_id": 1094561, "type": "USED-FOR"}, {"id": 177458, "from_id": 1094570, "to_id": 1094569, "type": "USED-FOR"}, {"id": 177459, "from_id": 1094556, "to_id": 1094557, "type": "CONJUNCTION"}, {"id": 177460, "from_id": 1094556, "to_id": 1094555, "type": "HYPONYM-OF"}, {"id": 177461, "from_id": 1094557, "to_id": 1094555, "type": "HYPONYM-OF"}, {"id": 177462, "from_id": 1094559, "to_id": 1094560, "type": "USED-FOR"}, {"id": 177463, "from_id": 1094566, "to_id": 1094564, "type": "USED-FOR"}, {"id": 177464, "from_id": 1094565, "to_id": 1094564, "type": "EVALUATE-FOR"}, {"id": 177465, "from_id": 1094568, "to_id": 1094567, "type": "USED-FOR"}, {"id": 177466, "from_id": 1094564, "to_id": 1094567, "type": "COMPARE"}, {"id": 177467, "from_id": 1094565, "to_id": 1094567, "type": "EVALUATE-FOR"}]}
{"id": "IJCAI_2001_4_abs", "text": "A new algorithm for solving the three dimensional container packing problem is proposed in this paper. This new algorithm deviates from the traditional approach of wall building and layering. It uses the concept of \" building growing \" from multiple sides of the container. We tested our method using all 760 test cases from the OR-Library. Experimental results indicate that the new algorithm is able to achieve an average packing utilization of more than 87%. This is better than the results reported in the literature.", "Comments": [], "entities": [{"id": 1094571, "label": "ENT", "start_offset": 6, "end_offset": 15}, {"id": 1094572, "label": "ENT", "start_offset": 38, "end_offset": 75}, {"id": 1094573, "label": "ENT", "start_offset": 112, "end_offset": 121}, {"id": 1094574, "label": "ENT", "start_offset": 152, "end_offset": 190}, {"id": 1094575, "label": "ENT", "start_offset": 192, "end_offset": 194}, {"id": 1094576, "label": "ENT", "start_offset": 288, "end_offset": 294}, {"id": 1094577, "label": "ENT", "start_offset": 329, "end_offset": 339}, {"id": 1094578, "label": "ENT", "start_offset": 384, "end_offset": 393}, {"id": 1094579, "label": "ENT", "start_offset": 416, "end_offset": 443}], "relations": [{"id": 177468, "from_id": 1094579, "to_id": 1094578, "type": "EVALUATE-FOR"}, {"id": 177469, "from_id": 1094571, "to_id": 1094572, "type": "USED-FOR"}, {"id": 177470, "from_id": 1094571, "to_id": 1094573, "type": "COREF"}, {"id": 177471, "from_id": 1094573, "to_id": 1094574, "type": "COMPARE"}, {"id": 177472, "from_id": 1094573, "to_id": 1094575, "type": "COREF"}, {"id": 177473, "from_id": 1094575, "to_id": 1094576, "type": "COREF"}, {"id": 177474, "from_id": 1094577, "to_id": 1094576, "type": "EVALUATE-FOR"}, {"id": 177475, "from_id": 1094575, "to_id": 1094578, "type": "COREF"}]}
{"id": "C94-1088", "text": " This paper describes a  characters-based Chinese collocation system  and discusses the advantages of it over a traditional  word-based system . Since  wordbreaks  are not conventionally marked in  Chinese text corpora , a  character-based collocation system  has the dual advantages of avoiding  pre-processing distortion  and directly accessing  sub-lexical information . Furthermore,  word-based collocational properties  can be obtained through an auxiliary module of  automatic segmentation . ", "Comments": [], "entities": [{"id": 1094853, "label": "ENT", "start_offset": 25, "end_offset": 68}, {"id": 1094854, "label": "ENT", "start_offset": 102, "end_offset": 104}, {"id": 1094855, "label": "ENT", "start_offset": 125, "end_offset": 142}, {"id": 1094856, "label": "ENT", "start_offset": 198, "end_offset": 218}, {"id": 1094857, "label": "ENT", "start_offset": 224, "end_offset": 258}, {"id": 1094858, "label": "ENT", "start_offset": 287, "end_offset": 322}, {"id": 1094859, "label": "ENT", "start_offset": 337, "end_offset": 371}, {"id": 1094860, "label": "ENT", "start_offset": 388, "end_offset": 423}, {"id": 1094861, "label": "ENT", "start_offset": 452, "end_offset": 495}], "relations": [{"id": 177680, "from_id": 1094854, "to_id": 1094853, "type": "COREF"}, {"id": 177681, "from_id": 1094854, "to_id": 1094855, "type": "COMPARE"}, {"id": 177682, "from_id": 1094857, "to_id": 1094854, "type": "COREF"}, {"id": 177683, "from_id": 1094858, "to_id": 1094857, "type": "FEATURE-OF"}, {"id": 177684, "from_id": 1094859, "to_id": 1094857, "type": "FEATURE-OF"}, {"id": 177685, "from_id": 1094858, "to_id": 1094859, "type": "CONJUNCTION"}, {"id": 177686, "from_id": 1094861, "to_id": 1094860, "type": "USED-FOR"}]}
{"id": "CVPR_2011_11_abs", "text": "We propose a novel approach to associate objects across multiple PTZ cameras that can be used to perform camera handoff in wide-area surveillance scenarios. While previous approaches relied on geometric, appearance, or correlation-based information for establishing correspondences between static cameras, they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras. In our approach, the slave camera only passively follows the target (by loose registration with the master) and bootstraps itself from its own incoming imagery , thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer. Towards this goal, we also propose a novel Multiple Instance Learning (MIL) formulation for the problem based on the logistic softmax function of covariance-based region features within a MAP estimation framework. We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches.", "Comments": [], "entities": [{"id": 1094904, "label": "ENT", "start_offset": 19, "end_offset": 27}, {"id": 1094905, "label": "ENT", "start_offset": 65, "end_offset": 76}, {"id": 1094906, "label": "ENT", "start_offset": 105, "end_offset": 155}, {"id": 1094907, "label": "ENT", "start_offset": 172, "end_offset": 182}, {"id": 1094908, "label": "ENT", "start_offset": 193, "end_offset": 248}, {"id": 1094909, "label": "ENT", "start_offset": 290, "end_offset": 304}, {"id": 1094910, "label": "ENT", "start_offset": 370, "end_offset": 388}, {"id": 1094911, "label": "ENT", "start_offset": 394, "end_offset": 405}, {"id": 1094912, "label": "ENT", "start_offset": 414, "end_offset": 422}, {"id": 1094913, "label": "ENT", "start_offset": 428, "end_offset": 440}, {"id": 1094914, "label": "ENT", "start_offset": 631, "end_offset": 641}, {"id": 1094915, "label": "ENT", "start_offset": 679, "end_offset": 693}, {"id": 1094916, "label": "ENT", "start_offset": 738, "end_offset": 782}, {"id": 1094917, "label": "ENT", "start_offset": 812, "end_offset": 873}, {"id": 1094918, "label": "ENT", "start_offset": 883, "end_offset": 907}, {"id": 1094919, "label": "ENT", "start_offset": 928, "end_offset": 936}, {"id": 1094920, "label": "ENT", "start_offset": 942, "end_offset": 971}, {"id": 1094921, "label": "ENT", "start_offset": 983, "end_offset": 1012}, {"id": 1094922, "label": "ENT", "start_offset": 1040, "end_offset": 1067}], "relations": [{"id": 177722, "from_id": 1094904, "to_id": 1094906, "type": "USED-FOR"}, {"id": 177723, "from_id": 1094908, "to_id": 1094907, "type": "USED-FOR"}, {"id": 177724, "from_id": 1094904, "to_id": 1094912, "type": "COREF"}, {"id": 177725, "from_id": 1094919, "to_id": 1094922, "type": "COMPARE"}, {"id": 177726, "from_id": 1094917, "to_id": 1094916, "type": "USED-FOR"}, {"id": 177727, "from_id": 1094918, "to_id": 1094916, "type": "USED-FOR"}, {"id": 177728, "from_id": 1094912, "to_id": 1094919, "type": "COREF"}, {"id": 177729, "from_id": 1094920, "to_id": 1094919, "type": "USED-FOR"}, {"id": 177730, "from_id": 1094919, "to_id": 1094921, "type": "USED-FOR"}, {"id": 177731, "from_id": 1094907, "to_id": 1094914, "type": "COREF"}]}
{"id": "H90-1060", "text": "   This paper reports on two contributions to  large vocabulary continuous speech recognition  . First, we present a new paradigm for  speaker-independent (SI) training  of  hidden Markov models (HMM)  , which uses a large amount of  speech  from a few  speakers  instead of the traditional practice of using a little  speech  from many  speakers  . In addition, combination of the  training speakers  is done by averaging the  statistics  of  independently trained models  rather than the usual pooling of all the  speech data  from many  speakers  prior to  training  . With only 12  training speakers  for  SI recognition  , we achieved a 7.5%  word error rate  on a standard  grammar  and  test set  from the  DARPA Resource Management corpus  . This  performance  is comparable to our best condition for this test suite, using 109  training speakers  . Second, we show a significant improvement for  speaker adaptation (SA)  using the new  SI corpus  and a small amount of  speech  from the new (target)  speaker  . A  probabilistic spectral mapping  is estimated independently for each  training (reference) speaker  and the  target speaker  . Each  reference model  is transformed to the  space  of the  target speaker  and combined by  averaging  . Using only 40  utterances  from the  target speaker  for  adaptation  , the  error rate  dropped to 4.1% --- a 45% reduction in error compared to the  SI  result. ", "Comments": [], "entities": [{"id": 1094960, "label": "ENT", "start_offset": 47, "end_offset": 93}, {"id": 1094961, "label": "ENT", "start_offset": 135, "end_offset": 200}, {"id": 1094962, "label": "ENT", "start_offset": 234, "end_offset": 240}, {"id": 1094963, "label": "ENT", "start_offset": 413, "end_offset": 472}, {"id": 1094964, "label": "ENT", "start_offset": 496, "end_offset": 527}, {"id": 1094965, "label": "ENT", "start_offset": 610, "end_offset": 624}, {"id": 1094966, "label": "ENT", "start_offset": 648, "end_offset": 663}, {"id": 1094967, "label": "ENT", "start_offset": 714, "end_offset": 746}, {"id": 1094968, "label": "ENT", "start_offset": 905, "end_offset": 928}, {"id": 1094969, "label": "ENT", "start_offset": 945, "end_offset": 954}, {"id": 1094970, "label": "ENT", "start_offset": 1024, "end_offset": 1054}, {"id": 1094971, "label": "ENT", "start_offset": 1156, "end_offset": 1171}, {"id": 1094972, "label": "ENT", "start_offset": 1315, "end_offset": 1325}, {"id": 1094973, "label": "ENT", "start_offset": 1334, "end_offset": 1344}, {"id": 1094974, "label": "ENT", "start_offset": 1408, "end_offset": 1410}], "relations": [{"id": 177765, "from_id": 1094969, "to_id": 1094968, "type": "EVALUATE-FOR"}, {"id": 177766, "from_id": 1094966, "to_id": 1094965, "type": "EVALUATE-FOR"}, {"id": 177767, "from_id": 1094967, "to_id": 1094965, "type": "EVALUATE-FOR"}, {"id": 177768, "from_id": 1094972, "to_id": 1094968, "type": "COREF"}, {"id": 177769, "from_id": 1094974, "to_id": 1094965, "type": "COREF"}, {"id": 177770, "from_id": 1094963, "to_id": 1094964, "type": "COMPARE"}, {"id": 177771, "from_id": 1094973, "to_id": 1094972, "type": "EVALUATE-FOR"}, {"id": 177772, "from_id": 1094962, "to_id": 1094961, "type": "USED-FOR"}]}
{"id": "H05-1005", "text": " In this paper, we use the  information redundancy  in  multilingual input  to correct errors in  machine translation  and thus improve the quality of  multilingual summaries  . We consider the case of  multi-document summarization  , where the input  documents  are in  Arabic  , and the output  summary  is in  English  . Typically, information that makes it to a  summary  appears in many different  lexical-syntactic forms  in the input  documents  . Further, the use of multiple  machine translation systems  provides yet more  redundancy  , yielding different ways to realize that  information  in  English  . We demonstrate how errors in the  machine translations  of the input  Arabic documents  can be corrected by identifying and generating from such  redundancy  , focusing on  noun phrases  . ", "Comments": [], "entities": [{"id": 1094975, "label": "ENT", "start_offset": 28, "end_offset": 74}, {"id": 1094976, "label": "ENT", "start_offset": 98, "end_offset": 117}, {"id": 1094977, "label": "ENT", "start_offset": 152, "end_offset": 174}, {"id": 1094978, "label": "ENT", "start_offset": 203, "end_offset": 231}, {"id": 1094979, "label": "ENT", "start_offset": 271, "end_offset": 277}, {"id": 1094980, "label": "ENT", "start_offset": 313, "end_offset": 320}, {"id": 1094981, "label": "ENT", "start_offset": 403, "end_offset": 426}, {"id": 1094982, "label": "ENT", "start_offset": 485, "end_offset": 512}, {"id": 1094983, "label": "ENT", "start_offset": 605, "end_offset": 612}, {"id": 1094984, "label": "ENT", "start_offset": 650, "end_offset": 670}, {"id": 1094985, "label": "ENT", "start_offset": 686, "end_offset": 702}], "relations": [{"id": 177773, "from_id": 1094984, "to_id": 1094982, "type": "COREF"}, {"id": 177774, "from_id": 1094985, "to_id": 1094984, "type": "USED-FOR"}, {"id": 177775, "from_id": 1094975, "to_id": 1094976, "type": "USED-FOR"}, {"id": 177776, "from_id": 1094975, "to_id": 1094977, "type": "USED-FOR"}]}
{"id": "NIPS_2002_18_abs", "text": "A bio-inspired model for an analog programmable array processor (APAP), based on studies on the vertebrate retina, has permitted the realization of complex programmable spatio-temporal dynamics in VLSI. This model mimics the way in which images are processed in the visual pathway, rendering a feasible alternative for the implementation of early vision applications in standard technologies. A prototype chip has been designed and fabricated in a 0.5\u00b5m standard CMOS process. Computing power per area and power consumption is amongst the highest reported for a single chip. Design challenges, trade-offs and some experimental results are presented in this paper.", "Comments": [], "entities": [{"id": 1095037, "label": "ENT", "start_offset": 2, "end_offset": 20}, {"id": 1095038, "label": "ENT", "start_offset": 28, "end_offset": 70}, {"id": 1095039, "label": "ENT", "start_offset": 96, "end_offset": 113}, {"id": 1095040, "label": "ENT", "start_offset": 148, "end_offset": 193}, {"id": 1095041, "label": "ENT", "start_offset": 197, "end_offset": 201}, {"id": 1095042, "label": "ENT", "start_offset": 208, "end_offset": 213}, {"id": 1095043, "label": "ENT", "start_offset": 238, "end_offset": 244}, {"id": 1095044, "label": "ENT", "start_offset": 266, "end_offset": 280}, {"id": 1095045, "label": "ENT", "start_offset": 347, "end_offset": 366}, {"id": 1095046, "label": "ENT", "start_offset": 395, "end_offset": 409}, {"id": 1095047, "label": "ENT", "start_offset": 463, "end_offset": 475}, {"id": 1095048, "label": "ENT", "start_offset": 477, "end_offset": 501}, {"id": 1095049, "label": "ENT", "start_offset": 506, "end_offset": 523}], "relations": [{"id": 177813, "from_id": 1095037, "to_id": 1095038, "type": "USED-FOR"}, {"id": 177814, "from_id": 1095039, "to_id": 1095037, "type": "USED-FOR"}, {"id": 177815, "from_id": 1095040, "to_id": 1095041, "type": "FEATURE-OF"}, {"id": 177816, "from_id": 1095037, "to_id": 1095040, "type": "USED-FOR"}, {"id": 177817, "from_id": 1095042, "to_id": 1095037, "type": "COREF"}, {"id": 177818, "from_id": 1095044, "to_id": 1095043, "type": "USED-FOR"}, {"id": 177819, "from_id": 1095048, "to_id": 1095049, "type": "CONJUNCTION"}]}
{"id": "N04-1022", "text": " We present  Minimum Bayes-Risk (MBR) decoding  for  statistical machine translation . This statistical approach aims to minimize  expected loss  of  translation errors  under  loss functions  that measure  translation performance . We describe a hierarchy of  loss functions  that incorporate different levels of  linguistic information  from  word strings ,  word-to-word alignments  from an  MT system , and  syntactic structure  from  parse-trees  of  source and target language sentences . We report the  performance  of the  MBR decoders  on a  Chinese-to-English translation task . Our results show that  MBR decoding  can be used to tune  statistical MT performance  for specific  loss functions . ", "Comments": [], "entities": [{"id": 1095129, "label": "ENT", "start_offset": 13, "end_offset": 46}, {"id": 1095130, "label": "ENT", "start_offset": 53, "end_offset": 84}, {"id": 1095131, "label": "ENT", "start_offset": 92, "end_offset": 112}, {"id": 1095132, "label": "ENT", "start_offset": 131, "end_offset": 144}, {"id": 1095133, "label": "ENT", "start_offset": 150, "end_offset": 168}, {"id": 1095134, "label": "ENT", "start_offset": 177, "end_offset": 191}, {"id": 1095135, "label": "ENT", "start_offset": 207, "end_offset": 218}, {"id": 1095136, "label": "ENT", "start_offset": 261, "end_offset": 275}, {"id": 1095137, "label": "ENT", "start_offset": 315, "end_offset": 337}, {"id": 1095138, "label": "ENT", "start_offset": 361, "end_offset": 384}, {"id": 1095139, "label": "ENT", "start_offset": 395, "end_offset": 404}, {"id": 1095140, "label": "ENT", "start_offset": 412, "end_offset": 431}, {"id": 1095141, "label": "ENT", "start_offset": 439, "end_offset": 450}, {"id": 1095142, "label": "ENT", "start_offset": 531, "end_offset": 543}, {"id": 1095143, "label": "ENT", "start_offset": 551, "end_offset": 586}, {"id": 1095144, "label": "ENT", "start_offset": 612, "end_offset": 624}, {"id": 1095145, "label": "ENT", "start_offset": 647, "end_offset": 661}, {"id": 1095146, "label": "ENT", "start_offset": 689, "end_offset": 703}], "relations": [{"id": 177875, "from_id": 1095129, "to_id": 1095130, "type": "USED-FOR"}, {"id": 177876, "from_id": 1095137, "to_id": 1095136, "type": "USED-FOR"}, {"id": 177877, "from_id": 1095138, "to_id": 1095139, "type": "PART-OF"}, {"id": 177878, "from_id": 1095138, "to_id": 1095136, "type": "USED-FOR"}, {"id": 177879, "from_id": 1095140, "to_id": 1095136, "type": "USED-FOR"}, {"id": 177880, "from_id": 1095141, "to_id": 1095140, "type": "PART-OF"}, {"id": 177881, "from_id": 1095142, "to_id": 1095129, "type": "COREF"}, {"id": 177882, "from_id": 1095142, "to_id": 1095143, "type": "USED-FOR"}, {"id": 177883, "from_id": 1095144, "to_id": 1095142, "type": "COREF"}, {"id": 177884, "from_id": 1095144, "to_id": 1095146, "type": "USED-FOR"}, {"id": 177885, "from_id": 1095134, "to_id": 1095135, "type": "EVALUATE-FOR"}, {"id": 177886, "from_id": 1095144, "to_id": 1095145, "type": "USED-FOR"}, {"id": 177887, "from_id": 1095131, "to_id": 1095129, "type": "COREF"}]}
{"id": "E06-1045", "text": " We describe an implementation of data-driven selection of emphatic facial displays for an  embodied conversational agent  in a  dialogue system . A  corpus of sentences  in the domain of the  target dialogue system  was recorded, and the facial displays used by the  speaker  were annotated. The data from those recordings was used in a range of models for generating facial displays, each model making use of a different amount of  context  or choosing displays differently within a  context . The models were evaluated in two ways: by  cross-validation  against the  corpus , and by asking users to rate the output. The predictions of the  cross-validation  study differed from the actual user ratings. While the  cross-validation  gave the highest scores to models making a majority choice within a context, the user study showed a significant preference for models that produced more variation. This preference was especially strong among the female subjects. ", "Comments": [], "entities": [{"id": 1095147, "label": "ENT", "start_offset": 34, "end_offset": 55}, {"id": 1095148, "label": "ENT", "start_offset": 59, "end_offset": 83}, {"id": 1095149, "label": "ENT", "start_offset": 92, "end_offset": 121}, {"id": 1095150, "label": "ENT", "start_offset": 129, "end_offset": 144}, {"id": 1095151, "label": "ENT", "start_offset": 150, "end_offset": 169}, {"id": 1095152, "label": "ENT", "start_offset": 200, "end_offset": 215}, {"id": 1095153, "label": "ENT", "start_offset": 239, "end_offset": 254}, {"id": 1095154, "label": "ENT", "start_offset": 297, "end_offset": 301}, {"id": 1095155, "label": "ENT", "start_offset": 347, "end_offset": 353}, {"id": 1095156, "label": "ENT", "start_offset": 369, "end_offset": 384}, {"id": 1095157, "label": "ENT", "start_offset": 391, "end_offset": 396}, {"id": 1095158, "label": "ENT", "start_offset": 500, "end_offset": 506}, {"id": 1095159, "label": "ENT", "start_offset": 539, "end_offset": 555}, {"id": 1095160, "label": "ENT", "start_offset": 570, "end_offset": 576}, {"id": 1095161, "label": "ENT", "start_offset": 643, "end_offset": 659}, {"id": 1095162, "label": "ENT", "start_offset": 717, "end_offset": 733}], "relations": [{"id": 177888, "from_id": 1095149, "to_id": 1095150, "type": "PART-OF"}, {"id": 177889, "from_id": 1095147, "to_id": 1095149, "type": "USED-FOR"}, {"id": 177890, "from_id": 1095148, "to_id": 1095147, "type": "USED-FOR"}, {"id": 177891, "from_id": 1095153, "to_id": 1095148, "type": "COREF"}, {"id": 177892, "from_id": 1095159, "to_id": 1095158, "type": "EVALUATE-FOR"}, {"id": 177893, "from_id": 1095161, "to_id": 1095159, "type": "COREF"}, {"id": 177894, "from_id": 1095162, "to_id": 1095161, "type": "COREF"}, {"id": 177895, "from_id": 1095156, "to_id": 1095153, "type": "COREF"}, {"id": 177896, "from_id": 1095155, "to_id": 1095156, "type": "USED-FOR"}, {"id": 177897, "from_id": 1095157, "to_id": 1095155, "type": "COREF"}, {"id": 177898, "from_id": 1095158, "to_id": 1095157, "type": "COREF"}, {"id": 177899, "from_id": 1095154, "to_id": 1095151, "type": "COREF"}, {"id": 177900, "from_id": 1095154, "to_id": 1095155, "type": "USED-FOR"}, {"id": 177901, "from_id": 1095160, "to_id": 1095154, "type": "COREF"}, {"id": 177902, "from_id": 1095150, "to_id": 1095152, "type": "COREF"}]}
{"id": "INTERSPEECH_2001_28_abs", "text": "In this paper we summarize the experiences gained from a field trial of a speaker verification system. In the test implementation access to two rooms at the University of Frankfurt had been controlled by a speaker verification system. The paper is organized as follows: Firstly, we will describe the system concepts and implementation issues. Secondly, results of the user evaluation are reported. During the field trial all speech data was recorded. The data base created in this way has been used extensively for simulation experiments. In chapter 4 we will describe recent experiments focusing on the use of Hidden Markov Models.", "Comments": [], "entities": [{"id": 1095211, "label": "ENT", "start_offset": 74, "end_offset": 101}, {"id": 1095212, "label": "ENT", "start_offset": 206, "end_offset": 233}, {"id": 1095213, "label": "ENT", "start_offset": 368, "end_offset": 383}, {"id": 1095214, "label": "ENT", "start_offset": 425, "end_offset": 436}, {"id": 1095215, "label": "ENT", "start_offset": 611, "end_offset": 631}], "relations": [{"id": 177938, "from_id": 1095211, "to_id": 1095212, "type": "COREF"}]}
{"id": "W06-1605", "text": " We propose a framework to derive the  distance  between  concepts  from  distributional measures of word co-occurrences . We use the  categories  in a published  thesaurus  as  coarse-grained concepts , allowing all possible  distance values  to be stored in a  concept-concept matrix  roughly.01% the size of that created by existing measures. We show that the newly proposed  concept-distance measures  outperform  traditional distributional word-distance measures  in the tasks of (1) ranking  word pairs  in order of  semantic distance , and (2) correcting  real-word spelling errors . In the latter task, of all the  WordNet-based measures , only that proposed by Jiang and Conrath outperforms the best  distributional concept-distance measures . ", "Comments": [], "entities": [{"id": 1095282, "label": "ENT", "start_offset": 14, "end_offset": 23}, {"id": 1095283, "label": "ENT", "start_offset": 58, "end_offset": 66}, {"id": 1095284, "label": "ENT", "start_offset": 74, "end_offset": 120}, {"id": 1095285, "label": "ENT", "start_offset": 178, "end_offset": 201}, {"id": 1095286, "label": "ENT", "start_offset": 263, "end_offset": 285}, {"id": 1095287, "label": "ENT", "start_offset": 379, "end_offset": 404}, {"id": 1095288, "label": "ENT", "start_offset": 430, "end_offset": 467}, {"id": 1095289, "label": "ENT", "start_offset": 476, "end_offset": 481}, {"id": 1095290, "label": "ENT", "start_offset": 489, "end_offset": 540}, {"id": 1095291, "label": "ENT", "start_offset": 551, "end_offset": 588}, {"id": 1095292, "label": "ENT", "start_offset": 605, "end_offset": 609}, {"id": 1095293, "label": "ENT", "start_offset": 623, "end_offset": 645}, {"id": 1095294, "label": "ENT", "start_offset": 710, "end_offset": 750}], "relations": [{"id": 177989, "from_id": 1095288, "to_id": 1095287, "type": "COMPARE"}, {"id": 177990, "from_id": 1095294, "to_id": 1095293, "type": "COMPARE"}, {"id": 177991, "from_id": 1095284, "to_id": 1095282, "type": "USED-FOR"}, {"id": 177992, "from_id": 1095290, "to_id": 1095289, "type": "HYPONYM-OF"}, {"id": 177993, "from_id": 1095291, "to_id": 1095289, "type": "HYPONYM-OF"}, {"id": 177994, "from_id": 1095288, "to_id": 1095289, "type": "USED-FOR"}, {"id": 177995, "from_id": 1095287, "to_id": 1095289, "type": "USED-FOR"}, {"id": 177996, "from_id": 1095292, "to_id": 1095291, "type": "COREF"}, {"id": 177997, "from_id": 1095287, "to_id": 1095282, "type": "COREF"}, {"id": 177998, "from_id": 1095291, "to_id": 1095290, "type": "CONJUNCTION"}, {"id": 177999, "from_id": 1095292, "to_id": 1095293, "type": "EVALUATE-FOR"}, {"id": 178000, "from_id": 1095292, "to_id": 1095294, "type": "EVALUATE-FOR"}, {"id": 178001, "from_id": 1095294, "to_id": 1095287, "type": "COREF"}]}
{"id": "J90-3002", "text": "   This paper presents a specialized  editor  for a highly structured  dictionary  . The basic goal in building that  editor  was to provide an adequate tool to help  lexicologists  produce a valid and coherent  dictionary  on the basis of a  linguistic theory  . If we want valuable  lexicons  and  grammars  to achieve complex  natural language processing  , we must provide very powerful tools to help create and ensure the validity of such complex  linguistic databases  . Our most important task in building the  editor  was to define a set of  coherence rules  that could be computationally applied to ensure the validity of  lexical entries  . A customized  interface  for browsing and editing was also designed and implemented. ", "Comments": [], "entities": [{"id": 1095321, "label": "ENT", "start_offset": 38, "end_offset": 44}, {"id": 1095322, "label": "ENT", "start_offset": 59, "end_offset": 81}, {"id": 1095323, "label": "ENT", "start_offset": 118, "end_offset": 124}, {"id": 1095324, "label": "ENT", "start_offset": 212, "end_offset": 222}, {"id": 1095325, "label": "ENT", "start_offset": 243, "end_offset": 260}, {"id": 1095326, "label": "ENT", "start_offset": 330, "end_offset": 357}, {"id": 1095327, "label": "ENT", "start_offset": 453, "end_offset": 473}, {"id": 1095328, "label": "ENT", "start_offset": 518, "end_offset": 524}, {"id": 1095329, "label": "ENT", "start_offset": 550, "end_offset": 565}], "relations": [{"id": 178019, "from_id": 1095325, "to_id": 1095324, "type": "USED-FOR"}, {"id": 178020, "from_id": 1095322, "to_id": 1095321, "type": "USED-FOR"}, {"id": 178021, "from_id": 1095323, "to_id": 1095321, "type": "COREF"}, {"id": 178022, "from_id": 1095323, "to_id": 1095324, "type": "USED-FOR"}, {"id": 178023, "from_id": 1095327, "to_id": 1095324, "type": "COREF"}, {"id": 178024, "from_id": 1095328, "to_id": 1095323, "type": "COREF"}, {"id": 178025, "from_id": 1095322, "to_id": 1095324, "type": "COREF"}]}
{"id": "W99-0408", "text": " In this paper we discuss a proposed  user knowledge modeling architecture  for the  ICICLE system , a  language tutoring application  for deaf learners of  written English . The model will represent the  language proficiency  of the user and is designed to be referenced during both  writing analysis  and  feedback production . We motivate our  model design  by citing relevant research on  second language and cognitive skill acquisition , and briefly discuss preliminary empirical evidence supporting the  design . We conclude by showing how our  design  can provide a rich and  robust information base  to a language assessment / correction application by modeling  user proficiency  at a high level of granularity and specificity. ", "Comments": [], "entities": [{"id": 1095344, "label": "ENT", "start_offset": 38, "end_offset": 74}, {"id": 1095345, "label": "ENT", "start_offset": 85, "end_offset": 98}, {"id": 1095346, "label": "ENT", "start_offset": 104, "end_offset": 133}, {"id": 1095347, "label": "ENT", "start_offset": 139, "end_offset": 152}, {"id": 1095348, "label": "ENT", "start_offset": 157, "end_offset": 172}, {"id": 1095349, "label": "ENT", "start_offset": 179, "end_offset": 184}, {"id": 1095350, "label": "ENT", "start_offset": 285, "end_offset": 301}, {"id": 1095351, "label": "ENT", "start_offset": 308, "end_offset": 327}, {"id": 1095352, "label": "ENT", "start_offset": 347, "end_offset": 359}, {"id": 1095353, "label": "ENT", "start_offset": 393, "end_offset": 440}, {"id": 1095354, "label": "ENT", "start_offset": 510, "end_offset": 516}, {"id": 1095355, "label": "ENT", "start_offset": 551, "end_offset": 557}, {"id": 1095356, "label": "ENT", "start_offset": 613, "end_offset": 657}, {"id": 1095357, "label": "ENT", "start_offset": 671, "end_offset": 687}, {"id": 1095358, "label": "ENT", "start_offset": 708, "end_offset": 719}, {"id": 1095359, "label": "ENT", "start_offset": 724, "end_offset": 735}], "relations": [{"id": 178034, "from_id": 1095344, "to_id": 1095345, "type": "USED-FOR"}, {"id": 178035, "from_id": 1095345, "to_id": 1095346, "type": "HYPONYM-OF"}, {"id": 178036, "from_id": 1095349, "to_id": 1095344, "type": "COREF"}, {"id": 178037, "from_id": 1095349, "to_id": 1095350, "type": "USED-FOR"}, {"id": 178038, "from_id": 1095349, "to_id": 1095351, "type": "USED-FOR"}, {"id": 178039, "from_id": 1095350, "to_id": 1095351, "type": "CONJUNCTION"}, {"id": 178040, "from_id": 1095352, "to_id": 1095349, "type": "COREF"}, {"id": 178041, "from_id": 1095353, "to_id": 1095352, "type": "USED-FOR"}, {"id": 178042, "from_id": 1095354, "to_id": 1095352, "type": "COREF"}, {"id": 178043, "from_id": 1095355, "to_id": 1095354, "type": "COREF"}, {"id": 178044, "from_id": 1095355, "to_id": 1095356, "type": "USED-FOR"}, {"id": 178045, "from_id": 1095355, "to_id": 1095357, "type": "USED-FOR"}, {"id": 178046, "from_id": 1095348, "to_id": 1095346, "type": "USED-FOR"}, {"id": 178047, "from_id": 1095346, "to_id": 1095347, "type": "USED-FOR"}, {"id": 178048, "from_id": 1095358, "to_id": 1095359, "type": "CONJUNCTION"}, {"id": 178049, "from_id": 1095358, "to_id": 1095357, "type": "EVALUATE-FOR"}, {"id": 178050, "from_id": 1095359, "to_id": 1095357, "type": "EVALUATE-FOR"}]}
{"id": "ICCV_2013_36_abs", "text": "There is an increased interest in the efficient creation of city models, be it virtual or as-built. We present a method for synthesizing complex, photo-realistic facade images, from a single example. After parsing the example image into its semantic components, a tiling for it is generated. Novel tilings can then be created, yielding facade textures with different dimensions or with occluded parts inpainted. A genetic algorithm guides the novel facades as well as inpainted parts to be consistent with the example, both in terms of their overall structure and their detailed textures. Promising results for multiple standard datasets \u2013 in particular for the different building styles they contain \u2013 demonstrate the potential of the method.", "Comments": [], "entities": [{"id": 1095375, "label": "ENT", "start_offset": 48, "end_offset": 71}, {"id": 1095376, "label": "ENT", "start_offset": 113, "end_offset": 119}, {"id": 1095377, "label": "ENT", "start_offset": 124, "end_offset": 175}, {"id": 1095378, "label": "ENT", "start_offset": 241, "end_offset": 260}, {"id": 1095379, "label": "ENT", "start_offset": 264, "end_offset": 270}, {"id": 1095380, "label": "ENT", "start_offset": 298, "end_offset": 305}, {"id": 1095381, "label": "ENT", "start_offset": 336, "end_offset": 351}, {"id": 1095382, "label": "ENT", "start_offset": 386, "end_offset": 410}, {"id": 1095383, "label": "ENT", "start_offset": 414, "end_offset": 431}, {"id": 1095384, "label": "ENT", "start_offset": 449, "end_offset": 456}, {"id": 1095385, "label": "ENT", "start_offset": 468, "end_offset": 483}, {"id": 1095386, "label": "ENT", "start_offset": 611, "end_offset": 637}, {"id": 1095387, "label": "ENT", "start_offset": 736, "end_offset": 742}], "relations": [{"id": 178067, "from_id": 1095376, "to_id": 1095377, "type": "USED-FOR"}, {"id": 178068, "from_id": 1095379, "to_id": 1095378, "type": "USED-FOR"}, {"id": 178069, "from_id": 1095382, "to_id": 1095381, "type": "FEATURE-OF"}, {"id": 178070, "from_id": 1095383, "to_id": 1095384, "type": "USED-FOR"}, {"id": 178071, "from_id": 1095383, "to_id": 1095385, "type": "USED-FOR"}, {"id": 178072, "from_id": 1095383, "to_id": 1095387, "type": "COREF"}, {"id": 178073, "from_id": 1095386, "to_id": 1095387, "type": "EVALUATE-FOR"}]}
{"id": "ICCV_2013_26_abs", "text": "We propose an exact, general and efficient coarse-to-fine energy minimization strategy for semantic video segmenta-tion. Our strategy is based on a hierarchical abstraction of the supervoxel graph that allows us to minimize an energy defined at the finest level of the hierarchy by minimizing a series of simpler energies defined over coarser graphs. The strategy is exact, i.e., it produces the same solution as minimizing over the finest graph. It is general, i.e., it can be used to minimize any energy function (e.g., unary, pairwise, and higher-order terms) with any existing energy minimization algorithm (e.g., graph cuts and belief propagation). It also gives significant speedups in inference for several datasets with varying degrees of spatio-temporal continuity. We also discuss the strengths and weaknesses of our strategy relative to existing hierarchical approaches, and the kinds of image and video data that provide the best speedups.", "Comments": [], "entities": [{"id": 1095388, "label": "ENT", "start_offset": 43, "end_offset": 86}, {"id": 1095389, "label": "ENT", "start_offset": 91, "end_offset": 119}, {"id": 1095390, "label": "ENT", "start_offset": 125, "end_offset": 133}, {"id": 1095391, "label": "ENT", "start_offset": 148, "end_offset": 196}, {"id": 1095392, "label": "ENT", "start_offset": 269, "end_offset": 278}, {"id": 1095393, "label": "ENT", "start_offset": 335, "end_offset": 349}, {"id": 1095394, "label": "ENT", "start_offset": 355, "end_offset": 363}, {"id": 1095395, "label": "ENT", "start_offset": 380, "end_offset": 382}, {"id": 1095396, "label": "ENT", "start_offset": 433, "end_offset": 445}, {"id": 1095397, "label": "ENT", "start_offset": 447, "end_offset": 449}, {"id": 1095398, "label": "ENT", "start_offset": 468, "end_offset": 470}, {"id": 1095399, "label": "ENT", "start_offset": 499, "end_offset": 514}, {"id": 1095400, "label": "ENT", "start_offset": 581, "end_offset": 610}, {"id": 1095401, "label": "ENT", "start_offset": 618, "end_offset": 628}, {"id": 1095402, "label": "ENT", "start_offset": 633, "end_offset": 651}, {"id": 1095403, "label": "ENT", "start_offset": 654, "end_offset": 656}, {"id": 1095404, "label": "ENT", "start_offset": 692, "end_offset": 701}, {"id": 1095405, "label": "ENT", "start_offset": 714, "end_offset": 722}, {"id": 1095406, "label": "ENT", "start_offset": 747, "end_offset": 773}, {"id": 1095407, "label": "ENT", "start_offset": 827, "end_offset": 835}, {"id": 1095408, "label": "ENT", "start_offset": 857, "end_offset": 880}, {"id": 1095409, "label": "ENT", "start_offset": 899, "end_offset": 919}], "relations": [{"id": 178074, "from_id": 1095388, "to_id": 1095389, "type": "USED-FOR"}, {"id": 178075, "from_id": 1095390, "to_id": 1095388, "type": "COREF"}, {"id": 178076, "from_id": 1095391, "to_id": 1095390, "type": "USED-FOR"}, {"id": 178077, "from_id": 1095390, "to_id": 1095394, "type": "COREF"}, {"id": 178078, "from_id": 1095394, "to_id": 1095395, "type": "COREF"}, {"id": 178079, "from_id": 1095394, "to_id": 1095397, "type": "COREF"}, {"id": 178080, "from_id": 1095397, "to_id": 1095398, "type": "COREF"}, {"id": 178081, "from_id": 1095398, "to_id": 1095399, "type": "USED-FOR"}, {"id": 178082, "from_id": 1095400, "to_id": 1095399, "type": "USED-FOR"}, {"id": 178083, "from_id": 1095398, "to_id": 1095400, "type": "CONJUNCTION"}, {"id": 178084, "from_id": 1095401, "to_id": 1095400, "type": "HYPONYM-OF"}, {"id": 178085, "from_id": 1095402, "to_id": 1095400, "type": "HYPONYM-OF"}, {"id": 178086, "from_id": 1095401, "to_id": 1095402, "type": "CONJUNCTION"}, {"id": 178087, "from_id": 1095398, "to_id": 1095407, "type": "COREF"}, {"id": 178088, "from_id": 1095407, "to_id": 1095408, "type": "COMPARE"}, {"id": 178089, "from_id": 1095397, "to_id": 1095403, "type": "COREF"}, {"id": 178090, "from_id": 1095403, "to_id": 1095404, "type": "USED-FOR"}, {"id": 178091, "from_id": 1095406, "to_id": 1095405, "type": "FEATURE-OF"}, {"id": 178092, "from_id": 1095405, "to_id": 1095403, "type": "EVALUATE-FOR"}]}
{"id": "N03-2017", "text": " We present a  syntax-based constraint  for  word alignment  , known as the  cohesion constraint  . It requires disjoint  English phrases  to be mapped to non-overlapping intervals in the  French sentence  . We evaluate the utility of this  constraint  in two different algorithms. The results show that it can provide a significant improvement in  alignment quality  . ", "Comments": [], "entities": [{"id": 1095424, "label": "ENT", "start_offset": 15, "end_offset": 38}, {"id": 1095425, "label": "ENT", "start_offset": 45, "end_offset": 59}, {"id": 1095426, "label": "ENT", "start_offset": 77, "end_offset": 96}, {"id": 1095427, "label": "ENT", "start_offset": 100, "end_offset": 102}, {"id": 1095428, "label": "ENT", "start_offset": 122, "end_offset": 137}, {"id": 1095429, "label": "ENT", "start_offset": 189, "end_offset": 204}, {"id": 1095430, "label": "ENT", "start_offset": 241, "end_offset": 251}, {"id": 1095431, "label": "ENT", "start_offset": 270, "end_offset": 280}, {"id": 1095432, "label": "ENT", "start_offset": 304, "end_offset": 306}, {"id": 1095433, "label": "ENT", "start_offset": 349, "end_offset": 366}], "relations": [{"id": 178106, "from_id": 1095424, "to_id": 1095425, "type": "USED-FOR"}, {"id": 178107, "from_id": 1095426, "to_id": 1095424, "type": "HYPONYM-OF"}, {"id": 178108, "from_id": 1095427, "to_id": 1095426, "type": "COREF"}, {"id": 178109, "from_id": 1095428, "to_id": 1095427, "type": "USED-FOR"}, {"id": 178110, "from_id": 1095430, "to_id": 1095427, "type": "COREF"}, {"id": 178111, "from_id": 1095432, "to_id": 1095430, "type": "COREF"}, {"id": 178112, "from_id": 1095431, "to_id": 1095430, "type": "EVALUATE-FOR"}, {"id": 178113, "from_id": 1095433, "to_id": 1095432, "type": "EVALUATE-FOR"}]}
{"id": "P05-1034", "text": " We describe a novel approach to  statistical machine translation  that combines  syntactic information  in the  source language  with recent advances in  phrasal translation  . This method requires a  source-language   dependency parser  ,  target language   word segmentation  and an  unsupervised word alignment component  . We align a  parallel corpus  , project the  source dependency parse  onto the target  sentence  , extract  dependency treelet translation pairs  , and train a  tree-based ordering model  . We describe an efficient  decoder  and show that using these  tree-based models  in combination with conventional  SMT models  provides a promising approach that incorporates the power of  phrasal SMT  with the linguistic generality available in a  parser  . ", "Comments": [], "entities": [{"id": 1095547, "label": "ENT", "start_offset": 21, "end_offset": 29}, {"id": 1095548, "label": "ENT", "start_offset": 34, "end_offset": 65}, {"id": 1095549, "label": "ENT", "start_offset": 82, "end_offset": 103}, {"id": 1095550, "label": "ENT", "start_offset": 155, "end_offset": 174}, {"id": 1095551, "label": "ENT", "start_offset": 183, "end_offset": 189}, {"id": 1095552, "label": "ENT", "start_offset": 202, "end_offset": 237}, {"id": 1095553, "label": "ENT", "start_offset": 242, "end_offset": 277}, {"id": 1095554, "label": "ENT", "start_offset": 287, "end_offset": 324}, {"id": 1095555, "label": "ENT", "start_offset": 340, "end_offset": 355}, {"id": 1095556, "label": "ENT", "start_offset": 372, "end_offset": 395}, {"id": 1095557, "label": "ENT", "start_offset": 435, "end_offset": 471}, {"id": 1095558, "label": "ENT", "start_offset": 488, "end_offset": 513}, {"id": 1095559, "label": "ENT", "start_offset": 543, "end_offset": 550}, {"id": 1095560, "label": "ENT", "start_offset": 579, "end_offset": 596}, {"id": 1095561, "label": "ENT", "start_offset": 632, "end_offset": 642}, {"id": 1095562, "label": "ENT", "start_offset": 665, "end_offset": 673}, {"id": 1095563, "label": "ENT", "start_offset": 706, "end_offset": 717}, {"id": 1095564, "label": "ENT", "start_offset": 728, "end_offset": 749}, {"id": 1095565, "label": "ENT", "start_offset": 766, "end_offset": 772}], "relations": [{"id": 178209, "from_id": 1095547, "to_id": 1095548, "type": "USED-FOR"}, {"id": 178210, "from_id": 1095549, "to_id": 1095550, "type": "CONJUNCTION"}, {"id": 178211, "from_id": 1095549, "to_id": 1095547, "type": "PART-OF"}, {"id": 178212, "from_id": 1095550, "to_id": 1095547, "type": "PART-OF"}, {"id": 178213, "from_id": 1095547, "to_id": 1095551, "type": "COREF"}, {"id": 178214, "from_id": 1095552, "to_id": 1095551, "type": "USED-FOR"}, {"id": 178215, "from_id": 1095553, "to_id": 1095551, "type": "USED-FOR"}, {"id": 178216, "from_id": 1095554, "to_id": 1095551, "type": "USED-FOR"}, {"id": 178217, "from_id": 1095553, "to_id": 1095554, "type": "CONJUNCTION"}, {"id": 178218, "from_id": 1095552, "to_id": 1095553, "type": "CONJUNCTION"}, {"id": 178219, "from_id": 1095558, "to_id": 1095560, "type": "COREF"}, {"id": 178220, "from_id": 1095560, "to_id": 1095561, "type": "CONJUNCTION"}, {"id": 178221, "from_id": 1095561, "to_id": 1095562, "type": "USED-FOR"}, {"id": 178222, "from_id": 1095560, "to_id": 1095562, "type": "USED-FOR"}, {"id": 178223, "from_id": 1095563, "to_id": 1095565, "type": "USED-FOR"}, {"id": 178224, "from_id": 1095564, "to_id": 1095565, "type": "FEATURE-OF"}, {"id": 178225, "from_id": 1095563, "to_id": 1095564, "type": "CONJUNCTION"}]}
{"id": "N01-1003", "text": "  Sentence planning  is a set of inter-related but distinct tasks, one of which is  sentence scoping  , i.e. the choice of  syntactic structure  for elementary  speech acts  and the decision of how to combine them into one or more  sentences  . In this paper, we present  SPoT  , a  sentence planner  , and a new methodology for automatically training  SPoT  on the basis of  feedback  provided by  human judges  . We reconceptualize the task into two distinct phases. First, a very simple,  randomized sentence-plan-generator (SPG)  generates a potentially large list of possible  sentence plans  for a given  text-plan input  . Second, the  sentence-plan-ranker (SPR)  ranks the list of output  sentence plans  , and then selects the top-ranked  plan  . The  SPR  uses  ranking rules  automatically learned from  training data  . We show that the trained  SPR  learns to select a  sentence plan  whose rating on average is only 5% worse than the  top human-ranked sentence plan  . ", "Comments": [], "entities": [{"id": 1095566, "label": "ENT", "start_offset": 2, "end_offset": 19}, {"id": 1095567, "label": "ENT", "start_offset": 60, "end_offset": 65}, {"id": 1095568, "label": "ENT", "start_offset": 84, "end_offset": 100}, {"id": 1095569, "label": "ENT", "start_offset": 124, "end_offset": 143}, {"id": 1095570, "label": "ENT", "start_offset": 161, "end_offset": 172}, {"id": 1095571, "label": "ENT", "start_offset": 272, "end_offset": 276}, {"id": 1095572, "label": "ENT", "start_offset": 283, "end_offset": 299}, {"id": 1095573, "label": "ENT", "start_offset": 313, "end_offset": 324}, {"id": 1095574, "label": "ENT", "start_offset": 353, "end_offset": 357}, {"id": 1095575, "label": "ENT", "start_offset": 492, "end_offset": 532}, {"id": 1095576, "label": "ENT", "start_offset": 582, "end_offset": 596}, {"id": 1095577, "label": "ENT", "start_offset": 611, "end_offset": 626}, {"id": 1095578, "label": "ENT", "start_offset": 643, "end_offset": 669}, {"id": 1095579, "label": "ENT", "start_offset": 697, "end_offset": 711}, {"id": 1095580, "label": "ENT", "start_offset": 761, "end_offset": 764}, {"id": 1095581, "label": "ENT", "start_offset": 772, "end_offset": 785}, {"id": 1095582, "label": "ENT", "start_offset": 858, "end_offset": 861}, {"id": 1095583, "label": "ENT", "start_offset": 883, "end_offset": 896}, {"id": 1095584, "label": "ENT", "start_offset": 949, "end_offset": 979}], "relations": [{"id": 178226, "from_id": 1095583, "to_id": 1095584, "type": "COMPARE"}, {"id": 178227, "from_id": 1095567, "to_id": 1095566, "type": "COREF"}, {"id": 178228, "from_id": 1095568, "to_id": 1095567, "type": "PART-OF"}, {"id": 178229, "from_id": 1095571, "to_id": 1095572, "type": "HYPONYM-OF"}, {"id": 178230, "from_id": 1095573, "to_id": 1095574, "type": "USED-FOR"}, {"id": 178231, "from_id": 1095574, "to_id": 1095571, "type": "COREF"}, {"id": 178232, "from_id": 1095575, "to_id": 1095576, "type": "USED-FOR"}, {"id": 178233, "from_id": 1095577, "to_id": 1095575, "type": "USED-FOR"}, {"id": 178234, "from_id": 1095578, "to_id": 1095579, "type": "USED-FOR"}, {"id": 178235, "from_id": 1095579, "to_id": 1095576, "type": "COREF"}, {"id": 178236, "from_id": 1095580, "to_id": 1095578, "type": "COREF"}, {"id": 178237, "from_id": 1095581, "to_id": 1095580, "type": "USED-FOR"}, {"id": 178238, "from_id": 1095582, "to_id": 1095580, "type": "COREF"}, {"id": 178239, "from_id": 1095582, "to_id": 1095583, "type": "USED-FOR"}, {"id": 178240, "from_id": 1095569, "to_id": 1095570, "type": "USED-FOR"}]}
{"id": "CVPR_2008_256_abs", "text": "Given an object model and a black-box measure of similarity between the model and candidate targets, we consider visual object tracking as a numerical optimization problem. During normal tracking conditions when the object is visible from frame to frame, local optimization is used to track the local mode of the similarity measure in a parameter space of translation, rotation and scale. However, when the object becomes partially or totally occluded, such local tracking is prone to failure, especially when common prediction techniques like the Kalman filter do not provide a good estimate of object parameters in future frames. To recover from these inevitable tracking failures, we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing (ASA), a method that avoids becoming trapped at local modes and is much faster than exhaustive search. As a Monte Carlo approach, ASA stochastically samples the parameter space, in contrast to local deterministic search. We apply cluster analysis on the sampled parameter space to redetect the object and renew the local tracker. Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions. Our approach outperforms state-of-the-art trackers on the VIVID benchmark datasets.", "Comments": [], "entities": [{"id": 1095608, "label": "ENT", "start_offset": 9, "end_offset": 21}, {"id": 1095609, "label": "ENT", "start_offset": 28, "end_offset": 59}, {"id": 1095610, "label": "ENT", "start_offset": 72, "end_offset": 77}, {"id": 1095611, "label": "ENT", "start_offset": 113, "end_offset": 135}, {"id": 1095612, "label": "ENT", "start_offset": 141, "end_offset": 171}, {"id": 1095613, "label": "ENT", "start_offset": 255, "end_offset": 273}, {"id": 1095614, "label": "ENT", "start_offset": 295, "end_offset": 331}, {"id": 1095615, "label": "ENT", "start_offset": 337, "end_offset": 387}, {"id": 1095616, "label": "ENT", "start_offset": 458, "end_offset": 472}, {"id": 1095617, "label": "ENT", "start_offset": 517, "end_offset": 538}, {"id": 1095618, "label": "ENT", "start_offset": 548, "end_offset": 561}, {"id": 1095619, "label": "ENT", "start_offset": 696, "end_offset": 712}, {"id": 1095620, "label": "ENT", "start_offset": 718, "end_offset": 745}, {"id": 1095621, "label": "ENT", "start_offset": 756, "end_offset": 758}, {"id": 1095622, "label": "ENT", "start_offset": 763, "end_offset": 797}, {"id": 1095623, "label": "ENT", "start_offset": 801, "end_offset": 807}, {"id": 1095624, "label": "ENT", "start_offset": 876, "end_offset": 893}, {"id": 1095625, "label": "ENT", "start_offset": 900, "end_offset": 920}, {"id": 1095626, "label": "ENT", "start_offset": 922, "end_offset": 925}, {"id": 1095627, "label": "ENT", "start_offset": 953, "end_offset": 968}, {"id": 1095628, "label": "ENT", "start_offset": 985, "end_offset": 1011}, {"id": 1095629, "label": "ENT", "start_offset": 1022, "end_offset": 1038}, {"id": 1095630, "label": "ENT", "start_offset": 1046, "end_offset": 1069}, {"id": 1095631, "label": "ENT", "start_offset": 1107, "end_offset": 1120}, {"id": 1095632, "label": "ENT", "start_offset": 1126, "end_offset": 1180}, {"id": 1095633, "label": "ENT", "start_offset": 1209, "end_offset": 1224}, {"id": 1095634, "label": "ENT", "start_offset": 1230, "end_offset": 1245}, {"id": 1095635, "label": "ENT", "start_offset": 1256, "end_offset": 1270}, {"id": 1095636, "label": "ENT", "start_offset": 1276, "end_offset": 1284}, {"id": 1095637, "label": "ENT", "start_offset": 1297, "end_offset": 1322}, {"id": 1095638, "label": "ENT", "start_offset": 1330, "end_offset": 1354}], "relations": [{"id": 178258, "from_id": 1095610, "to_id": 1095608, "type": "COREF"}, {"id": 178259, "from_id": 1095612, "to_id": 1095611, "type": "USED-FOR"}, {"id": 178260, "from_id": 1095613, "to_id": 1095614, "type": "USED-FOR"}, {"id": 178261, "from_id": 1095615, "to_id": 1095614, "type": "USED-FOR"}, {"id": 178262, "from_id": 1095620, "to_id": 1095619, "type": "USED-FOR"}, {"id": 178263, "from_id": 1095620, "to_id": 1095621, "type": "COREF"}, {"id": 178264, "from_id": 1095622, "to_id": 1095621, "type": "USED-FOR"}, {"id": 178265, "from_id": 1095623, "to_id": 1095622, "type": "COREF"}, {"id": 178266, "from_id": 1095623, "to_id": 1095624, "type": "COMPARE"}, {"id": 178267, "from_id": 1095622, "to_id": 1095626, "type": "COREF"}, {"id": 178268, "from_id": 1095626, "to_id": 1095625, "type": "HYPONYM-OF"}, {"id": 178269, "from_id": 1095626, "to_id": 1095628, "type": "COMPARE"}, {"id": 178270, "from_id": 1095632, "to_id": 1095636, "type": "COREF"}, {"id": 178271, "from_id": 1095637, "to_id": 1095636, "type": "COMPARE"}, {"id": 178272, "from_id": 1095638, "to_id": 1095636, "type": "EVALUATE-FOR"}, {"id": 178273, "from_id": 1095638, "to_id": 1095637, "type": "EVALUATE-FOR"}, {"id": 178274, "from_id": 1095633, "to_id": 1095632, "type": "EVALUATE-FOR"}, {"id": 178275, "from_id": 1095634, "to_id": 1095633, "type": "FEATURE-OF"}, {"id": 178276, "from_id": 1095635, "to_id": 1095633, "type": "FEATURE-OF"}, {"id": 178277, "from_id": 1095634, "to_id": 1095635, "type": "CONJUNCTION"}, {"id": 178278, "from_id": 1095629, "to_id": 1095630, "type": "USED-FOR"}, {"id": 178279, "from_id": 1095629, "to_id": 1095631, "type": "USED-FOR"}, {"id": 178280, "from_id": 1095618, "to_id": 1095617, "type": "PART-OF"}]}
{"id": "P81-1032", "text": " Robust  natural language interpretation  requires strong  semantic domain models ,  fail-soft recovery heuristics , and very flexible  control structures . Although  single-strategy parsers  have met with a measure of success, a  multi-strategy approach  is shown to provide a much higher degree of flexibility, redundancy, and ability to bring  task-specific domain knowledge  (in addition to  general linguistic knowledge ) to bear on both  grammatical and ungrammatical input . A  parsing algorithm  is presented that integrates several different  parsing strategies , with  case-frame instantiation  dominating. Each of these  parsing strategies  exploits different  types of knowledge ; and their combination provides a strong framework in which to process  conjunctions ,  fragmentary input , and  ungrammatical structures , as well as less exotic,  grammatically correct input . Several  specific heuristics  for handling  ungrammatical input  are presented within this  multi-strategy framework . ", "Comments": [], "entities": [{"id": 1095656, "label": "ENT", "start_offset": 9, "end_offset": 40}, {"id": 1095657, "label": "ENT", "start_offset": 59, "end_offset": 81}, {"id": 1095658, "label": "ENT", "start_offset": 85, "end_offset": 114}, {"id": 1095659, "label": "ENT", "start_offset": 136, "end_offset": 154}, {"id": 1095660, "label": "ENT", "start_offset": 167, "end_offset": 190}, {"id": 1095661, "label": "ENT", "start_offset": 231, "end_offset": 254}, {"id": 1095662, "label": "ENT", "start_offset": 347, "end_offset": 377}, {"id": 1095663, "label": "ENT", "start_offset": 396, "end_offset": 424}, {"id": 1095664, "label": "ENT", "start_offset": 444, "end_offset": 479}, {"id": 1095665, "label": "ENT", "start_offset": 485, "end_offset": 502}, {"id": 1095666, "label": "ENT", "start_offset": 552, "end_offset": 570}, {"id": 1095667, "label": "ENT", "start_offset": 579, "end_offset": 603}, {"id": 1095668, "label": "ENT", "start_offset": 632, "end_offset": 650}, {"id": 1095669, "label": "ENT", "start_offset": 764, "end_offset": 776}, {"id": 1095670, "label": "ENT", "start_offset": 780, "end_offset": 797}, {"id": 1095671, "label": "ENT", "start_offset": 805, "end_offset": 829}, {"id": 1095672, "label": "ENT", "start_offset": 848, "end_offset": 884}, {"id": 1095673, "label": "ENT", "start_offset": 896, "end_offset": 915}, {"id": 1095674, "label": "ENT", "start_offset": 931, "end_offset": 950}, {"id": 1095675, "label": "ENT", "start_offset": 979, "end_offset": 1003}], "relations": [{"id": 178291, "from_id": 1095657, "to_id": 1095656, "type": "USED-FOR"}, {"id": 178292, "from_id": 1095662, "to_id": 1095663, "type": "CONJUNCTION"}, {"id": 178293, "from_id": 1095666, "to_id": 1095665, "type": "PART-OF"}, {"id": 178294, "from_id": 1095673, "to_id": 1095675, "type": "PART-OF"}, {"id": 178295, "from_id": 1095666, "to_id": 1095668, "type": "COREF"}, {"id": 178296, "from_id": 1095673, "to_id": 1095674, "type": "USED-FOR"}, {"id": 178297, "from_id": 1095658, "to_id": 1095656, "type": "USED-FOR"}, {"id": 178298, "from_id": 1095659, "to_id": 1095656, "type": "USED-FOR"}, {"id": 178299, "from_id": 1095658, "to_id": 1095659, "type": "CONJUNCTION"}, {"id": 178300, "from_id": 1095657, "to_id": 1095658, "type": "CONJUNCTION"}, {"id": 178301, "from_id": 1095660, "to_id": 1095661, "type": "COMPARE"}, {"id": 178302, "from_id": 1095667, "to_id": 1095666, "type": "HYPONYM-OF"}, {"id": 178303, "from_id": 1095668, "to_id": 1095669, "type": "USED-FOR"}, {"id": 178304, "from_id": 1095668, "to_id": 1095670, "type": "USED-FOR"}, {"id": 178305, "from_id": 1095668, "to_id": 1095671, "type": "USED-FOR"}, {"id": 178306, "from_id": 1095668, "to_id": 1095672, "type": "USED-FOR"}, {"id": 178307, "from_id": 1095669, "to_id": 1095670, "type": "CONJUNCTION"}, {"id": 178308, "from_id": 1095670, "to_id": 1095671, "type": "CONJUNCTION"}, {"id": 178309, "from_id": 1095671, "to_id": 1095672, "type": "CONJUNCTION"}, {"id": 178310, "from_id": 1095661, "to_id": 1095675, "type": "COREF"}]}
{"id": "C92-3165", "text": "   This paper introduces a robust  interactive method for speech understanding  . The  generalized LR parsing  is enhanced in this approach.  Parsing  proceeds from left to right correcting minor errors. When a very noisy  portion  is detected, the  parser  skips that  portion  using a fake  non-terminal symbol  . The unidentified  portion  is resolved by  re-utterance  of that  portion  which is parsed very efficiently by using the  parse record  of the first  utterance  . The  user  does not have to speak the whole  sentence  again. This method is also capable of handling  unknown words  , which is important in practical systems. Detected  unknown words  can be incrementally incorporated into the  dictionary  after the interaction with the  user  . A  pilot system  has shown great effectiveness of this approach. ", "Comments": [], "entities": [{"id": 1095721, "label": "ENT", "start_offset": 27, "end_offset": 53}, {"id": 1095722, "label": "ENT", "start_offset": 58, "end_offset": 78}, {"id": 1095723, "label": "ENT", "start_offset": 87, "end_offset": 109}, {"id": 1095724, "label": "ENT", "start_offset": 131, "end_offset": 139}, {"id": 1095725, "label": "ENT", "start_offset": 142, "end_offset": 149}, {"id": 1095726, "label": "ENT", "start_offset": 250, "end_offset": 256}, {"id": 1095727, "label": "ENT", "start_offset": 293, "end_offset": 312}, {"id": 1095728, "label": "ENT", "start_offset": 546, "end_offset": 552}, {"id": 1095729, "label": "ENT", "start_offset": 582, "end_offset": 595}, {"id": 1095730, "label": "ENT", "start_offset": 816, "end_offset": 824}], "relations": [{"id": 178342, "from_id": 1095727, "to_id": 1095726, "type": "USED-FOR"}, {"id": 178343, "from_id": 1095721, "to_id": 1095722, "type": "USED-FOR"}, {"id": 178344, "from_id": 1095724, "to_id": 1095721, "type": "COREF"}, {"id": 178345, "from_id": 1095724, "to_id": 1095723, "type": "USED-FOR"}, {"id": 178346, "from_id": 1095726, "to_id": 1095725, "type": "COREF"}, {"id": 178347, "from_id": 1095728, "to_id": 1095724, "type": "COREF"}, {"id": 178348, "from_id": 1095728, "to_id": 1095729, "type": "USED-FOR"}, {"id": 178349, "from_id": 1095730, "to_id": 1095728, "type": "COREF"}]}
{"id": "INTERSPEECH_2001_31_abs", "text": "This paper presents a method for blind estimation of reverberation times in reverberant enclosures. The proposed algorithm is based on a statistical model of short-term log-energy sequences for echo-free speech. Given a speech utterance recorded in a reverberant room, it computes a Maximum Likelihood estimate of the room full-band reverberation time. The estimation method is shown to require little data and to perform satisfactorily. The method has been successfully applied to robust automatic speech recognition in reverberant environments by model selection. For this application, the reverberation time is first estimated from the reverberated speech utterance to be recognized. The estimation is then used to select the best acoustic model out of a library of models trained in various artificial re-verberant conditions. Speech recognition experiments in simulated and real reverberant environments show the efficiency of our approach which outperforms standard channel normaliza-tion techniques.", "Comments": [], "entities": [{"id": 1095772, "label": "ENT", "start_offset": 22, "end_offset": 28}, {"id": 1095773, "label": "ENT", "start_offset": 33, "end_offset": 72}, {"id": 1095774, "label": "ENT", "start_offset": 76, "end_offset": 98}, {"id": 1095775, "label": "ENT", "start_offset": 113, "end_offset": 122}, {"id": 1095776, "label": "ENT", "start_offset": 137, "end_offset": 189}, {"id": 1095777, "label": "ENT", "start_offset": 194, "end_offset": 210}, {"id": 1095778, "label": "ENT", "start_offset": 283, "end_offset": 351}, {"id": 1095779, "label": "ENT", "start_offset": 357, "end_offset": 374}, {"id": 1095780, "label": "ENT", "start_offset": 442, "end_offset": 448}, {"id": 1095781, "label": "ENT", "start_offset": 482, "end_offset": 517}, {"id": 1095782, "label": "ENT", "start_offset": 521, "end_offset": 545}, {"id": 1095783, "label": "ENT", "start_offset": 549, "end_offset": 564}, {"id": 1095784, "label": "ENT", "start_offset": 575, "end_offset": 586}, {"id": 1095785, "label": "ENT", "start_offset": 592, "end_offset": 610}, {"id": 1095786, "label": "ENT", "start_offset": 639, "end_offset": 668}, {"id": 1095787, "label": "ENT", "start_offset": 691, "end_offset": 701}, {"id": 1095788, "label": "ENT", "start_offset": 734, "end_offset": 748}, {"id": 1095789, "label": "ENT", "start_offset": 769, "end_offset": 775}, {"id": 1095790, "label": "ENT", "start_offset": 795, "end_offset": 829}, {"id": 1095791, "label": "ENT", "start_offset": 831, "end_offset": 849}, {"id": 1095792, "label": "ENT", "start_offset": 865, "end_offset": 908}, {"id": 1095793, "label": "ENT", "start_offset": 936, "end_offset": 944}, {"id": 1095794, "label": "ENT", "start_offset": 972, "end_offset": 1005}], "relations": [{"id": 178382, "from_id": 1095774, "to_id": 1095773, "type": "FEATURE-OF"}, {"id": 178383, "from_id": 1095772, "to_id": 1095773, "type": "USED-FOR"}, {"id": 178384, "from_id": 1095772, "to_id": 1095775, "type": "COREF"}, {"id": 178385, "from_id": 1095776, "to_id": 1095775, "type": "USED-FOR"}, {"id": 178386, "from_id": 1095776, "to_id": 1095777, "type": "USED-FOR"}, {"id": 178387, "from_id": 1095779, "to_id": 1095778, "type": "COREF"}, {"id": 178388, "from_id": 1095779, "to_id": 1095780, "type": "COREF"}, {"id": 178389, "from_id": 1095780, "to_id": 1095781, "type": "USED-FOR"}, {"id": 178390, "from_id": 1095782, "to_id": 1095781, "type": "FEATURE-OF"}, {"id": 178391, "from_id": 1095783, "to_id": 1095780, "type": "USED-FOR"}, {"id": 178392, "from_id": 1095781, "to_id": 1095784, "type": "COREF"}, {"id": 178393, "from_id": 1095786, "to_id": 1095785, "type": "USED-FOR"}, {"id": 178394, "from_id": 1095792, "to_id": 1095791, "type": "FEATURE-OF"}, {"id": 178395, "from_id": 1095775, "to_id": 1095793, "type": "COREF"}, {"id": 178396, "from_id": 1095794, "to_id": 1095793, "type": "COMPARE"}, {"id": 178397, "from_id": 1095791, "to_id": 1095793, "type": "EVALUATE-FOR"}, {"id": 178398, "from_id": 1095791, "to_id": 1095794, "type": "EVALUATE-FOR"}, {"id": 178399, "from_id": 1095788, "to_id": 1095789, "type": "PART-OF"}, {"id": 178400, "from_id": 1095790, "to_id": 1095789, "type": "FEATURE-OF"}, {"id": 178401, "from_id": 1095787, "to_id": 1095788, "type": "USED-FOR"}]}
{"id": "AAAI_1993_71_abs", "text": "In this paper we investigate the simple logical properties of contexts. We describe both the syntax and semantics of a general propositional language of context, and give a Hilbert style proof system for this language. A propositional logic of context extends classical propositional logic in two ways. Firstly, a new modality, ist(;), is introduced. It is used to express that the sentence, , holds in the context. Secondly, each context has its own vocabulary, i.e. a set of propositional atoms which are deened or meaningful in that context. The main results of this paper are the sound-ness and completeness of this Hilbert style proof system. We also provide soundness and completeness results (i.e. correspondence theory) for various extensions of the general system.", "Comments": [], "entities": [{"id": 1095876, "label": "ENT", "start_offset": 40, "end_offset": 70}, {"id": 1095877, "label": "ENT", "start_offset": 93, "end_offset": 99}, {"id": 1095878, "label": "ENT", "start_offset": 104, "end_offset": 113}, {"id": 1095879, "label": "ENT", "start_offset": 127, "end_offset": 160}, {"id": 1095880, "label": "ENT", "start_offset": 173, "end_offset": 199}, {"id": 1095881, "label": "ENT", "start_offset": 209, "end_offset": 217}, {"id": 1095882, "label": "ENT", "start_offset": 221, "end_offset": 251}, {"id": 1095883, "label": "ENT", "start_offset": 260, "end_offset": 289}, {"id": 1095884, "label": "ENT", "start_offset": 318, "end_offset": 326}, {"id": 1095885, "label": "ENT", "start_offset": 351, "end_offset": 353}, {"id": 1095886, "label": "ENT", "start_offset": 620, "end_offset": 646}, {"id": 1095887, "label": "ENT", "start_offset": 705, "end_offset": 726}], "relations": [{"id": 178456, "from_id": 1095879, "to_id": 1095881, "type": "COREF"}, {"id": 178457, "from_id": 1095878, "to_id": 1095879, "type": "FEATURE-OF"}, {"id": 178458, "from_id": 1095877, "to_id": 1095879, "type": "FEATURE-OF"}, {"id": 178459, "from_id": 1095877, "to_id": 1095878, "type": "CONJUNCTION"}, {"id": 178460, "from_id": 1095884, "to_id": 1095885, "type": "COREF"}, {"id": 178461, "from_id": 1095880, "to_id": 1095881, "type": "USED-FOR"}, {"id": 178462, "from_id": 1095880, "to_id": 1095886, "type": "COREF"}, {"id": 178463, "from_id": 1095883, "to_id": 1095882, "type": "USED-FOR"}]}
{"id": "ICASSP_1997_707_abs", "text": "Nonstationary chaotic behavior is not an oxymoron. We present two methods for capturing nonstationary chaos, then present a few examples including biological signals, ocean waves and traffic flow. The issue is of practical interest because it is often useful to capture when nonstationary events take place and it is desirable to know over what periods a signal is stationary.", "Comments": [], "entities": [{"id": 1095908, "label": "ENT", "start_offset": 0, "end_offset": 30}, {"id": 1095909, "label": "ENT", "start_offset": 41, "end_offset": 49}, {"id": 1095910, "label": "ENT", "start_offset": 66, "end_offset": 73}, {"id": 1095911, "label": "ENT", "start_offset": 88, "end_offset": 107}, {"id": 1095912, "label": "ENT", "start_offset": 128, "end_offset": 136}, {"id": 1095913, "label": "ENT", "start_offset": 147, "end_offset": 165}, {"id": 1095914, "label": "ENT", "start_offset": 167, "end_offset": 178}, {"id": 1095915, "label": "ENT", "start_offset": 183, "end_offset": 195}, {"id": 1095916, "label": "ENT", "start_offset": 275, "end_offset": 295}], "relations": [{"id": 178480, "from_id": 1095910, "to_id": 1095911, "type": "USED-FOR"}, {"id": 178481, "from_id": 1095913, "to_id": 1095912, "type": "HYPONYM-OF"}, {"id": 178482, "from_id": 1095914, "to_id": 1095912, "type": "HYPONYM-OF"}, {"id": 178483, "from_id": 1095915, "to_id": 1095912, "type": "HYPONYM-OF"}, {"id": 178484, "from_id": 1095913, "to_id": 1095914, "type": "CONJUNCTION"}, {"id": 178485, "from_id": 1095914, "to_id": 1095915, "type": "CONJUNCTION"}]}
{"id": "ICCV_1999_47_abs", "text": "Background maintenance is a frequent element of video surveillance systems. We develop Wallflower, a three-component system for background maintenance: the pixel-level component performs Wiener filtering to make probabilistic predictions of the expected background; the region-level component fills in homogeneous regions of foreground objects; and the frame-level component detects sudden, global changes in the image and swaps in better approximations of the background. We compare our system with 8 other background subtraction algorithms. Wallflower is shown to outperform previous algorithms by handling a greater set of the difficult situations that can occur. Finally, we analyze the experimental results and propose normative principles for background maintenance.", "Comments": [], "entities": [{"id": 1095917, "label": "ENT", "start_offset": 0, "end_offset": 22}, {"id": 1095918, "label": "ENT", "start_offset": 48, "end_offset": 74}, {"id": 1095919, "label": "ENT", "start_offset": 87, "end_offset": 97}, {"id": 1095920, "label": "ENT", "start_offset": 101, "end_offset": 123}, {"id": 1095921, "label": "ENT", "start_offset": 128, "end_offset": 150}, {"id": 1095922, "label": "ENT", "start_offset": 156, "end_offset": 177}, {"id": 1095923, "label": "ENT", "start_offset": 187, "end_offset": 203}, {"id": 1095924, "label": "ENT", "start_offset": 212, "end_offset": 264}, {"id": 1095925, "label": "ENT", "start_offset": 270, "end_offset": 292}, {"id": 1095926, "label": "ENT", "start_offset": 302, "end_offset": 343}, {"id": 1095927, "label": "ENT", "start_offset": 353, "end_offset": 374}, {"id": 1095928, "label": "ENT", "start_offset": 488, "end_offset": 494}, {"id": 1095929, "label": "ENT", "start_offset": 508, "end_offset": 541}, {"id": 1095930, "label": "ENT", "start_offset": 543, "end_offset": 553}, {"id": 1095931, "label": "ENT", "start_offset": 586, "end_offset": 596}, {"id": 1095932, "label": "ENT", "start_offset": 724, "end_offset": 744}, {"id": 1095933, "label": "ENT", "start_offset": 749, "end_offset": 771}], "relations": [{"id": 178486, "from_id": 1095917, "to_id": 1095918, "type": "PART-OF"}, {"id": 178487, "from_id": 1095921, "to_id": 1095917, "type": "COREF"}, {"id": 178488, "from_id": 1095919, "to_id": 1095920, "type": "COREF"}, {"id": 178489, "from_id": 1095920, "to_id": 1095921, "type": "USED-FOR"}, {"id": 178490, "from_id": 1095922, "to_id": 1095920, "type": "PART-OF"}, {"id": 178491, "from_id": 1095923, "to_id": 1095922, "type": "USED-FOR"}, {"id": 178492, "from_id": 1095923, "to_id": 1095924, "type": "USED-FOR"}, {"id": 178493, "from_id": 1095925, "to_id": 1095926, "type": "USED-FOR"}, {"id": 178494, "from_id": 1095925, "to_id": 1095920, "type": "PART-OF"}, {"id": 178495, "from_id": 1095927, "to_id": 1095920, "type": "PART-OF"}, {"id": 178496, "from_id": 1095922, "to_id": 1095925, "type": "CONJUNCTION"}, {"id": 178497, "from_id": 1095925, "to_id": 1095927, "type": "CONJUNCTION"}, {"id": 178498, "from_id": 1095919, "to_id": 1095928, "type": "COREF"}, {"id": 178499, "from_id": 1095928, "to_id": 1095929, "type": "COMPARE"}, {"id": 178500, "from_id": 1095930, "to_id": 1095928, "type": "COREF"}, {"id": 178501, "from_id": 1095931, "to_id": 1095929, "type": "COREF"}, {"id": 178502, "from_id": 1095930, "to_id": 1095931, "type": "COMPARE"}, {"id": 178503, "from_id": 1095932, "to_id": 1095933, "type": "USED-FOR"}, {"id": 178504, "from_id": 1095921, "to_id": 1095933, "type": "COREF"}]}
{"id": "CVPR_2005_11_abs", "text": "This work presents a real-time system for multiple object tracking in dynamic scenes. A unique characteristic of the system is its ability to cope with long-duration and complete occlusion without a prior knowledge about the shape or motion of objects. The system produces good segment and tracking results at a frame rate of 15-20 fps for image size of 320x240, as demonstrated by extensive experiments performed using video sequences under different conditions indoor and outdoor with long-duration and complete occlusions in changing background.", "Comments": [], "entities": [{"id": 1095934, "label": "ENT", "start_offset": 21, "end_offset": 37}, {"id": 1095935, "label": "ENT", "start_offset": 42, "end_offset": 84}, {"id": 1095936, "label": "ENT", "start_offset": 117, "end_offset": 123}, {"id": 1095937, "label": "ENT", "start_offset": 152, "end_offset": 188}, {"id": 1095938, "label": "ENT", "start_offset": 199, "end_offset": 214}, {"id": 1095939, "label": "ENT", "start_offset": 225, "end_offset": 230}, {"id": 1095940, "label": "ENT", "start_offset": 234, "end_offset": 251}, {"id": 1095941, "label": "ENT", "start_offset": 257, "end_offset": 263}, {"id": 1095942, "label": "ENT", "start_offset": 290, "end_offset": 298}, {"id": 1095943, "label": "ENT", "start_offset": 312, "end_offset": 322}, {"id": 1095944, "label": "ENT", "start_offset": 340, "end_offset": 350}, {"id": 1095945, "label": "ENT", "start_offset": 420, "end_offset": 435}, {"id": 1095946, "label": "ENT", "start_offset": 487, "end_offset": 524}, {"id": 1095947, "label": "ENT", "start_offset": 528, "end_offset": 547}], "relations": [{"id": 178505, "from_id": 1095934, "to_id": 1095935, "type": "USED-FOR"}, {"id": 178506, "from_id": 1095934, "to_id": 1095936, "type": "COREF"}, {"id": 178507, "from_id": 1095936, "to_id": 1095937, "type": "USED-FOR"}, {"id": 178508, "from_id": 1095936, "to_id": 1095941, "type": "COREF"}, {"id": 178509, "from_id": 1095942, "to_id": 1095941, "type": "EVALUATE-FOR"}, {"id": 178510, "from_id": 1095938, "to_id": 1095939, "type": "FEATURE-OF"}, {"id": 178511, "from_id": 1095938, "to_id": 1095940, "type": "FEATURE-OF"}, {"id": 178512, "from_id": 1095939, "to_id": 1095940, "type": "CONJUNCTION"}]}
{"id": "A88-1003", "text": "   In this paper, we describe the  pronominal anaphora resolution module  of  Lucy  , a portable  English understanding system  . The design of this module was motivated by the observation that, although there exist many theories of  anaphora resolution  , no one of these theories is complete. Thus we have implemented a  blackboard-like architecture  in which individual  partial theories  can be encoded as separate modules that can interact to propose candidate  antecedents  and to evaluate each other's proposals. ", "Comments": [], "entities": [{"id": 1095948, "label": "ENT", "start_offset": 35, "end_offset": 72}, {"id": 1095949, "label": "ENT", "start_offset": 78, "end_offset": 82}, {"id": 1095950, "label": "ENT", "start_offset": 98, "end_offset": 126}, {"id": 1095951, "label": "ENT", "start_offset": 149, "end_offset": 155}, {"id": 1095952, "label": "ENT", "start_offset": 234, "end_offset": 253}, {"id": 1095953, "label": "ENT", "start_offset": 323, "end_offset": 351}], "relations": [{"id": 178513, "from_id": 1095948, "to_id": 1095949, "type": "PART-OF"}, {"id": 178514, "from_id": 1095951, "to_id": 1095948, "type": "COREF"}, {"id": 178515, "from_id": 1095949, "to_id": 1095950, "type": "HYPONYM-OF"}]}
